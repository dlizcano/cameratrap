[
  {
    "objectID": "posts/2025-06-01-spatial-single-species-occupancy/index.html",
    "href": "posts/2025-06-01-spatial-single-species-occupancy/index.html",
    "title": "Spatial, single-species occupancy model",
    "section": "",
    "text": "In principle Yes!. Specially if you are using geographical covariates, mapping the occupancy, or predicting occupancy the across the space. Imperfect detection and spatial autocorrelation are two important issues to deal with in ecological sampling."
  },
  {
    "objectID": "posts/2025-06-01-spatial-single-species-occupancy/index.html#shoud-i-use-a-spatial-model",
    "href": "posts/2025-06-01-spatial-single-species-occupancy/index.html#shoud-i-use-a-spatial-model",
    "title": "Spatial, single-species occupancy model",
    "section": "",
    "text": "In principle Yes!. Specially if you are using geographical covariates, mapping the occupancy, or predicting occupancy the across the space. Imperfect detection and spatial autocorrelation are two important issues to deal with in ecological sampling."
  },
  {
    "objectID": "posts/2025-06-01-spatial-single-species-occupancy/index.html#what-is-spatial-autocorrelation",
    "href": "posts/2025-06-01-spatial-single-species-occupancy/index.html#what-is-spatial-autocorrelation",
    "title": "Spatial, single-species occupancy model",
    "section": "What is spatial autocorrelation?",
    "text": "What is spatial autocorrelation?\nThings closer together in space tend to be more similar than things farther apart. Similar to temporal autocorrelation, spatial autocorrelation is the measurement of the potential tendency for similar values to cluster based on proximity. This fact complicates statistical analyses that rely on assumptions of independence.\n\nPositive spatial autocorrelation: if a large value is observed at point A, large values will also be observed at the neighboring points.\nNegative spatial autocorrelation: if a large value is observed at point A, small values will be observed at the neighboring points.\n\n\n\nSpatial Autocorrelation\n\nWhat leads to spatial autocorrelation in species distributions?\n\nEnvironmental drivers\nBiotic factors (e.g., dispersal, conspecific attraction).\nClimatic factors (temperature-elevation)\n\nIn the past the way to incorporate spatial autocorrelation in your occupancy model was coding in BUGS or JAGS. More recently some models coded in Stan incorporated spatial autocorrelation with the package ubms, but in in a limited way. Building an occupancy model with spatial autocorrelation in Stan involves adding a spatial random effect to the occupancy submodel, often with a Conditional Autoregressive (CAR) or Gaussian Process (GP) prior. Acknowledging that nearby sites are not independent improves the accuracy of occupancy estimates and their relationship with environmental covariates. However CAR models are best for areal data, like sites organized in a grid (polygons) or counties in a state.\nRecently spOccupancy came out, this new R package was designed for efficient fitting of single-species and multi-species spatial occupancy models using Pólya-Gamma data augmentation. It leverages Nearest Neighbor Gaussian Processes (NNGPs) for scalability with large datasets.\nThis code was adapted from: https://github.com/doserjef/acoustic-spOccupancy-22/blob/main/code/single-species-example.R"
  },
  {
    "objectID": "posts/2025-06-01-spatial-single-species-occupancy/index.html#load-packages",
    "href": "posts/2025-06-01-spatial-single-species-occupancy/index.html#load-packages",
    "title": "Spatial, single-species occupancy model",
    "section": "Load packages",
    "text": "Load packages\nFirst we load some packages\n\nCodelibrary(grateful) # Facilitate Citation of R Packages\nlibrary(patchwork) # The Composer of Plots\nlibrary(readxl) # Read Excel Files\nlibrary(sf) # Simple Features for R\nlibrary(mapview) # Interactive Viewing of Spatial Data in R\nlibrary(terra) # Spatial Data Analysis\nlibrary(elevatr) # Access Elevation Data from Various APIs\nlibrary(readr) # read csv files\n\nlibrary(camtrapR) # Camera Trap Data Management and Preparation of Occupancy and Spatial Capture-Recapture Analyses\nlibrary(spOccupancy)\nlibrary(MCMCvis) # Markov chains viewer\nlibrary(bayesplot) \nlibrary(DT) # nice tables\n\nlibrary(kableExtra) # Construct Complex Table with 'kable' and Pipe Syntax\nlibrary(tidyverse) # Load the 'Tidyverse'"
  },
  {
    "objectID": "posts/2025-06-01-spatial-single-species-occupancy/index.html#load-data",
    "href": "posts/2025-06-01-spatial-single-species-occupancy/index.html#load-data",
    "title": "Spatial, single-species occupancy model",
    "section": "Load data",
    "text": "Load data\nThe data set is downloaded from Initiative Monitoreo Katios in Wildlife insights were we sampled with an array of 30 cameras on two consecutive years in Katios National Park in Colombia.\nWe use this data set just for illustrative purposes.\n\n\nInitiative Monitoreo Katios\n\n\nCode\npath &lt;- \"C:/CodigoR/CameraTrapCesar/data/katios/\"\ncameras &lt;- read_csv(paste(path, \"cameras.csv\", sep = \"\"))\ndeployment &lt;- read_csv(paste(path, \"deployments.csv\", sep = \"\"))\nimages &lt;- read_csv(paste(path, \"images.csv\", sep = \"\"))\nproject &lt;- read_csv(paste(path, \"projects.csv\", sep = \"\"))\n\n# join_by(project_id, camera_id, camera_name)`\ncam_deploy &lt;- cameras |&gt;\n  left_join(deployment) |&gt;\n  dplyr::mutate(year = lubridate::year(start_date)) #|&gt; filter(year== 2023)\ncam_deploy_image &lt;- images |&gt;\n  left_join(cam_deploy) |&gt;\n  mutate(scientificName = paste(genus, species, sep = \" \")) |&gt;\n  mutate(deployment_id_cam = paste(deployment_id, camera_id, sep = \"-\")) #|&gt; \n# filter(year==2022)"
  },
  {
    "objectID": "posts/2025-06-01-spatial-single-species-occupancy/index.html#convert-to-sf-and-view-the-map",
    "href": "posts/2025-06-01-spatial-single-species-occupancy/index.html#convert-to-sf-and-view-the-map",
    "title": "Spatial, single-species occupancy model",
    "section": "Convert to sf and view the map",
    "text": "Convert to sf and view the map\n\nCode\ndatos_distinct &lt;- cam_deploy_image |&gt;\n  distinct(longitude, latitude, deployment_id, samp_year) |&gt;\n  as.data.frame()\n\n# Fix NA camera 16\ndatos_distinct[16, ] &lt;- c(\n  -77.2787, 7.73855,\n  \"CT-K1-31-124\", 2021\n)\n\nprojlatlon &lt;- \"+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0\"\n\ndatos_sf &lt;- st_as_sf(\n  x = datos_distinct,\n  coords = c(\n    \"longitude\",\n    \"latitude\"\n  ),\n  crs = projlatlon\n)\n\nmapview(st_jitter(datos_sf, 0.00075), zcol = \"samp_year\")\n\n\n\n\n\nNotice we used the function st_jitter() because the points are on top of the previous year."
  },
  {
    "objectID": "posts/2025-06-01-spatial-single-species-occupancy/index.html#extract-site-covariates",
    "href": "posts/2025-06-01-spatial-single-species-occupancy/index.html#extract-site-covariates",
    "title": "Spatial, single-species occupancy model",
    "section": "Extract site covariates",
    "text": "Extract site covariates\nUsing the coordinates of the sf object (datos_sf) we put the cameras on top of the covaraies and with the function terra::extract() we get the covariate value.\nIn this case we used as covariates:\n\nCattle distribution as number of cows per 10 square kilometer (Gilbert et al. 2018).\nPercent of tree cover from MODIS product 44B.\nRoad density from (Meijer et al. 2018).\nLand cover types from MODIS.\n\n\nCode# load rasters\nper_tree_cov &lt;- rast(\"C:/CodigoR/WCS-CameraTrap/raster/latlon/Veg_Cont_Fields_Yearly_250m_v61/Perc_TreeCov/MOD44B_Perc_TreeCov_2021_065.tif\")\nroad_den &lt;- rast(\"C:/CodigoR/WCS-CameraTrap/raster/latlon/RoadDensity/grip4_total_dens_m_km2.asc\")\n# elev &lt;- rast(\"D:/CORREGIDAS/elevation_z7.tif\")\nlandcov &lt;- rast(\"C:/CodigoR/WCS-CameraTrap/raster/latlon/LandCover_Type_Yearly_500m_v61/LC1/MCD12Q1_LC1_2021_001.tif\")\ncattle &lt;- rast(\"C:/CodigoR/WCS-CameraTrap/raster/latlon/Global cattle distribution/5_Ct_2010_Da.tif\")\n# river &lt;- st_read(\"F:/WCS-CameraTrap/shp/DensidadRios/MCD12Q1_LC1_2001_001_RECLASS_MASK_GRID_3600m_DensDrenSouthAmer.shp\")\n\n# get elevation map\n# elevation_detailed &lt;- rast(get_elev_raster(sites, z = 10, clip=\"bbox\", neg_to_na=TRUE))\n# elevation_detailed &lt;- get_elev_point (datos_sf, src=\"aws\", overwrite=TRUE)\n\n\n# extract covs using points and add to sites\n# covs &lt;- cbind(sites, terra::extract(SiteCovsRast, sites))\nper_tre &lt;- terra::extract(per_tree_cov, datos_sf)\nroads &lt;- terra::extract(road_den, datos_sf)\n# eleva &lt;- terra::extract(elevation_detailed, sites)\nland_cov &lt;- terra::extract(landcov, datos_sf)\ncattle_den &lt;- terra::extract(cattle, datos_sf)\n\n#### drop geometry\nsites &lt;- datos_sf %&gt;%\n  mutate(\n    lat = st_coordinates(.)[, 1],\n    lon = st_coordinates(.)[, 2]\n  ) %&gt;%\n  st_drop_geometry() |&gt;\n  as.data.frame()\n\n# remove decimals convert to factor\nsites$land_cover &lt;- factor(land_cov$MCD12Q1_LC1_2021_001)\n# sites$elevation &lt;-  eleva$file3be898018c3\nsites$per_tree_cov &lt;- per_tre$MOD44B_Perc_TreeCov_2021_065\n#  fix 200 isue\nind &lt;- which(sites$per_tree_cov == 200)\nsites$per_tree_cov[ind] &lt;- 0\n\n# sites$elevation &lt;- elevation_detailed$elevation\nsites$roads &lt;- roads$grip4_total_dens_m_km2\nsites$cattle &lt;- cattle_den[, 2]\n\n\n# write.csv(sites, \"C:/CodigoR/CameraTrapCesar/data/katios/stacked/site_covs.csv\")\n\n\nSelecting the first year 2021\nHere we use the function detectionHistory() from the package camtrapR to generate species detection histories that can be used later in occupancy analyses, with package unmarked and ubms. detectionHistory() generates detection histories in different formats, with adjustable occasion length and occasion start time and effort covariates. Notice we first need to get the camera operation dates using the function cameraOperation().\n\nCode# filter first year and make uniques\n\nCToperation_2021 &lt;- cam_deploy_image |&gt; # multi-season data\n  filter(samp_year == 2021) |&gt;\n  group_by(deployment_id) |&gt;\n  mutate(minStart = min(start_date), maxEnd = max(end_date)) |&gt;\n  distinct(longitude, latitude, minStart, maxEnd, samp_year) |&gt;\n  ungroup() |&gt;\n  as.data.frame()\n\n\n# Fix NA camera 16\nCToperation_2021[16, ] &lt;- c(\n  \"CT-K1-31-124\", -77.2787, 7.73855,\n  \"2021-10-10\", \"2021-12-31\", 2021\n)\n\n# make numeric sampling year\nCToperation_2021$samp_year &lt;- as.numeric(CToperation_2021$samp_year)\n\n# camera operation matrix for _2021\n# multi-season data. Season1\ncamop_2021 &lt;- cameraOperation(\n  CTtable = CToperation_2021, # Tabla de operación\n  stationCol = \"deployment_id\", # Columna que define la estación\n  setupCol = \"minStart\", # Columna fecha de colocación\n  retrievalCol = \"maxEnd\", # Columna fecha de retiro\n  sessionCol = \"samp_year\", # multi-season column\n  # hasProblems= T, # Hubo fallos de cámaras\n  dateFormat = \"%Y-%m-%d\"\n) # , #, # Formato de las fechas\n# cameraCol=\"CT\")\n# sessionCol= \"samp_year\")\n\n# Generar las historias de detección ---------------------------------------\n## remove plroblem species\n# ind &lt;- which(datos_PCF$Species==\"Marmosa sp.\")\n# datos_PCF &lt;- datos_PCF[-ind,]\n\n# filter y1\ndatay_2021 &lt;- cam_deploy_image |&gt; filter(samp_year == 2021) # |&gt;\n# filter(samp_year==2022)\n\nDetHist_list_2021 &lt;- lapply(unique(datay_2021$scientificName), FUN = function(x) {\n  detectionHistory(\n    recordTable = datay_2021, # Tabla de registros\n    camOp = camop_2021, # Matriz de operación de cámaras\n    stationCol = \"deployment_id\",\n    speciesCol = \"scientificName\",\n    recordDateTimeCol = \"timestamp\",\n    recordDateTimeFormat = \"%Y-%m-%d %H:%M:%S\",\n    species = x, # la función reemplaza x por cada una de las especies\n    occasionLength = 15, # Colapso de las historias a días\n    day1 = \"station\", # inicie en la fecha de cada survey\n    datesAsOccasionNames = FALSE,\n    includeEffort = TRUE,\n    scaleEffort = FALSE,\n    unmarkedMultFrameInput = TRUE,\n    timeZone = \"America/Bogota\"\n  )\n})\n\n# names\nnames(DetHist_list_2021) &lt;- unique(datay_2021$scientificName)\n\n# Finalmente creamos una lista nueva donde estén solo las historias de detección\nylist_2021 &lt;- lapply(DetHist_list_2021, FUN = function(x) x$detection_history)\n# y el esfuerzo\neffortlist_2021 &lt;- lapply(DetHist_list_2021, FUN = function(x) x$effort)\n\n### Danta, Jaguar\nwhich(names(ylist_2021) == \"Tapirus bairdii\")\n#&gt; integer(0)\nwhich(names(ylist_2021) == \"Panthera onca\")\n#&gt; [1] 5"
  },
  {
    "objectID": "posts/2025-06-01-spatial-single-species-occupancy/index.html#fitting-a-spatial-model-for-the-jaguar",
    "href": "posts/2025-06-01-spatial-single-species-occupancy/index.html#fitting-a-spatial-model-for-the-jaguar",
    "title": "Spatial, single-species occupancy model",
    "section": "Fitting a spatial model for the Jaguar",
    "text": "Fitting a spatial model for the Jaguar\nThis is a single species, single season spatial occupancy model.\nLoad the data\n\nCodejaguar &lt;- read.csv(\"C:/CodigoR/CameraTrapCesar/data/katios/stacked/y_jaguar_stacked.csv\") |&gt; filter(year == 2021)\n\n# remove one NA\njaguar &lt;- jaguar[-15, ]\n\n\nprojlatlon &lt;- \"+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0\"\n\ndatos_jaguar_sf &lt;- st_as_sf(\n  x = jaguar,\n  coords = c(\n    \"lon\",\n    \"lat\"\n  ),\n  crs = projlatlon\n)\n\n\nLook at the data\nNotice how the data was organized.\n\nCode\ndatatable(head(jaguar))\n\n\n\n\n\nNotice we collapsed the events to 15 days in the 2021 sampling season, and to 25 days in the 2022 sampling season, to end with 6 repeated observations in de matrix. In the matrix o1 to o6 are observations and e1 to e6 are sampling effort (observation-detection covariates). Land_cover, per_tree_cov and roads are site covariates (occupancy covariate).\nLoad and prepare data\nFirst we transform to UTM to get the coordinates in meters. Notice that the coordinates of the cameras are part of the data feeding the model. Next we assembled a list including the coordinates, the detection history data and the covariates.\n\nCode\n# 1. Data prep ------------------------------------------------------------\n\n# transform to utm\ndatos_sf_2021_utm &lt;- datos_jaguar_sf |&gt; # filter(samp_year==2021) |&gt;\n  st_transform(crs = 21891) #|&gt; left_join(jaguar)\n\njaguar_covs &lt;- jaguar[, c(8, 9, 16:19)]\n# jaguar_covs$year &lt;- as.factor(jaguar_covs$year)\n\n\njaguar.data &lt;- list()\njaguar.data$coords &lt;- st_coordinates(datos_sf_2021_utm)\njaguar.data$y &lt;- jaguar[, 2:7]\njaguar.data$occ.covs &lt;- jaguar_covs\njaguar.data$det.covs &lt;- list(effort = jaguar[10:15])\n\n\nNotice the structure of the data\nIt is a list! including:\n\ncoordinates\nspecies detections.\noccupancy covariates\ndetection covariates.\n\n\nCodeglimpse(jaguar.data)\n#&gt; List of 4\n#&gt;  $ coords  : num [1:31, 1:2] 2440383 2442762 2442674 2443361 2439344 ...\n#&gt;   ..- attr(*, \"dimnames\")=List of 2\n#&gt;   .. ..$ : NULL\n#&gt;   .. ..$ : chr [1:2] \"X\" \"Y\"\n#&gt;  $ y       :'data.frame':    31 obs. of  6 variables:\n#&gt;   ..$ o1: int [1:31] 1 1 0 0 0 0 0 1 0 0 ...\n#&gt;   ..$ o2: int [1:31] 1 0 0 0 0 0 0 0 0 0 ...\n#&gt;   ..$ o3: int [1:31] 0 1 0 0 0 0 0 0 0 0 ...\n#&gt;   ..$ o4: int [1:31] 0 0 0 0 0 0 0 0 0 0 ...\n#&gt;   ..$ o5: int [1:31] 0 0 0 0 0 0 0 0 0 0 ...\n#&gt;   ..$ o6: int [1:31] 0 0 0 0 0 0 0 0 0 0 ...\n#&gt;  $ occ.covs:'data.frame':    31 obs. of  6 variables:\n#&gt;   ..$ site        : int [1:31] 1 2 3 4 5 6 7 8 9 10 ...\n#&gt;   ..$ year        : int [1:31] 2021 2021 2021 2021 2021 2021 2021 2021 2021 2021 ...\n#&gt;   ..$ land_cover  : int [1:31] 2 2 2 2 2 2 2 2 2 2 ...\n#&gt;   ..$ per_tree_cov: int [1:31] 65 70 76 75 73 75 65 71 71 74 ...\n#&gt;   ..$ roads       : int [1:31] 152 152 152 152 152 152 152 152 152 152 ...\n#&gt;   ..$ cattle      : num [1:31] 0 0 0 0 0 0 0 0 0 0 ...\n#&gt;  $ det.covs:List of 1\n#&gt;   ..$ effort:'data.frame':   31 obs. of  6 variables:\n#&gt;   .. ..$ e1: num [1:31] 14.5 14.5 14.5 14.5 14.5 14.5 14.5 14.5 14.5 14.5 ...\n#&gt;   .. ..$ e2: int [1:31] 15 15 15 15 15 15 15 15 15 15 ...\n#&gt;   .. ..$ e3: int [1:31] 15 15 15 15 15 15 15 15 15 15 ...\n#&gt;   .. ..$ e4: int [1:31] 15 15 15 15 15 15 15 15 15 15 ...\n#&gt;   .. ..$ e5: int [1:31] 15 15 15 15 15 15 15 15 15 15 ...\n#&gt;   .. ..$ e6: int [1:31] 5 8 3 7 3 7 3 2 7 7 ...\n\n\nwith the names: coords, y, occ.covs, det.covs.\nFit models\nWe are going to fit a non spatial model and a spatial one, both using effort as detection covariate.\nNon-spatial, single-species occupancy model\n\nCode# 2. Model fitting --------------------------------------------------------\n# Fit a non-spatial, single-species occupancy model.\nout &lt;- PGOcc(\n  occ.formula = ~ scale(per_tree_cov) + scale(roads) +\n    scale(cattle),\n  det.formula = ~ scale(effort),\n  data = jaguar.data,\n  n.samples = 50000,\n  n.thin = 2,\n  n.burn = 5000,\n  n.chains = 3,\n  n.report = 500\n)\n#&gt; ----------------------------------------\n#&gt;  Preparing to run the model\n#&gt; ----------------------------------------\n#&gt; ----------------------------------------\n#&gt;  Model description\n#&gt; ----------------------------------------\n#&gt; Occupancy model with Polya-Gamma latent\n#&gt; variable fit with 31 sites.\n#&gt; \n#&gt; Samples per Chain: 50000 \n#&gt; Burn-in: 5000 \n#&gt; Thinning Rate: 2 \n#&gt; Number of Chains: 3 \n#&gt; Total Posterior Samples: 67500 \n#&gt; \n#&gt; Source compiled with OpenMP support and model fit using 1 thread(s).\n#&gt; \n#&gt; ----------------------------------------\n#&gt;  Chain 1\n#&gt; ----------------------------------------\n#&gt; Sampling ... \n#&gt; Sampled: 500 of 50000, 1.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 1000 of 50000, 2.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 1500 of 50000, 3.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 2000 of 50000, 4.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 2500 of 50000, 5.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 3000 of 50000, 6.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 3500 of 50000, 7.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 4000 of 50000, 8.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 4500 of 50000, 9.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 5000 of 50000, 10.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 5500 of 50000, 11.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 6000 of 50000, 12.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 6500 of 50000, 13.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 7000 of 50000, 14.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 7500 of 50000, 15.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 8000 of 50000, 16.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 8500 of 50000, 17.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 9000 of 50000, 18.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 9500 of 50000, 19.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 10000 of 50000, 20.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 10500 of 50000, 21.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 11000 of 50000, 22.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 11500 of 50000, 23.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 12000 of 50000, 24.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 12500 of 50000, 25.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 13000 of 50000, 26.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 13500 of 50000, 27.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 14000 of 50000, 28.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 14500 of 50000, 29.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 15000 of 50000, 30.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 15500 of 50000, 31.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 16000 of 50000, 32.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 16500 of 50000, 33.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 17000 of 50000, 34.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 17500 of 50000, 35.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 18000 of 50000, 36.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 18500 of 50000, 37.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 19000 of 50000, 38.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 19500 of 50000, 39.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 20000 of 50000, 40.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 20500 of 50000, 41.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 21000 of 50000, 42.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 21500 of 50000, 43.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 22000 of 50000, 44.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 22500 of 50000, 45.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 23000 of 50000, 46.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 23500 of 50000, 47.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 24000 of 50000, 48.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 24500 of 50000, 49.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 25000 of 50000, 50.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 25500 of 50000, 51.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 26000 of 50000, 52.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 26500 of 50000, 53.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 27000 of 50000, 54.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 27500 of 50000, 55.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 28000 of 50000, 56.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 28500 of 50000, 57.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 29000 of 50000, 58.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 29500 of 50000, 59.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 30000 of 50000, 60.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 30500 of 50000, 61.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 31000 of 50000, 62.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 31500 of 50000, 63.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 32000 of 50000, 64.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 32500 of 50000, 65.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 33000 of 50000, 66.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 33500 of 50000, 67.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 34000 of 50000, 68.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 34500 of 50000, 69.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 35000 of 50000, 70.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 35500 of 50000, 71.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 36000 of 50000, 72.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 36500 of 50000, 73.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 37000 of 50000, 74.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 37500 of 50000, 75.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 38000 of 50000, 76.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 38500 of 50000, 77.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 39000 of 50000, 78.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 39500 of 50000, 79.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 40000 of 50000, 80.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 40500 of 50000, 81.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 41000 of 50000, 82.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 41500 of 50000, 83.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 42000 of 50000, 84.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 42500 of 50000, 85.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 43000 of 50000, 86.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 43500 of 50000, 87.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 44000 of 50000, 88.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 44500 of 50000, 89.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 45000 of 50000, 90.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 45500 of 50000, 91.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 46000 of 50000, 92.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 46500 of 50000, 93.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 47000 of 50000, 94.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 47500 of 50000, 95.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 48000 of 50000, 96.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 48500 of 50000, 97.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 49000 of 50000, 98.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 49500 of 50000, 99.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 50000 of 50000, 100.00%\n#&gt; ----------------------------------------\n#&gt;  Chain 2\n#&gt; ----------------------------------------\n#&gt; Sampling ... \n#&gt; Sampled: 500 of 50000, 1.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 1000 of 50000, 2.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 1500 of 50000, 3.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 2000 of 50000, 4.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 2500 of 50000, 5.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 3000 of 50000, 6.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 3500 of 50000, 7.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 4000 of 50000, 8.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 4500 of 50000, 9.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 5000 of 50000, 10.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 5500 of 50000, 11.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 6000 of 50000, 12.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 6500 of 50000, 13.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 7000 of 50000, 14.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 7500 of 50000, 15.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 8000 of 50000, 16.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 8500 of 50000, 17.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 9000 of 50000, 18.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 9500 of 50000, 19.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 10000 of 50000, 20.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 10500 of 50000, 21.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 11000 of 50000, 22.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 11500 of 50000, 23.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 12000 of 50000, 24.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 12500 of 50000, 25.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 13000 of 50000, 26.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 13500 of 50000, 27.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 14000 of 50000, 28.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 14500 of 50000, 29.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 15000 of 50000, 30.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 15500 of 50000, 31.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 16000 of 50000, 32.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 16500 of 50000, 33.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 17000 of 50000, 34.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 17500 of 50000, 35.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 18000 of 50000, 36.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 18500 of 50000, 37.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 19000 of 50000, 38.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 19500 of 50000, 39.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 20000 of 50000, 40.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 20500 of 50000, 41.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 21000 of 50000, 42.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 21500 of 50000, 43.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 22000 of 50000, 44.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 22500 of 50000, 45.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 23000 of 50000, 46.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 23500 of 50000, 47.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 24000 of 50000, 48.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 24500 of 50000, 49.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 25000 of 50000, 50.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 25500 of 50000, 51.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 26000 of 50000, 52.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 26500 of 50000, 53.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 27000 of 50000, 54.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 27500 of 50000, 55.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 28000 of 50000, 56.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 28500 of 50000, 57.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 29000 of 50000, 58.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 29500 of 50000, 59.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 30000 of 50000, 60.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 30500 of 50000, 61.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 31000 of 50000, 62.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 31500 of 50000, 63.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 32000 of 50000, 64.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 32500 of 50000, 65.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 33000 of 50000, 66.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 33500 of 50000, 67.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 34000 of 50000, 68.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 34500 of 50000, 69.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 35000 of 50000, 70.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 35500 of 50000, 71.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 36000 of 50000, 72.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 36500 of 50000, 73.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 37000 of 50000, 74.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 37500 of 50000, 75.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 38000 of 50000, 76.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 38500 of 50000, 77.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 39000 of 50000, 78.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 39500 of 50000, 79.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 40000 of 50000, 80.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 40500 of 50000, 81.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 41000 of 50000, 82.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 41500 of 50000, 83.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 42000 of 50000, 84.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 42500 of 50000, 85.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 43000 of 50000, 86.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 43500 of 50000, 87.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 44000 of 50000, 88.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 44500 of 50000, 89.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 45000 of 50000, 90.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 45500 of 50000, 91.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 46000 of 50000, 92.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 46500 of 50000, 93.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 47000 of 50000, 94.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 47500 of 50000, 95.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 48000 of 50000, 96.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 48500 of 50000, 97.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 49000 of 50000, 98.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 49500 of 50000, 99.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 50000 of 50000, 100.00%\n#&gt; ----------------------------------------\n#&gt;  Chain 3\n#&gt; ----------------------------------------\n#&gt; Sampling ... \n#&gt; Sampled: 500 of 50000, 1.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 1000 of 50000, 2.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 1500 of 50000, 3.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 2000 of 50000, 4.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 2500 of 50000, 5.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 3000 of 50000, 6.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 3500 of 50000, 7.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 4000 of 50000, 8.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 4500 of 50000, 9.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 5000 of 50000, 10.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 5500 of 50000, 11.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 6000 of 50000, 12.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 6500 of 50000, 13.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 7000 of 50000, 14.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 7500 of 50000, 15.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 8000 of 50000, 16.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 8500 of 50000, 17.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 9000 of 50000, 18.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 9500 of 50000, 19.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 10000 of 50000, 20.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 10500 of 50000, 21.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 11000 of 50000, 22.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 11500 of 50000, 23.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 12000 of 50000, 24.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 12500 of 50000, 25.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 13000 of 50000, 26.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 13500 of 50000, 27.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 14000 of 50000, 28.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 14500 of 50000, 29.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 15000 of 50000, 30.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 15500 of 50000, 31.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 16000 of 50000, 32.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 16500 of 50000, 33.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 17000 of 50000, 34.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 17500 of 50000, 35.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 18000 of 50000, 36.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 18500 of 50000, 37.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 19000 of 50000, 38.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 19500 of 50000, 39.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 20000 of 50000, 40.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 20500 of 50000, 41.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 21000 of 50000, 42.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 21500 of 50000, 43.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 22000 of 50000, 44.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 22500 of 50000, 45.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 23000 of 50000, 46.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 23500 of 50000, 47.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 24000 of 50000, 48.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 24500 of 50000, 49.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 25000 of 50000, 50.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 25500 of 50000, 51.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 26000 of 50000, 52.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 26500 of 50000, 53.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 27000 of 50000, 54.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 27500 of 50000, 55.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 28000 of 50000, 56.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 28500 of 50000, 57.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 29000 of 50000, 58.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 29500 of 50000, 59.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 30000 of 50000, 60.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 30500 of 50000, 61.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 31000 of 50000, 62.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 31500 of 50000, 63.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 32000 of 50000, 64.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 32500 of 50000, 65.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 33000 of 50000, 66.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 33500 of 50000, 67.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 34000 of 50000, 68.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 34500 of 50000, 69.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 35000 of 50000, 70.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 35500 of 50000, 71.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 36000 of 50000, 72.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 36500 of 50000, 73.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 37000 of 50000, 74.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 37500 of 50000, 75.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 38000 of 50000, 76.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 38500 of 50000, 77.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 39000 of 50000, 78.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 39500 of 50000, 79.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 40000 of 50000, 80.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 40500 of 50000, 81.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 41000 of 50000, 82.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 41500 of 50000, 83.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 42000 of 50000, 84.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 42500 of 50000, 85.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 43000 of 50000, 86.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 43500 of 50000, 87.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 44000 of 50000, 88.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 44500 of 50000, 89.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 45000 of 50000, 90.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 45500 of 50000, 91.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 46000 of 50000, 92.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 46500 of 50000, 93.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 47000 of 50000, 94.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 47500 of 50000, 95.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 48000 of 50000, 96.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 48500 of 50000, 97.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 49000 of 50000, 98.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 49500 of 50000, 99.00%\n#&gt; -------------------------------------------------\n#&gt; Sampled: 50000 of 50000, 100.00%\n\nsummary(out)\n#&gt; \n#&gt; Call:\n#&gt; PGOcc(occ.formula = ~scale(per_tree_cov) + scale(roads) + scale(cattle), \n#&gt;     det.formula = ~scale(effort), data = jaguar.data, n.samples = 50000, \n#&gt;     n.report = 500, n.burn = 5000, n.thin = 2, n.chains = 3)\n#&gt; \n#&gt; Samples per Chain: 50000\n#&gt; Burn-in: 5000\n#&gt; Thinning Rate: 2\n#&gt; Number of Chains: 3\n#&gt; Total Posterior Samples: 67500\n#&gt; Run Time (min): 0.2238\n#&gt; \n#&gt; Occurrence (logit scale): \n#&gt;                        Mean     SD    2.5%     50%  97.5%   Rhat   ESS\n#&gt; (Intercept)         -0.2601 1.2395 -2.2195 -0.4477 2.5703 1.0012  5492\n#&gt; scale(per_tree_cov) -0.8895 0.9682 -3.1281 -0.7623 0.7598 1.0009 12223\n#&gt; scale(roads)         0.1180 0.8483 -1.5979  0.1150 1.8477 1.0014 14145\n#&gt; scale(cattle)       -1.0820 1.2777 -3.6533 -1.0596 1.7270 1.0019 10147\n#&gt; \n#&gt; Detection (logit scale): \n#&gt;                  Mean     SD    2.5%     50%   97.5%   Rhat   ESS\n#&gt; (Intercept)   -2.2076 0.6115 -3.3766 -2.2230 -0.9931 1.0003  7859\n#&gt; scale(effort)  0.9249 0.6883 -0.1276  0.8225  2.5420 1.0004 16372\n\n\nSpatial, single-species occupancy model\n\nCode# Fit a spatial, single-species occupancy model.\nout.sp &lt;- spPGOcc(\n  occ.formula = ~ scale(per_tree_cov) + scale(roads) +\n    scale(cattle),\n  det.formula = ~ scale(effort),\n  data = jaguar.data,\n  n.neighbors = 8,\n  n.batch = 1000,\n  batch.length = 15,\n  # n.samples = 105000,\n  n.thin = 2,\n  n.burn = 5000,\n  n.chains = 3,\n  n.report = 500\n)\n#&gt; ----------------------------------------\n#&gt;  Preparing to run the model\n#&gt; ----------------------------------------\n#&gt; ----------------------------------------\n#&gt;  Building the neighbor list\n#&gt; ----------------------------------------\n#&gt; ----------------------------------------\n#&gt; Building the neighbors of neighbors list\n#&gt; ----------------------------------------\n#&gt; ----------------------------------------\n#&gt;  Model description\n#&gt; ----------------------------------------\n#&gt; NNGP Spatial Occupancy model with Polya-Gamma latent\n#&gt; variable fit with 31 sites.\n#&gt; \n#&gt; Samples per chain: 15000 (1000 batches of length 15)\n#&gt; Burn-in: 5000 \n#&gt; Thinning Rate: 2 \n#&gt; Number of Chains: 3 \n#&gt; Total Posterior Samples: 15000 \n#&gt; \n#&gt; Using the exponential spatial correlation model.\n#&gt; \n#&gt; Using 8 nearest neighbors.\n#&gt; \n#&gt; Source compiled with OpenMP support and model fit using 1 thread(s).\n#&gt; \n#&gt; Adaptive Metropolis with target acceptance rate: 43.0\n#&gt; ----------------------------------------\n#&gt;  Chain 1\n#&gt; ----------------------------------------\n#&gt; Sampling ... \n#&gt; Batch: 500 of 1000, 50.00%\n#&gt;  Parameter   Acceptance  Tuning\n#&gt;  phi     60.0        3.15819\n#&gt; -------------------------------------------------\n#&gt; Batch: 1000 of 1000, 100.00%\n#&gt; ----------------------------------------\n#&gt;  Chain 2\n#&gt; ----------------------------------------\n#&gt; Sampling ... \n#&gt; Batch: 500 of 1000, 50.00%\n#&gt;  Parameter   Acceptance  Tuning\n#&gt;  phi     26.7        3.03436\n#&gt; -------------------------------------------------\n#&gt; Batch: 1000 of 1000, 100.00%\n#&gt; ----------------------------------------\n#&gt;  Chain 3\n#&gt; ----------------------------------------\n#&gt; Sampling ... \n#&gt; Batch: 500 of 1000, 50.00%\n#&gt;  Parameter   Acceptance  Tuning\n#&gt;  phi     46.7        3.70617\n#&gt; -------------------------------------------------\n#&gt; Batch: 1000 of 1000, 100.00%\n\nsummary(out.sp)\n#&gt; \n#&gt; Call:\n#&gt; spPGOcc(occ.formula = ~scale(per_tree_cov) + scale(roads) + scale(cattle), \n#&gt;     det.formula = ~scale(effort), data = jaguar.data, n.neighbors = 8, \n#&gt;     n.batch = 1000, batch.length = 15, n.report = 500, n.burn = 5000, \n#&gt;     n.thin = 2, n.chains = 3)\n#&gt; \n#&gt; Samples per Chain: 15000\n#&gt; Burn-in: 5000\n#&gt; Thinning Rate: 2\n#&gt; Number of Chains: 3\n#&gt; Total Posterior Samples: 15000\n#&gt; Run Time (min): 0.194\n#&gt; \n#&gt; Occurrence (logit scale): \n#&gt;                        Mean     SD    2.5%     50%  97.5%   Rhat  ESS\n#&gt; (Intercept)         -0.3927 1.2605 -2.4270 -0.5666 2.5384 1.0028 1109\n#&gt; scale(per_tree_cov) -0.9225 1.0080 -3.2406 -0.8023 0.7861 1.0022 2599\n#&gt; scale(roads)         0.1264 0.8738 -1.6345  0.1375 1.8836 1.0004 3502\n#&gt; scale(cattle)       -1.0953 1.2401 -3.5987 -1.0687 1.4932 1.0062 2539\n#&gt; \n#&gt; Detection (logit scale): \n#&gt;                  Mean     SD    2.5%     50%   97.5%   Rhat  ESS\n#&gt; (Intercept)   -2.1725 0.6023 -3.3286 -2.1799 -0.9827 1.0041 1439\n#&gt; scale(effort)  0.9243 0.6913 -0.1378  0.8183  2.5489 1.0032 3629\n#&gt; \n#&gt; Spatial Covariance: \n#&gt;            Mean     SD   2.5%    50%  97.5%   Rhat  ESS\n#&gt; sigma.sq 1.1516 1.9055 0.1845 0.6349 5.4347 1.0985  790\n#&gt; phi      0.0203 0.0112 0.0015 0.0205 0.0388 1.0021 3394\n\n\nModel validation\nWe perform a posterior predictive check to assess model fit.\n\nCode# 3. Model validation -----------------------------------------------------\n# Perform a posterior predictive check to assess model fit. \nppc.out &lt;- ppcOcc(out, fit.stat = 'freeman-tukey', group = 1)\nppc.out.sp &lt;- ppcOcc(out.sp, fit.stat = 'freeman-tukey', group = 1)\n# Calculate a Bayesian p-value as a simple measure of Goodness of Fit.\n# Bayesian p-values between 0.1 and 0.9 indicate adequate model fit. \nsummary(ppc.out)\n#&gt; \n#&gt; Call:\n#&gt; ppcOcc(object = out, fit.stat = \"freeman-tukey\", group = 1)\n#&gt; \n#&gt; Samples per Chain: 50000\n#&gt; Burn-in: 5000\n#&gt; Thinning Rate: 2\n#&gt; Number of Chains: 3\n#&gt; Total Posterior Samples: 67500\n#&gt; \n#&gt; Bayesian p-value:  0.269 \n#&gt; Fit statistic:  freeman-tukey\nsummary(ppc.out.sp)\n#&gt; \n#&gt; Call:\n#&gt; ppcOcc(object = out.sp, fit.stat = \"freeman-tukey\", group = 1)\n#&gt; \n#&gt; Samples per Chain: 15000\n#&gt; Burn-in: 5000\n#&gt; Thinning Rate: 2\n#&gt; Number of Chains: 3\n#&gt; Total Posterior Samples: 15000\n#&gt; \n#&gt; Bayesian p-value:  0.2819 \n#&gt; Fit statistic:  freeman-tukey\n\n# ## see model selection as a table\n# datatable( \n#   round(modSel(mods), 3)\n#   )\n\n\nModel comparison\nLets compare the two models, the non spatial and the spatial one.\n\nCode# 4. Model comparison -----------------------------------------------------\n# Compute Widely Applicable Information Criterion (WAIC)\n# Lower values indicate better model fit. \nwaicOcc(out)\n#&gt;       elpd         pD       WAIC \n#&gt; -32.514838   3.585918  72.201512\nwaicOcc(out.sp)\n#&gt;       elpd         pD       WAIC \n#&gt; -31.251946   4.447797  71.399485\n\n\nlook at the Widely Applicable Information Criterion (WAIC). Lower values indicate better model fit!\n\nBest model is out.sp (out.sp) which deals with spatial autocorrelation.\n\nLook at the traceplots\nFor the spatial model.\n\nCodeMCMCtrace(out.sp$beta.samples, params = c(\"scale(per_tree_cov)\"), type = 'trace', pdf = F, Rhat = TRUE, n.eff = TRUE)\n\n\n\n\n\n\nCode\nMCMCtrace(out.sp$beta.samples, type = 'both', pdf = F, Rhat = FALSE, n.eff = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n### density for per_tree_cov\nMCMCtrace(out.sp$beta.samples, params = c(\"scale(per_tree_cov)\"), ISB = FALSE, pdf = F, exact = TRUE, post_zm = TRUE, type = 'density', Rhat = TRUE, n.eff = TRUE, ind = TRUE)\n\n\n\n\n\n\n\nUsing bayesplot\n\nCodecolor_scheme_set(\"mix-blue-red\")\nmcmc_trace(out.sp$beta.samples,  \n           facet_args = list(ncol = 1, strip.position = \"left\"))\n\n\n\n\n\n\n\nPosterior summaries\n\nCode# 5. Posterior summaries --------------------------------------------------\n# Concise summary of main parameter estimates\nsummary(out.sp)\n#&gt; \n#&gt; Call:\n#&gt; spPGOcc(occ.formula = ~scale(per_tree_cov) + scale(roads) + scale(cattle), \n#&gt;     det.formula = ~scale(effort), data = jaguar.data, n.neighbors = 8, \n#&gt;     n.batch = 1000, batch.length = 15, n.report = 500, n.burn = 5000, \n#&gt;     n.thin = 2, n.chains = 3)\n#&gt; \n#&gt; Samples per Chain: 15000\n#&gt; Burn-in: 5000\n#&gt; Thinning Rate: 2\n#&gt; Number of Chains: 3\n#&gt; Total Posterior Samples: 15000\n#&gt; Run Time (min): 0.194\n#&gt; \n#&gt; Occurrence (logit scale): \n#&gt;                        Mean     SD    2.5%     50%  97.5%   Rhat  ESS\n#&gt; (Intercept)         -0.3927 1.2605 -2.4270 -0.5666 2.5384 1.0028 1109\n#&gt; scale(per_tree_cov) -0.9225 1.0080 -3.2406 -0.8023 0.7861 1.0022 2599\n#&gt; scale(roads)         0.1264 0.8738 -1.6345  0.1375 1.8836 1.0004 3502\n#&gt; scale(cattle)       -1.0953 1.2401 -3.5987 -1.0687 1.4932 1.0062 2539\n#&gt; \n#&gt; Detection (logit scale): \n#&gt;                  Mean     SD    2.5%     50%   97.5%   Rhat  ESS\n#&gt; (Intercept)   -2.1725 0.6023 -3.3286 -2.1799 -0.9827 1.0041 1439\n#&gt; scale(effort)  0.9243 0.6913 -0.1378  0.8183  2.5489 1.0032 3629\n#&gt; \n#&gt; Spatial Covariance: \n#&gt;            Mean     SD   2.5%    50%  97.5%   Rhat  ESS\n#&gt; sigma.sq 1.1516 1.9055 0.1845 0.6349 5.4347 1.0985  790\n#&gt; phi      0.0203 0.0112 0.0015 0.0205 0.0388 1.0021 3394\n# Take a look at objects in resulting object\nnames(out.sp)\n#&gt;  [1] \"rhat\"           \"beta.samples\"   \"alpha.samples\"  \"theta.samples\" \n#&gt;  [5] \"coords\"         \"z.samples\"      \"X\"              \"X.re\"          \n#&gt;  [9] \"w.samples\"      \"psi.samples\"    \"like.samples\"   \"X.p\"           \n#&gt; [13] \"X.p.re\"         \"y\"              \"ESS\"            \"call\"          \n#&gt; [17] \"n.samples\"      \"n.neighbors\"    \"cov.model.indx\" \"type\"          \n#&gt; [21] \"n.post\"         \"n.thin\"         \"n.burn\"         \"n.chains\"      \n#&gt; [25] \"pRE\"            \"psiRE\"          \"run.time\"\nstr(out.sp$beta.samples)\n#&gt;  'mcmc' num [1:15000, 1:4] 0.255 0.957 2.696 1.607 0.621 ...\n#&gt;  - attr(*, \"mcpar\")= num [1:3] 1 15000 1\n#&gt;  - attr(*, \"dimnames\")=List of 2\n#&gt;   ..$ : NULL\n#&gt;   ..$ : chr [1:4] \"(Intercept)\" \"scale(per_tree_cov)\" \"scale(roads)\" \"scale(cattle)\"\n# Probability the effect of tree cover on occupancy is positive\nmean(out.sp$beta.samples[, 1] &gt; 0)\n#&gt; [1] 0.3351333\n\n# Create simple plot summaries using MCMCvis package.\n# Detection covariate effects --------- \nMCMCplot(out.sp$alpha.samples, ref_ovl = TRUE, ci = c(50, 95))\n\n\n\n\n\n\nCode\n# Occupancy covariate effects ---------\nMCMCplot(out.sp$beta.samples, ref_ovl = TRUE, ci = c(50, 95))\n\n\n\n\n\n\n\nAnother way using bayesplot\n\nCodeout.sp$beta.samples |&gt;  \n  mcmc_intervals()\n\n\n\n\n\n\nCode  yaxis_text() \n#&gt; &lt;theme&gt; List of 1\n#&gt;  $ axis.text.y: &lt;ggplot2::element_text&gt;\n#&gt;   ..@ family       : NULL\n#&gt;   ..@ face         : NULL\n#&gt;   ..@ italic       : chr NA\n#&gt;   ..@ fontweight   : num NA\n#&gt;   ..@ fontwidth    : num NA\n#&gt;   ..@ colour       : NULL\n#&gt;   ..@ size         : NULL\n#&gt;   ..@ hjust        : NULL\n#&gt;   ..@ vjust        : NULL\n#&gt;   ..@ angle        : NULL\n#&gt;   ..@ lineheight   : NULL\n#&gt;   ..@ margin       : NULL\n#&gt;   ..@ debug        : NULL\n#&gt;   ..@ inherit.blank: logi FALSE\n#&gt;  @ complete: logi FALSE\n#&gt;  @ validate: logi TRUE\n\n\nLook at rhat\n\nCodeprint(out.sp$rhat)\n#&gt; $beta\n#&gt; [1] 1.002806 1.002214 1.000402 1.006207\n#&gt; \n#&gt; $alpha\n#&gt; [1] 1.004107 1.003228\n#&gt; \n#&gt; $theta\n#&gt; [1] 1.098540 1.002097\n\n\nAll rhat values should, in theory, be less than 1.1, if the sampler has values of or greater than 1.1, it is likely that it was not particularly efficient or effective.\nAnother way is plotting the rhats for betas\n\nCode\nout.sp$rhat[[1]] |&gt;  \n  mcmc_rhat() +\n  yaxis_text()"
  },
  {
    "objectID": "posts/2025-06-01-spatial-single-species-occupancy/index.html#prediction",
    "href": "posts/2025-06-01-spatial-single-species-occupancy/index.html#prediction",
    "title": "Spatial, single-species occupancy model",
    "section": "Prediction",
    "text": "Prediction\nPredict occupancy along a gradient of per_tree_cov. The prediction takes in to account the spatial autocorrelation.\n\nCode# 6. Prediction -----------------------------------------------------------\n# Predict occupancy along a gradient of forest cover.\n# Create a set of values across the range of observed forest values\nforest.pred.vals &lt;- seq(min(jaguar.data$occ.covs$per_tree_cov),\n  max(jaguar.data$occ.covs$per_tree_cov),\n  length.out = 100\n)\n\n# Scale predicted values by mean and standard deviation used to fit the model\nforest.pred.vals.scale &lt;- (forest.pred.vals - mean(jaguar.data$occ.covs$per_tree_cov)) / sd(jaguar.data$occ.covs$per_tree_cov)\n\n# Predict occupancy across forest values at mean values of all other variables\npred.df &lt;- as.matrix(data.frame(intercept = 1, forest = forest.pred.vals.scale, roads = 0, cattle = 0))\n\nout.pred &lt;- predict(out, pred.df)\nstr(out.pred)\n#&gt; List of 3\n#&gt;  $ psi.0.samples: 'mcmc' num [1:67500, 1:100] 0.993 0.999 0.858 0.856 0.865 ...\n#&gt;   ..- attr(*, \"mcpar\")= num [1:3] 1 67500 1\n#&gt;  $ z.0.samples  : 'mcmc' int [1:67500, 1:100] 1 1 1 1 0 1 0 1 0 0 ...\n#&gt;   ..- attr(*, \"mcpar\")= num [1:3] 1 67500 1\n#&gt;  $ call         : language predict.PGOcc(object = out, X.0 = pred.df)\n#&gt;  - attr(*, \"class\")= chr \"predict.PGOcc\"\npsi.0.quants &lt;- apply(out.pred$psi.0.samples, 2, quantile,\n  prob = c(0.025, 0.5, 0.975)\n)\npsi.plot.dat &lt;- data.frame(\n  psi.med = psi.0.quants[2, ],\n  psi.low = psi.0.quants[1, ],\n  psi.high = psi.0.quants[3, ],\n  forest = forest.pred.vals\n)\nggplot(psi.plot.dat, aes(x = forest, y = psi.med)) +\n  geom_ribbon(aes(ymin = psi.low, ymax = psi.high), fill = \"grey70\") +\n  geom_line() +\n  theme_bw() +\n  scale_y_continuous(limits = c(0, 1)) +\n  labs(x = \"Forest (% tree cover)\", y = \"Occupancy Probability\")\n\n\n\n\n\n\n\nSee the huge errors…. well it is just for illustrative purposes…"
  },
  {
    "objectID": "posts/2025-06-01-spatial-single-species-occupancy/index.html#package-citation",
    "href": "posts/2025-06-01-spatial-single-species-occupancy/index.html#package-citation",
    "title": "Spatial, single-species occupancy model",
    "section": "Package Citation",
    "text": "Package Citation\n\nCodepkgs &lt;- cite_packages(output = \"paragraph\", out.dir = \".\") #knitr::kable(pkgs)\npkgs\n\nWe used R v. 4.4.2 (R Core Team 2024) and the following R packages: bayesplot v. 1.14.0 (Gabry et al. 2019; Gabry and Mahr 2025), camtrapR v. 3.0.0 (Niedballa et al. 2016), devtools v. 2.4.6 (Wickham et al. 2025), DT v. 0.34.0 (Xie et al. 2025), elevatr v. 0.99.0 (Hollister et al. 2023), kableExtra v. 1.4.0 (Zhu 2024), mapview v. 2.11.4 (Appelhans et al. 2025), MCMCvis v. 0.16.3 (Youngflesh 2018), patchwork v. 1.3.2 (Pedersen 2025), quarto v. 1.5.1 (Allaire and Dervieux 2025), rmarkdown v. 2.30 (Xie, Allaire, and Grolemund 2018; Xie, Dervieux, and Riederer 2020; Allaire et al. 2025), sf v. 1.0.21 (Pebesma 2018; Pebesma and Bivand 2023), spOccupancy v. 0.8.0 (Doser et al. 2022, 2024; Doser, Finley, and Banerjee 2023), styler v. 1.10.3 (Müller and Walthert 2024), terra v. 1.8.70 (Hijmans 2025), tidyverse v. 2.0.0 (Wickham et al. 2019)."
  },
  {
    "objectID": "posts/2025-06-01-spatial-single-species-occupancy/index.html#session-info",
    "href": "posts/2025-06-01-spatial-single-species-occupancy/index.html#session-info",
    "title": "Spatial, single-species occupancy model",
    "section": "Session info",
    "text": "Session info\n\nSession info\n\n#&gt; ─ Session info ───────────────────────────────────────────────────────────────────────────────────────────────────────\n#&gt;  setting  value\n#&gt;  version  R version 4.4.2 (2024-10-31 ucrt)\n#&gt;  os       Windows 10 x64 (build 19045)\n#&gt;  system   x86_64, mingw32\n#&gt;  ui       RTerm\n#&gt;  language (EN)\n#&gt;  collate  Spanish_Colombia.utf8\n#&gt;  ctype    Spanish_Colombia.utf8\n#&gt;  tz       America/Bogota\n#&gt;  date     2025-11-08\n#&gt;  pandoc   3.6.3 @ C:/Program Files/RStudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n#&gt;  quarto   NA @ C:\\\\Users\\\\usuario\\\\AppData\\\\Local\\\\Programs\\\\Quarto\\\\bin\\\\quarto.exe\n#&gt; \n#&gt; ─ Packages ───────────────────────────────────────────────────────────────────────────────────────────────────────────\n#&gt;  ! package           * version  date (UTC) lib source\n#&gt;    abind               1.4-8    2024-09-12 [1] CRAN (R 4.4.1)\n#&gt;  D archive             1.1.12   2025-03-20 [1] CRAN (R 4.4.3)\n#&gt;    backports           1.5.0    2024-05-23 [1] CRAN (R 4.4.0)\n#&gt;    base64enc           0.1-3    2015-07-28 [1] CRAN (R 4.4.0)\n#&gt;    bayesplot         * 1.14.0   2025-08-31 [1] CRAN (R 4.4.3)\n#&gt;    bit                 4.5.0.1  2024-12-03 [1] CRAN (R 4.4.2)\n#&gt;    bit64               4.5.2    2024-09-22 [1] CRAN (R 4.4.2)\n#&gt;    boot                1.3-31   2024-08-28 [2] CRAN (R 4.4.2)\n#&gt;    brew                1.0-10   2023-12-16 [1] CRAN (R 4.4.2)\n#&gt;    bslib               0.9.0    2025-01-30 [1] CRAN (R 4.4.3)\n#&gt;    cachem              1.1.0    2024-05-16 [1] CRAN (R 4.4.2)\n#&gt;    camtrapR          * 3.0.0    2025-09-28 [1] CRAN (R 4.4.3)\n#&gt;    cellranger          1.1.0    2016-07-27 [1] CRAN (R 4.4.2)\n#&gt;    checkmate           2.3.2    2024-07-29 [1] CRAN (R 4.4.2)\n#&gt;    class               7.3-22   2023-05-03 [2] CRAN (R 4.4.2)\n#&gt;    classInt            0.4-11   2025-01-08 [1] CRAN (R 4.4.3)\n#&gt;    cli                 3.6.5    2025-04-23 [1] CRAN (R 4.4.3)\n#&gt;    coda                0.19-4.1 2024-01-31 [1] CRAN (R 4.4.2)\n#&gt;    codetools           0.2-20   2024-03-31 [2] CRAN (R 4.4.2)\n#&gt;    colorspace          2.1-1    2024-07-26 [1] CRAN (R 4.4.2)\n#&gt;    crayon              1.5.3    2024-06-20 [1] CRAN (R 4.4.2)\n#&gt;    crosstalk           1.2.1    2023-11-23 [1] CRAN (R 4.4.2)\n#&gt;    data.table          1.17.8   2025-07-10 [1] CRAN (R 4.4.3)\n#&gt;    DBI                 1.2.3    2024-06-02 [1] CRAN (R 4.4.2)\n#&gt;    devtools            2.4.6    2025-10-03 [1] CRAN (R 4.4.3)\n#&gt;    dichromat           2.0-0.1  2022-05-02 [1] CRAN (R 4.4.0)\n#&gt;    digest              0.6.37   2024-08-19 [1] CRAN (R 4.4.2)\n#&gt;    distributional      0.5.0    2024-09-17 [1] CRAN (R 4.4.2)\n#&gt;    doParallel          1.0.17   2022-02-07 [1] CRAN (R 4.4.2)\n#&gt;    dplyr             * 1.1.4    2023-11-17 [1] CRAN (R 4.4.2)\n#&gt;    DT                * 0.34.0   2025-09-02 [1] CRAN (R 4.4.3)\n#&gt;    e1071               1.7-16   2024-09-16 [1] CRAN (R 4.4.2)\n#&gt;    elevatr           * 0.99.0   2023-09-12 [1] CRAN (R 4.4.2)\n#&gt;    ellipsis            0.3.2    2021-04-29 [1] CRAN (R 4.4.2)\n#&gt;    evaluate            1.0.4    2025-06-18 [1] CRAN (R 4.4.3)\n#&gt;    farver              2.1.2    2024-05-13 [1] CRAN (R 4.4.2)\n#&gt;    fastmap             1.2.0    2024-05-15 [1] CRAN (R 4.4.2)\n#&gt;    forcats           * 1.0.0    2023-01-29 [1] CRAN (R 4.4.2)\n#&gt;    foreach             1.5.2    2022-02-02 [1] CRAN (R 4.4.2)\n#&gt;    fs                  1.6.6    2025-04-12 [1] CRAN (R 4.4.3)\n#&gt;    generics            0.1.3    2022-07-05 [1] CRAN (R 4.4.2)\n#&gt;    ggplot2           * 4.0.0    2025-09-11 [1] CRAN (R 4.4.3)\n#&gt;    glue                1.8.0    2024-09-30 [1] CRAN (R 4.4.2)\n#&gt;    grateful          * 0.3.0    2025-09-04 [1] CRAN (R 4.4.3)\n#&gt;    gtable              0.3.6    2024-10-25 [1] CRAN (R 4.4.2)\n#&gt;    hms                 1.1.3    2023-03-21 [1] CRAN (R 4.4.2)\n#&gt;    htmltools           0.5.8.1  2024-04-04 [1] CRAN (R 4.4.2)\n#&gt;    htmlwidgets         1.6.4    2023-12-06 [1] CRAN (R 4.4.2)\n#&gt;    httpuv              1.6.16   2025-04-16 [1] CRAN (R 4.4.3)\n#&gt;    iterators           1.0.14   2022-02-05 [1] CRAN (R 4.4.2)\n#&gt;    jquerylib           0.1.4    2021-04-26 [1] CRAN (R 4.4.2)\n#&gt;    jsonlite            2.0.0    2025-03-27 [1] CRAN (R 4.4.3)\n#&gt;    kableExtra        * 1.4.0    2024-01-24 [1] CRAN (R 4.4.2)\n#&gt;    KernSmooth          2.23-24  2024-05-17 [2] CRAN (R 4.4.2)\n#&gt;    knitr               1.50     2025-03-16 [1] CRAN (R 4.4.3)\n#&gt;    labeling            0.4.3    2023-08-29 [1] CRAN (R 4.4.0)\n#&gt;    later               1.4.2    2025-04-08 [1] CRAN (R 4.4.3)\n#&gt;    lattice             0.22-6   2024-03-20 [2] CRAN (R 4.4.2)\n#&gt;    leafem              0.2.4    2025-05-01 [1] CRAN (R 4.4.3)\n#&gt;    leaflet             2.2.3    2025-09-04 [1] CRAN (R 4.4.3)\n#&gt;    leaflet.providers   2.0.0    2023-10-17 [1] CRAN (R 4.4.2)\n#&gt;    leafpop             0.1.0    2021-05-22 [1] CRAN (R 4.4.2)\n#&gt;    lifecycle           1.0.4    2023-11-07 [1] CRAN (R 4.4.2)\n#&gt;    lme4                1.1-35.5 2024-07-03 [1] CRAN (R 4.4.2)\n#&gt;    lubridate         * 1.9.4    2024-12-08 [1] CRAN (R 4.4.2)\n#&gt;    magrittr            2.0.3    2022-03-30 [1] CRAN (R 4.4.2)\n#&gt;    mapview           * 2.11.4   2025-09-08 [1] CRAN (R 4.4.3)\n#&gt;    MASS                7.3-61   2024-06-13 [2] CRAN (R 4.4.2)\n#&gt;    Matrix              1.7-1    2024-10-18 [2] CRAN (R 4.4.2)\n#&gt;    MCMCvis           * 0.16.3   2023-10-17 [1] CRAN (R 4.4.3)\n#&gt;    memoise             2.0.1    2021-11-26 [1] CRAN (R 4.4.2)\n#&gt;    mgcv                1.9-1    2023-12-21 [2] CRAN (R 4.4.2)\n#&gt;    mime                0.13     2025-03-17 [1] CRAN (R 4.4.3)\n#&gt;    minqa               1.2.8    2024-08-17 [1] CRAN (R 4.4.2)\n#&gt;    mvtnorm             1.3-2    2024-11-04 [1] CRAN (R 4.4.2)\n#&gt;    nlme                3.1-166  2024-08-14 [2] CRAN (R 4.4.2)\n#&gt;    nloptr              2.1.1    2024-06-25 [1] CRAN (R 4.4.2)\n#&gt;    patchwork         * 1.3.2    2025-08-25 [1] CRAN (R 4.4.3)\n#&gt;    pillar              1.11.1   2025-09-17 [1] CRAN (R 4.4.2)\n#&gt;    pkgbuild            1.4.8    2025-05-26 [1] CRAN (R 4.4.3)\n#&gt;    pkgconfig           2.0.3    2019-09-22 [1] CRAN (R 4.4.2)\n#&gt;    pkgload             1.4.1    2025-09-23 [1] CRAN (R 4.4.3)\n#&gt;    plyr                1.8.9    2023-10-02 [1] CRAN (R 4.4.2)\n#&gt;    png                 0.1-8    2022-11-29 [1] CRAN (R 4.4.0)\n#&gt;    posterior           1.6.1    2025-03-12 [1] Github (jgabry/posterior@307260e)\n#&gt;    processx            3.8.4    2024-03-16 [1] CRAN (R 4.4.2)\n#&gt;    progressr           0.15.0   2024-10-29 [1] CRAN (R 4.4.2)\n#&gt;    promises            1.3.3    2025-05-29 [1] CRAN (R 4.4.3)\n#&gt;    proxy               0.4-27   2022-06-09 [1] CRAN (R 4.4.2)\n#&gt;    ps                  1.8.1    2024-10-28 [1] CRAN (R 4.4.2)\n#&gt;    purrr             * 1.1.0    2025-07-10 [1] CRAN (R 4.4.3)\n#&gt;    quarto            * 1.5.1    2025-09-04 [1] CRAN (R 4.4.3)\n#&gt;    R.cache             0.16.0   2022-07-21 [1] CRAN (R 4.4.2)\n#&gt;    R.methodsS3         1.8.2    2022-06-13 [1] CRAN (R 4.4.0)\n#&gt;    R.oo                1.27.0   2024-11-01 [1] CRAN (R 4.4.1)\n#&gt;    R.utils             2.13.0   2025-02-24 [1] CRAN (R 4.4.3)\n#&gt;    R6                  2.6.1    2025-02-15 [1] CRAN (R 4.4.2)\n#&gt;    RANN                2.6.2    2024-08-25 [1] CRAN (R 4.4.3)\n#&gt;    raster              3.6-32   2025-03-28 [1] CRAN (R 4.4.3)\n#&gt;    RColorBrewer        1.1-3    2022-04-03 [1] CRAN (R 4.4.0)\n#&gt;    Rcpp                1.1.0    2025-07-02 [1] CRAN (R 4.4.3)\n#&gt;    RcppNumerical       0.6-0    2023-09-06 [1] CRAN (R 4.4.2)\n#&gt;  D RcppParallel        5.1.9    2024-08-19 [1] CRAN (R 4.4.2)\n#&gt;    readr             * 2.1.5    2024-01-10 [1] CRAN (R 4.4.2)\n#&gt;    readxl            * 1.4.3    2023-07-06 [1] CRAN (R 4.4.2)\n#&gt;    remotes             2.5.0    2024-03-17 [1] CRAN (R 4.4.3)\n#&gt;    renv                1.0.11   2024-10-12 [1] CRAN (R 4.4.2)\n#&gt;    reshape2            1.4.4    2020-04-09 [1] CRAN (R 4.4.2)\n#&gt;    rlang               1.1.6    2025-04-11 [1] CRAN (R 4.4.3)\n#&gt;    rmarkdown           2.30     2025-09-28 [1] CRAN (R 4.4.3)\n#&gt;    rstudioapi          0.17.1   2024-10-22 [1] CRAN (R 4.4.2)\n#&gt;    S7                  0.2.0    2024-11-07 [1] CRAN (R 4.4.3)\n#&gt;    sass                0.4.10   2025-04-11 [1] CRAN (R 4.4.3)\n#&gt;    satellite           1.0.5    2024-02-10 [1] CRAN (R 4.4.2)\n#&gt;    scales              1.4.0    2025-04-24 [1] CRAN (R 4.4.3)\n#&gt;    secr                5.1.0    2024-11-04 [1] CRAN (R 4.4.2)\n#&gt;    sessioninfo         1.2.3    2025-02-05 [1] CRAN (R 4.4.3)\n#&gt;    sf                * 1.0-21   2025-05-15 [1] CRAN (R 4.4.3)\n#&gt;    shiny               1.9.1    2024-08-01 [1] CRAN (R 4.4.2)\n#&gt;    shinyBS             0.61.1   2022-04-17 [1] CRAN (R 4.4.3)\n#&gt;    shinydashboard      0.7.3    2025-04-21 [1] CRAN (R 4.4.3)\n#&gt;    sp                  2.2-0    2025-02-01 [1] CRAN (R 4.4.3)\n#&gt;    spAbundance         0.2.1    2024-10-05 [1] CRAN (R 4.4.3)\n#&gt;    spOccupancy       * 0.8.0    2024-12-14 [1] CRAN (R 4.4.3)\n#&gt;    stringi             1.8.4    2024-05-06 [1] CRAN (R 4.4.0)\n#&gt;    stringr           * 1.5.2    2025-09-08 [1] CRAN (R 4.4.3)\n#&gt;    styler            * 1.10.3   2024-04-07 [1] CRAN (R 4.4.2)\n#&gt;    svglite             2.1.3    2023-12-08 [1] CRAN (R 4.4.2)\n#&gt;    systemfonts         1.1.0    2024-05-15 [1] CRAN (R 4.4.2)\n#&gt;    tensorA             0.36.2.1 2023-12-13 [1] CRAN (R 4.4.0)\n#&gt;    terra             * 1.8-70   2025-09-27 [1] CRAN (R 4.4.3)\n#&gt;    tibble            * 3.2.1    2023-03-20 [1] CRAN (R 4.4.2)\n#&gt;    tidyr             * 1.3.1    2024-01-24 [1] CRAN (R 4.4.2)\n#&gt;    tidyselect          1.2.1    2024-03-11 [1] CRAN (R 4.4.2)\n#&gt;    tidyverse         * 2.0.0    2023-02-22 [1] CRAN (R 4.4.2)\n#&gt;    timechange          0.3.0    2024-01-18 [1] CRAN (R 4.4.2)\n#&gt;    tzdb                0.4.0    2023-05-12 [1] CRAN (R 4.4.2)\n#&gt;    units               0.8-7    2025-03-11 [1] CRAN (R 4.4.3)\n#&gt;    usethis             3.2.1    2025-09-06 [1] CRAN (R 4.4.3)\n#&gt;    uuid                1.2-1    2024-07-29 [1] CRAN (R 4.4.1)\n#&gt;    vctrs               0.6.5    2023-12-01 [1] CRAN (R 4.4.2)\n#&gt;    viridisLite         0.4.2    2023-05-02 [1] CRAN (R 4.4.2)\n#&gt;    vroom               1.6.5    2023-12-05 [1] CRAN (R 4.4.2)\n#&gt;    withr               3.0.2    2024-10-28 [1] CRAN (R 4.4.2)\n#&gt;    xfun                0.52     2025-04-02 [1] CRAN (R 4.4.3)\n#&gt;    xml2                1.4.0    2025-08-20 [1] CRAN (R 4.4.3)\n#&gt;    xtable              1.8-4    2019-04-21 [1] CRAN (R 4.4.2)\n#&gt;    yaml                2.3.10   2024-07-26 [1] CRAN (R 4.4.1)\n#&gt; \n#&gt;  [1] C:/Users/usuario/AppData/Local/R/win-library/4.4\n#&gt;  [2] C:/Program Files/R/R-4.4.2/library\n#&gt; \n#&gt;  * ── Packages attached to the search path.\n#&gt;  D ── DLL MD5 mismatch, broken installation.\n#&gt; \n#&gt; ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/2024-12-10-RAI/index.html",
    "href": "posts/2024-12-10-RAI/index.html",
    "title": "Esfuerzo de muestreo y RAI en Fototrampeo",
    "section": "",
    "text": "Este post es parte de el curso Introducción al fototrampeo realizado en el Instituto de ciencias naturales (ICN), de la Universidad Nacional de Colombia en Bogota en Diciembre 2024."
  },
  {
    "objectID": "posts/2024-12-10-RAI/index.html#introducción",
    "href": "posts/2024-12-10-RAI/index.html#introducción",
    "title": "Esfuerzo de muestreo y RAI en Fototrampeo",
    "section": "INTRODUCCIÓN",
    "text": "INTRODUCCIÓN\nEl estudio de mamíferos medianos y grandes en bosques tropicales suele ser difícil ya que muchas de estas especies son crípticas, nocturnas y esquivas, dificultando su detección. Los métodos tradicionales requieren de la captura de los animales y suelen ser costosos, de difícil manejo y poco efectivos a gran escala. Por esta razón, estas técnicas tradicionales han sido reemplazadas rápidamente por la técnica del fototrampeo, la cual usa cámaras fijas que se activan para captar imágenes de animales en el momento que pasan frente a la cámara, mediante sensores de movimiento y calor que activan la cámara.\nLas cámaras trampa son utilizadas en investigaciones biológicas como una herramienta importante para determinar distintos parámetros ecológicos como la densidad, ocurrencia, ocupación y riqueza, entre otros. Las ventajas de esta técnica son amplias, por lo que su uso es cada vez más frecuente. Por esta razón es importante conocer las características de los equipos, los alcances y limitaciones del empleo de cámaras, así como tener claridad sobre el tipo de datos proporcionados por esta técnica y su correcta interpretación. El éxito de esta técnica, como de cualquier otra, depende a su vez de un adecuado planteamiento de las preguntas de investigación y del diseño de muestreo, así como el empleo de una base conceptual sólida que permita alcanzar los objetivos planteados.\nEn este curso queremos hacer una introducción general al fototrampeo donde los participantes entiendan como funcionan las cámaras trampa, que consideraciones se deben tener en cuenta para el diseño de un estudio con fototrampeo, así como una introducción a tres análisis básicos (abundancia relativa, estimación de riqueza y patrones de actividad). En este post haremos énfasis en la abundancia relativa. La estimación de riqueza se puede ver en éste enlace. Los patrones de actividad seran objeto de un próximo post donde trataré el tema con bastante profundidad."
  },
  {
    "objectID": "posts/2024-12-10-RAI/index.html#objetivos",
    "href": "posts/2024-12-10-RAI/index.html#objetivos",
    "title": "Esfuerzo de muestreo y RAI en Fototrampeo",
    "section": "OBJETIVOS",
    "text": "OBJETIVOS\n\nCapacitar estudiantes de pregrado y personas interesadas en entender el uso y los alcances de la técnica del fototrampeo.\nEntender de manera general como se diseña un estudio con fototrampeo y como se estructuran e interpretan los datos derivados, haciendo con énfasis en lo basico: riqueza, abundancia relativa y patrones de actividad."
  },
  {
    "objectID": "posts/2024-12-10-RAI/index.html#metodología",
    "href": "posts/2024-12-10-RAI/index.html#metodología",
    "title": "Esfuerzo de muestreo y RAI en Fototrampeo",
    "section": "METODOLOGÍA",
    "text": "METODOLOGÍA\nEl curso está estructurado en dos grandes temas. El primero concerniente a la técnica propiamente dicha y el segundo relacionado con las preguntas de investigación y su análisis. Todas las sesiones son teórico-prácticas y para los ejercicios de montaje de cámaras se hará una práctica corta al interior de la Universidad Nacional. Al finalizar el curso se entregará una carpeta digital con material relacionado como libros y artículos y las presentaciones en pdf, así como los códigos en R usados en las demostraciones."
  },
  {
    "objectID": "posts/2024-12-10-RAI/index.html#libro",
    "href": "posts/2024-12-10-RAI/index.html#libro",
    "title": "Esfuerzo de muestreo y RAI en Fototrampeo",
    "section": "Libro",
    "text": "Libro\nEl curso incluye una copia impresa del Libro Fototrampeo en R de Salvador Mandujano:\n\n\nFototrampeo en R"
  },
  {
    "objectID": "posts/2024-12-10-RAI/index.html#indice-de-abundancia-relativa-rai",
    "href": "posts/2024-12-10-RAI/index.html#indice-de-abundancia-relativa-rai",
    "title": "Esfuerzo de muestreo y RAI en Fototrampeo",
    "section": "Indice de Abundancia Relativa (RAI)",
    "text": "Indice de Abundancia Relativa (RAI)\n\nRecuerda que el RAI es el número de fotos por unidad de esfuerzo de muestreo y puede ser expresado con la siguiente formula\n\n\\[\nRAI = \\dfrac{Número de fotos independientes}{dias de camara * 100}\n\\]\ny ten muy encuenta que:\n\n\n\n\n\n\nImportanteRAI no es exactamente un buen estimado de abundancia\n\n\n\nPor eso es mucho mejor llamarla Frecuencia de Captura (Capture Rate).\n\n\nPueden ver una revision muy interesante del concepto de abundancia relativa en el articulo:\n\n\n link to artículo.\n\n\nFigura 1"
  },
  {
    "objectID": "posts/2024-12-10-RAI/index.html#veamos-un-ejemplo",
    "href": "posts/2024-12-10-RAI/index.html#veamos-un-ejemplo",
    "title": "Esfuerzo de muestreo y RAI en Fototrampeo",
    "section": "Veamos un ejemplo",
    "text": "Veamos un ejemplo\nCargar Paquetes\nPrimero cargamos algunos paquetes de R\n\nCódigo\nlibrary(grateful) # Facilitate Citation of R Packages\nlibrary(patchwork) # The Composer of Plots\nlibrary(readxl) # Read Excel Files\nlibrary(sf) # Simple Features for R\nlibrary(mapview) # Interactive Viewing of Spatial Data in R\nlibrary(tmap) #nice mapr in R\nlibrary(tmaptools) #expands tmap\n# library(terra) # Spatial Data Analysis\nlibrary(readr) # Read Rectangular Text Data\nlibrary(camtrapR) # Camera Trap Data Management and Preparation of Occupancy and Spatial Capture-Recapture Analyses \nlibrary(RColorBrewer) # ColorBrewer Palettes\nlibrary(DT) # A Wrapper of the JavaScript Library 'DataTables'\nlibrary(kableExtra) # Construct Complex Table with 'kable' and Pipe Syntax\nlibrary(tidyverse) # Easily Install and Load the 'Tidyverse'\n\n# source(\"C:/CodigoR/CameraTrapCesar/R/organiza_datos.R\")\n\n\nCarguemos los datos\nSon dos archivos uno de las cámaras y otro de las especies.\n\nCódigo\n\n# library(hrbrthemes)\nlibrary(viridis)\n\ncameras &lt;- read.csv(\"C:/CodigoR/CameraTrapCesar/posts/2024-12-10-RAI/data/survey_metadata_sp_rich.csv\")\n# sp recs\nsp_rec &lt;- read.csv2(\"C:/CodigoR/CameraTrapCesar/posts/2024-12-10-RAI/data/FAZ_sp_rec_only_mammals_indep_with_generics.csv\", encoding = \"LATIN1\")\n\n# Delete cams that were not active\ncameras1 &lt;- cameras %&gt;% \n              filter(!No_spp == 0) #\n  \n# check cams vs sp records\n\nnot_in_cams &lt;- left_join(sp_rec, cameras1, by =\"deployment_id\") \nunique(not_in_cams$deployment_id) #OK\n#&gt;  [1] \"FAZ001\" \"FAZ002\" \"FAZ003\" \"FAZ004\" \"FAZ005\" \"FAZ007\" \"FAZ008\" \"FAZ009\"\n#&gt;  [9] \"FAZ010\" \"FAZ011\" \"FAZ012\" \"FAZ013\" \"FAZ014\" \"FAZ015\" \"FAZ017\" \"FAZ018\"\n#&gt; [17] \"FAZ019\" \"FAZ020\" \"FAZ021\" \"FAZ022\" \"FAZ023\" \"FAZ024\" \"FAZ025\" \"FAZ026\"\n#&gt; [25] \"FAZ027\" \"FAZ028\" \"FAZ029\"\n\n\nCamaras\nVeamos las cámaras en una tabla.\n\nCódigodatatable(head(cameras))\n\n\n\n\n\nEspecies\nVeamos las especies.\n\nCódigodatatable(sp_rec)\n\n\n\n\n\nUsemos las funciones de camtrapR\n\nEstas funciones nos permiten organizar y manipular las tablas para obtener 5 tablas derivadas. En este caso usaremos la funcion survey_rep, pero tenga en cuenta que esta función pronto será reemplazada en una proxima version de camtrapR.\nResultando en una lista de R que consta de 5 partes:\n\nsurvey_rep[[1]] esfuerzo_muestreo. camera trap operation times and image date ranges\nsurvey_rep[[2]] number of species by station\nsurvey_rep[[3]] number of events and number of stations by species\nsurvey_rep[[4]] registros_especies. number of species events by station\nsurvey_rep[[5]] number of species events by station including 0s (non-observed species)\n\n\nCódigo# first fix dates\nsp_rec$start_time &lt;- as.POSIXct(sp_rec$start_time, format = \"%Y-%m-%d %H:%M\") #     \n# make the survey report\nsurvey_rep &lt;- surveyReport(recordTable = sp_rec,\n                               CTtable = cameras1,\n                               speciesCol = \"spanish_common_name\", \n                               stationCol = \"deployment_id\",\n                               setupCol = \"start_date\", \n                               retrievalCol = \"end_date\",\n                               recordDateTimeCol = \"start_time\",\n                               makezip = F # prepara un archivo .zip, False here \n                               #sinkpath = \"data_out\",\n                            # camOp = cam_op) # directorio donde guardara .zip\n                           )\n#&gt; \n#&gt; -------------------------------------------------------\n#&gt; [1] \"Total number of stations:  27\"\n#&gt; \n#&gt; -------------------------------------------------------\n#&gt; [1] \"Number of operational stations:  27\"\n#&gt; \n#&gt; -------------------------------------------------------\n#&gt; [1] \"n nights with cameras set up (operational or not. NOTE: only correct if 1 camera per station): 4531\"\n#&gt; \n#&gt; -------------------------------------------------------\n#&gt; [1] \"n nights with cameras set up and active (trap nights. NOTE: only correct if 1 camera per station): 4531\"\n#&gt; \n#&gt; -------------------------------------------------------\n#&gt; [1] \"total trapping period:  2024-01-03 - 2024-08-28\"\n\n\nCalculemos el RAI\n\n\n\n\n\n\nTip\n\n\n\nRecuerda que el RAI es en realidad más una tasa de captura que una abundancia.\n\n\nPrimero unimos las dos tablas\nUnimos las el esfuerzo de muestreo y los registros de las especies.\n\nCódigoesfuerzo_muestreo &lt;- survey_rep[[1]] |&gt; left_join(cameras)\nn_activas &lt;- esfuerzo_muestreo[c(\"deployment_id\", \"n_nights_active\",\n                                 \"longitude\", \"latitude\")]\nwildlife.data &lt;- merge(survey_rep[[4]], n_activas, all.y = T)\ndatatable(head(wildlife.data))# \n\n\n\n\n\nRenombramos algunas columnas\n\nCódigonames(wildlife.data)[names(wildlife.data) == \"deployment_id\"] &lt;- \"Camera\"\nnames(wildlife.data)[names(wildlife.data) == \"n_events\"] &lt;- \"Events\"\nnames(wildlife.data)[names(wildlife.data) == \"n_nights_active\"] &lt;- \"Effort\"\nnames(wildlife.data)[names(wildlife.data) == \"spanish_common_name\"] &lt;- \"common_name\"\n\n\nVeamos en un mapa el esfuerzo de cada camara\n\nCódigo# primero convertimos la tabla a un objeto sf\nEfort_map &lt;- wildlife.data |&gt; \n  select(c(\"Camera\", \"longitude\", \"latitude\", \"Effort\")) |&gt; \n  st_as_sf(coords = c('longitude', 'latitude'), crs = 4326)\n# mapview\nmapview(Efort_map, \n        alpha = 0,\n        map.types = \"Esri.WorldImagery\",\n        cex = \"Effort\")\n\n\n\n\n\nRAI general por especie\nEl RAI general que se calcula agrupando toda la información de las cámaras por especie y es un valor que tiene en cuenta los registros de cada especie dividido por el esfuerzo.\n\nCódigoRAI &lt;- wildlife.data |&gt; group_by(common_name) |&gt; mutate (RAI_general=round ( (sum(Events) / sum(Effort) ) * 100, 2)) |&gt; ungroup()\ndatatable(head(RAI))\n\n\n\n\n\nRAI alternativo\nEl RAI alternativo se calcula por especie por camara y es un valor para cada especie en cada camara.\n\nCódigoRAI2 &lt;- RAI |&gt; group_by(common_name) |&gt; mutate (RAI_camara=round ( Events / Effort * 100, 2)) |&gt; ungroup()\n# make common_name factor\nRAI2$common_name &lt;- as.factor(RAI2$common_name)\ndatatable(head(RAI2))\n\n\n\n\n\nVeamolo como graficas\n\nCódigo\n# Barplot\nggplot(RAI, aes(x=reorder(common_name, RAI_general), y=RAI_general)) + \n  geom_bar(stat = \"identity\") +  ggtitle(\"RAI general\") +\n  coord_flip()\n\n\n\n\n\n\nCódigo\n# Barplot\n# Plot\nRAI2 %&gt;%\n  ggplot( aes(x=common_name, y=RAI_camara, fill=common_name)) +\n    geom_boxplot() + scale_x_discrete(guide = guide_axis(angle = 90)) +\n    scale_fill_viridis(discrete = TRUE, alpha=0.6) +\n    geom_jitter(color=\"black\", size=0.4, alpha=0.9) +\n    # theme_ipsum() +\n    theme(\n      legend.position=\"none\",\n      plot.title = element_text(size=11)\n    ) +\n    ggtitle(\"RAI alternativo\") +\n    xlab(\"\")\n\n\n\n\n\n\n\nVeamos el RAI alternativo como un mapa\nPara esto usaremos las facilidades que ofrece el paquete tmap. Los puntos negros son las cámaras y los rojos el RAI alternativo para cada especie.\n\nCódigo######| layout-nrow: 1\n#### column: screen-inset-shaded\n\n# primero convertimos el RAI2 a un sf\nRAI2 &lt;- RAI2 |&gt; st_as_sf(coords = c('longitude', 'latitude'), crs = 4326)\n\n# veamos un mapa por especie\ntm_shape(RAI2, bbox = tmaptools::bb(RAI2, ext = 1.5))  + \n  tm_basemap(\"Esri.WorldImagery\") + # usa basemap\n    tm_symbols(shape = 1, col = \"black\", fill = \"black\",size =0.2) + #punto negro\n  tm_shape(RAI2, bbox = tmaptools::bb(RAI2, ext = 1.5))  + \n    tm_bubbles(fill = \"red\", col = \"red\", size = \"RAI_camara\", scale = 1.5) +\n    tm_facets(by = \"common_name\") + #, ncol = 5) +\n  tm_tiles(\"Esri_WorldImagery\") +\n  tm_legend_hide() \n\n\n\n\n\n\n\n\nFacil no?\n\nNormalmente el trabajo con datos de fototrampeo involucra 80% del tiempo ajustando los datos y las tablas y tan solo en 20% del tiempo corriendo el analisis."
  },
  {
    "objectID": "posts/2024-12-10-RAI/index.html#foto-de-los-participantes-del-curso",
    "href": "posts/2024-12-10-RAI/index.html#foto-de-los-participantes-del-curso",
    "title": "Esfuerzo de muestreo y RAI en Fototrampeo",
    "section": "Foto de los participantes del curso:",
    "text": "Foto de los participantes del curso:"
  },
  {
    "objectID": "posts/2024-12-10-RAI/index.html#package-citation",
    "href": "posts/2024-12-10-RAI/index.html#package-citation",
    "title": "Esfuerzo de muestreo y RAI en Fototrampeo",
    "section": "Package Citation",
    "text": "Package Citation\n\nCódigopkgs &lt;- cite_packages(output = \"paragraph\", out.dir = \".\") #knitr::kable(pkgs)\npkgs\n\nWe used R v. 4.4.2 (R Core Team 2024) and the following R packages: camtrapR v. 3.0.0 (Niedballa et al. 2016), devtools v. 2.4.6 (Wickham et al. 2025), DT v. 0.34.0 (Xie et al. 2025), kableExtra v. 1.4.0 (Zhu 2024), mapview v. 2.11.4 (Appelhans et al. 2025), patchwork v. 1.3.2 (Pedersen 2025), quarto v. 1.5.1 (Allaire y Dervieux 2025), RColorBrewer v. 1.1.3 (Neuwirth 2022), rmarkdown v. 2.30 (Xie, Allaire, y Grolemund 2018; Xie, Dervieux, y Riederer 2020; Allaire et al. 2025), sf v. 1.0.21 (Pebesma 2018; Pebesma y Bivand 2023), styler v. 1.10.3 (Müller y Walthert 2024), tidyverse v. 2.0.0 (Wickham et al. 2019), tmap v. 4.2 (Tennekes 2018), tmaptools v. 3.3 (Tennekes 2025), viridis v. 0.6.5 (Garnier et al. 2024)."
  },
  {
    "objectID": "posts/2024-12-10-RAI/index.html#sesion-info",
    "href": "posts/2024-12-10-RAI/index.html#sesion-info",
    "title": "Esfuerzo de muestreo y RAI en Fototrampeo",
    "section": "Sesion info",
    "text": "Sesion info\n\nSession info\n\n#&gt; ─ Session info ───────────────────────────────────────────────────────────────────────────────────────────────────────\n#&gt;  setting  value\n#&gt;  version  R version 4.4.2 (2024-10-31 ucrt)\n#&gt;  os       Windows 10 x64 (build 19045)\n#&gt;  system   x86_64, mingw32\n#&gt;  ui       RTerm\n#&gt;  language (EN)\n#&gt;  collate  Spanish_Colombia.utf8\n#&gt;  ctype    Spanish_Colombia.utf8\n#&gt;  tz       America/Bogota\n#&gt;  date     2025-11-05\n#&gt;  pandoc   3.6.3 @ C:/Program Files/RStudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n#&gt;  quarto   NA @ C:\\\\Users\\\\usuario\\\\AppData\\\\Local\\\\Programs\\\\Quarto\\\\bin\\\\quarto.exe\n#&gt; \n#&gt; ─ Packages ───────────────────────────────────────────────────────────────────────────────────────────────────────────\n#&gt;  ! package           * version   date (UTC) lib source\n#&gt;    abind               1.4-8     2024-09-12 [1] CRAN (R 4.4.1)\n#&gt;    base64enc           0.1-3     2015-07-28 [1] CRAN (R 4.4.0)\n#&gt;    brew                1.0-10    2023-12-16 [1] CRAN (R 4.4.2)\n#&gt;    bslib               0.9.0     2025-01-30 [1] CRAN (R 4.4.3)\n#&gt;    cachem              1.1.0     2024-05-16 [1] CRAN (R 4.4.2)\n#&gt;    camtrapR          * 3.0.0     2025-09-28 [1] CRAN (R 4.4.3)\n#&gt;    cellranger          1.1.0     2016-07-27 [1] CRAN (R 4.4.2)\n#&gt;    class               7.3-22    2023-05-03 [2] CRAN (R 4.4.2)\n#&gt;    classInt            0.4-11    2025-01-08 [1] CRAN (R 4.4.3)\n#&gt;    cli                 3.6.5     2025-04-23 [1] CRAN (R 4.4.3)\n#&gt;    codetools           0.2-20    2024-03-31 [2] CRAN (R 4.4.2)\n#&gt;    colorspace          2.1-1     2024-07-26 [1] CRAN (R 4.4.2)\n#&gt;    cols4all            0.8-1     2025-08-17 [1] Github (cols4all/cols4all-R@d39bcbd)\n#&gt;    crosstalk           1.2.1     2023-11-23 [1] CRAN (R 4.4.2)\n#&gt;    curl                7.0.0     2025-08-19 [1] CRAN (R 4.4.3)\n#&gt;    data.table          1.17.8    2025-07-10 [1] CRAN (R 4.4.3)\n#&gt;    DBI                 1.2.3     2024-06-02 [1] CRAN (R 4.4.2)\n#&gt;    devtools            2.4.6     2025-10-03 [1] CRAN (R 4.4.3)\n#&gt;    dichromat           2.0-0.1   2022-05-02 [1] CRAN (R 4.4.0)\n#&gt;    digest              0.6.37    2024-08-19 [1] CRAN (R 4.4.2)\n#&gt;    dplyr             * 1.1.4     2023-11-17 [1] CRAN (R 4.4.2)\n#&gt;    DT                * 0.34.0    2025-09-02 [1] CRAN (R 4.4.3)\n#&gt;    e1071               1.7-16    2024-09-16 [1] CRAN (R 4.4.2)\n#&gt;    ellipsis            0.3.2     2021-04-29 [1] CRAN (R 4.4.2)\n#&gt;    evaluate            1.0.4     2025-06-18 [1] CRAN (R 4.4.3)\n#&gt;    farver              2.1.2     2024-05-13 [1] CRAN (R 4.4.2)\n#&gt;    fastmap             1.2.0     2024-05-15 [1] CRAN (R 4.4.2)\n#&gt;    forcats           * 1.0.0     2023-01-29 [1] CRAN (R 4.4.2)\n#&gt;    fs                  1.6.6     2025-04-12 [1] CRAN (R 4.4.3)\n#&gt;    generics            0.1.3     2022-07-05 [1] CRAN (R 4.4.2)\n#&gt;    ggplot2           * 4.0.0     2025-09-11 [1] CRAN (R 4.4.3)\n#&gt;    glue                1.8.0     2024-09-30 [1] CRAN (R 4.4.2)\n#&gt;    grateful          * 0.3.0     2025-09-04 [1] CRAN (R 4.4.3)\n#&gt;    gridExtra           2.3       2017-09-09 [1] CRAN (R 4.4.2)\n#&gt;    gtable              0.3.6     2024-10-25 [1] CRAN (R 4.4.2)\n#&gt;    hms                 1.1.3     2023-03-21 [1] CRAN (R 4.4.2)\n#&gt;    htmltools           0.5.8.1   2024-04-04 [1] CRAN (R 4.4.2)\n#&gt;    htmlwidgets         1.6.4     2023-12-06 [1] CRAN (R 4.4.2)\n#&gt;    httpuv              1.6.16    2025-04-16 [1] CRAN (R 4.4.3)\n#&gt;    jquerylib           0.1.4     2021-04-26 [1] CRAN (R 4.4.2)\n#&gt;    jsonlite            2.0.0     2025-03-27 [1] CRAN (R 4.4.3)\n#&gt;    kableExtra        * 1.4.0     2024-01-24 [1] CRAN (R 4.4.2)\n#&gt;    KernSmooth          2.23-24   2024-05-17 [2] CRAN (R 4.4.2)\n#&gt;    knitr               1.50      2025-03-16 [1] CRAN (R 4.4.3)\n#&gt;    labeling            0.4.3     2023-08-29 [1] CRAN (R 4.4.0)\n#&gt;    later               1.4.2     2025-04-08 [1] CRAN (R 4.4.3)\n#&gt;    lattice             0.22-6    2024-03-20 [2] CRAN (R 4.4.2)\n#&gt;    leafem              0.2.4     2025-05-01 [1] CRAN (R 4.4.3)\n#&gt;    leaflegend          1.2.1     2024-05-09 [1] CRAN (R 4.4.2)\n#&gt;    leaflet             2.2.3     2025-09-04 [1] CRAN (R 4.4.3)\n#&gt;    leaflet.providers   2.0.0     2023-10-17 [1] CRAN (R 4.4.2)\n#&gt;    leafpop             0.1.0     2021-05-22 [1] CRAN (R 4.4.2)\n#&gt;    leafsync            0.1.0     2019-03-05 [1] CRAN (R 4.4.2)\n#&gt;    lifecycle           1.0.4     2023-11-07 [1] CRAN (R 4.4.2)\n#&gt;    logger              0.4.0     2024-10-22 [1] CRAN (R 4.4.3)\n#&gt;    lubridate         * 1.9.4     2024-12-08 [1] CRAN (R 4.4.2)\n#&gt;    lwgeom              0.2-14    2024-02-21 [1] CRAN (R 4.4.2)\n#&gt;    magrittr            2.0.3     2022-03-30 [1] CRAN (R 4.4.2)\n#&gt;    maptiles            0.10.0    2025-05-07 [1] CRAN (R 4.4.3)\n#&gt;    mapview           * 2.11.4    2025-09-08 [1] CRAN (R 4.4.3)\n#&gt;    MASS                7.3-61    2024-06-13 [2] CRAN (R 4.4.2)\n#&gt;    Matrix              1.7-1     2024-10-18 [2] CRAN (R 4.4.2)\n#&gt;    memoise             2.0.1     2021-11-26 [1] CRAN (R 4.4.2)\n#&gt;    mgcv                1.9-1     2023-12-21 [2] CRAN (R 4.4.2)\n#&gt;    microbenchmark      1.5.0     2024-09-04 [1] CRAN (R 4.4.2)\n#&gt;    mime                0.13      2025-03-17 [1] CRAN (R 4.4.3)\n#&gt;    mvtnorm             1.3-2     2024-11-04 [1] CRAN (R 4.4.2)\n#&gt;    nlme                3.1-166   2024-08-14 [2] CRAN (R 4.4.2)\n#&gt;    patchwork         * 1.3.2     2025-08-25 [1] CRAN (R 4.4.3)\n#&gt;    pillar              1.11.1    2025-09-17 [1] CRAN (R 4.4.2)\n#&gt;    pkgbuild            1.4.8     2025-05-26 [1] CRAN (R 4.4.3)\n#&gt;    pkgconfig           2.0.3     2019-09-22 [1] CRAN (R 4.4.2)\n#&gt;    pkgload             1.4.1     2025-09-23 [1] CRAN (R 4.4.3)\n#&gt;    png                 0.1-8     2022-11-29 [1] CRAN (R 4.4.0)\n#&gt;    processx            3.8.4     2024-03-16 [1] CRAN (R 4.4.2)\n#&gt;    promises            1.3.3     2025-05-29 [1] CRAN (R 4.4.3)\n#&gt;    proxy               0.4-27    2022-06-09 [1] CRAN (R 4.4.2)\n#&gt;    ps                  1.8.1     2024-10-28 [1] CRAN (R 4.4.2)\n#&gt;    purrr             * 1.1.0     2025-07-10 [1] CRAN (R 4.4.3)\n#&gt;    quarto            * 1.5.1     2025-09-04 [1] CRAN (R 4.4.3)\n#&gt;    R.cache             0.16.0    2022-07-21 [1] CRAN (R 4.4.2)\n#&gt;    R.methodsS3         1.8.2     2022-06-13 [1] CRAN (R 4.4.0)\n#&gt;    R.oo                1.27.0    2024-11-01 [1] CRAN (R 4.4.1)\n#&gt;    R.utils             2.13.0    2025-02-24 [1] CRAN (R 4.4.3)\n#&gt;    R6                  2.6.1     2025-02-15 [1] CRAN (R 4.4.2)\n#&gt;    raster              3.6-32    2025-03-28 [1] CRAN (R 4.4.3)\n#&gt;    RColorBrewer      * 1.1-3     2022-04-03 [1] CRAN (R 4.4.0)\n#&gt;    Rcpp                1.1.0     2025-07-02 [1] CRAN (R 4.4.3)\n#&gt;    RcppNumerical       0.6-0     2023-09-06 [1] CRAN (R 4.4.2)\n#&gt;  D RcppParallel        5.1.9     2024-08-19 [1] CRAN (R 4.4.2)\n#&gt;    readr             * 2.1.5     2024-01-10 [1] CRAN (R 4.4.2)\n#&gt;    readxl            * 1.4.3     2023-07-06 [1] CRAN (R 4.4.2)\n#&gt;    remotes             2.5.0     2024-03-17 [1] CRAN (R 4.4.3)\n#&gt;    renv                1.0.11    2024-10-12 [1] CRAN (R 4.4.2)\n#&gt;    rlang               1.1.6     2025-04-11 [1] CRAN (R 4.4.3)\n#&gt;    rmarkdown           2.30      2025-09-28 [1] CRAN (R 4.4.3)\n#&gt;    rstudioapi          0.17.1    2024-10-22 [1] CRAN (R 4.4.2)\n#&gt;    s2                  1.1.9     2025-05-23 [1] CRAN (R 4.4.3)\n#&gt;    S7                  0.2.0     2024-11-07 [1] CRAN (R 4.4.3)\n#&gt;    sass                0.4.10    2025-04-11 [1] CRAN (R 4.4.3)\n#&gt;    satellite           1.0.5     2024-02-10 [1] CRAN (R 4.4.2)\n#&gt;    scales              1.4.0     2025-04-24 [1] CRAN (R 4.4.3)\n#&gt;    secr                5.1.0     2024-11-04 [1] CRAN (R 4.4.2)\n#&gt;    sessioninfo         1.2.3     2025-02-05 [1] CRAN (R 4.4.3)\n#&gt;    sf                * 1.0-21    2025-05-15 [1] CRAN (R 4.4.3)\n#&gt;    shiny               1.9.1     2024-08-01 [1] CRAN (R 4.4.2)\n#&gt;    shinyBS             0.61.1    2022-04-17 [1] CRAN (R 4.4.3)\n#&gt;    shinydashboard      0.7.3     2025-04-21 [1] CRAN (R 4.4.3)\n#&gt;    slippymath          0.3.1     2019-06-28 [1] CRAN (R 4.4.2)\n#&gt;    sp                  2.2-0     2025-02-01 [1] CRAN (R 4.4.3)\n#&gt;    spacesXYZ           1.6-0     2025-06-06 [1] CRAN (R 4.4.3)\n#&gt;    stars               0.6-8     2025-02-01 [1] CRAN (R 4.4.2)\n#&gt;    stringi             1.8.4     2024-05-06 [1] CRAN (R 4.4.0)\n#&gt;    stringr           * 1.5.2     2025-09-08 [1] CRAN (R 4.4.3)\n#&gt;    styler            * 1.10.3    2024-04-07 [1] CRAN (R 4.4.2)\n#&gt;    svglite             2.1.3     2023-12-08 [1] CRAN (R 4.4.2)\n#&gt;    systemfonts         1.1.0     2024-05-15 [1] CRAN (R 4.4.2)\n#&gt;    terra               1.8-70    2025-09-27 [1] CRAN (R 4.4.3)\n#&gt;    tibble            * 3.2.1     2023-03-20 [1] CRAN (R 4.4.2)\n#&gt;    tidyr             * 1.3.1     2024-01-24 [1] CRAN (R 4.4.2)\n#&gt;    tidyselect          1.2.1     2024-03-11 [1] CRAN (R 4.4.2)\n#&gt;    tidyverse         * 2.0.0     2023-02-22 [1] CRAN (R 4.4.2)\n#&gt;    timechange          0.3.0     2024-01-18 [1] CRAN (R 4.4.2)\n#&gt;    tmap              * 4.2       2025-09-10 [1] CRAN (R 4.4.3)\n#&gt;    tmaptools         * 3.3       2025-07-24 [1] CRAN (R 4.4.3)\n#&gt;    tzdb                0.4.0     2023-05-12 [1] CRAN (R 4.4.2)\n#&gt;    units               0.8-7     2025-03-11 [1] CRAN (R 4.4.3)\n#&gt;    usethis             3.2.1     2025-09-06 [1] CRAN (R 4.4.3)\n#&gt;    uuid                1.2-1     2024-07-29 [1] CRAN (R 4.4.1)\n#&gt;    vctrs               0.6.5     2023-12-01 [1] CRAN (R 4.4.2)\n#&gt;    viridis           * 0.6.5     2024-01-29 [1] CRAN (R 4.4.3)\n#&gt;    viridisLite       * 0.4.2     2023-05-02 [1] CRAN (R 4.4.2)\n#&gt;    withr               3.0.2     2024-10-28 [1] CRAN (R 4.4.2)\n#&gt;    wk                  0.9.4     2024-10-11 [1] CRAN (R 4.4.2)\n#&gt;    xfun                0.52      2025-04-02 [1] CRAN (R 4.4.3)\n#&gt;    XML                 3.99-0.18 2025-01-01 [1] CRAN (R 4.4.3)\n#&gt;    xml2                1.4.0     2025-08-20 [1] CRAN (R 4.4.3)\n#&gt;    xtable              1.8-4     2019-04-21 [1] CRAN (R 4.4.2)\n#&gt;    yaml                2.3.10    2024-07-26 [1] CRAN (R 4.4.1)\n#&gt; \n#&gt;  [1] C:/Users/usuario/AppData/Local/R/win-library/4.4\n#&gt;  [2] C:/Program Files/R/R-4.4.2/library\n#&gt; \n#&gt;  * ── Packages attached to the search path.\n#&gt;  D ── DLL MD5 mismatch, broken installation.\n#&gt; \n#&gt; ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/2024-07-17-stackmodel/index.html",
    "href": "posts/2024-07-17-stackmodel/index.html",
    "title": "“Stacked” Models",
    "section": "",
    "text": "Multi-season (or dynamic) models are commonly used to estimate colonization and/or extinction probabilities, and to test hypotheses on these parameters (using covariates on the parameters gamma and epsilon). This approach needs good amounts of data (many sites, and specially many seasons or years). If you don’t need to estimate dynamic parameters (Colonization or extinction, gamma and epsilon) but you’d like to test for temporal variation in occupancy (Psi) between two or three years taking in to account detection probability (p) you could apply a single-season model with random effects (being random effects the camera trap, sampling unit, or site), by stacking years (i.e., your sampling units would be combination camera-years)."
  },
  {
    "objectID": "posts/2024-07-17-stackmodel/index.html#shoud-i-use-a-multiseason-model",
    "href": "posts/2024-07-17-stackmodel/index.html#shoud-i-use-a-multiseason-model",
    "title": "“Stacked” Models",
    "section": "",
    "text": "Multi-season (or dynamic) models are commonly used to estimate colonization and/or extinction probabilities, and to test hypotheses on these parameters (using covariates on the parameters gamma and epsilon). This approach needs good amounts of data (many sites, and specially many seasons or years). If you don’t need to estimate dynamic parameters (Colonization or extinction, gamma and epsilon) but you’d like to test for temporal variation in occupancy (Psi) between two or three years taking in to account detection probability (p) you could apply a single-season model with random effects (being random effects the camera trap, sampling unit, or site), by stacking years (i.e., your sampling units would be combination camera-years)."
  },
  {
    "objectID": "posts/2024-07-17-stackmodel/index.html#using-random-effects-with-ubms",
    "href": "posts/2024-07-17-stackmodel/index.html#using-random-effects-with-ubms",
    "title": "“Stacked” Models",
    "section": "Using random effects with ubms\n",
    "text": "Using random effects with ubms\n\nOne of the advantages of the package ubms is that it is possible to include random effects easily in your models, using the same syntax as lme4 (Bates et al. 2015). For example, if you have a group or site covariate, you can fit a model with random intercepts by group-site by including + (1|site) in your parameter formula. Random slopes, or a combination of random slopes and intercepts, are also possible.\nTo illustrate the use of random effects using the package ubms, in this post, we fit a model using a “stacked” model approach. Additionally in ubms you can instead include, for example, random site intercepts to account for possible pseudoreplication, or handle the temporal autocorrelation structure of o two-three year dataset.\nRecently (February 2025) version 1.5.0 of unmarked also incorporated random effects and community models."
  },
  {
    "objectID": "posts/2024-07-17-stackmodel/index.html#the-stacked-model",
    "href": "posts/2024-07-17-stackmodel/index.html#the-stacked-model",
    "title": "“Stacked” Models",
    "section": "The “stacked” model",
    "text": "The “stacked” model\nAn alternative approach to try a dynamic model, is to fit multiple years of data into a single-season model, using the “stacked” approach. Essentially, you treat unique site-year combinations as sites and can make occupancy comparisons between years.\nThere are several potential reasons for this:\n\n\nTake in to account that dynamic models and Dail-Madsen type models are particularly data hungry.\n\n\nYou are not interested in the transition probabilities (colonization or extinction rates).\n\n\nYou have very few years or seasons (less than five) in your sampling design, and the occupancy did not changed substantially in those few years.\n\n\nThis is specially useful if you only have 2 years of data, so there is no great gain in fitting a dynamic occupancy model with the four parameters parameters \\(\\Psi\\), \\(p\\), \\(\\gamma\\), and \\(\\epsilon\\), especially if you have a low number of detections and few years or seasond. So the best approach is combining (stacking) the two-treee years, and running a single season occupancy model, with just two parameters (\\(\\Psi\\) and \\(p\\) instead of four parameters), with year as an explanatory variable and the site as random effect as using lme4 notation as:\nmodel &lt;- occu (~ effort ~ elevation + year + (1 | site), data = newOccu)"
  },
  {
    "objectID": "posts/2024-07-17-stackmodel/index.html#load-packages",
    "href": "posts/2024-07-17-stackmodel/index.html#load-packages",
    "title": "“Stacked” Models",
    "section": "Load packages",
    "text": "Load packages\nFirst we load some packages\n\nCode\nlibrary(grateful) # Facilitate Citation of R Packages\nlibrary(patchwork) # The Composer of Plots\nlibrary(readxl) # Read Excel Files\nlibrary(sf) # Simple Features for R\nlibrary(mapview) # Interactive Viewing of Spatial Data in R\nlibrary(terra) # Spatial Data Analysis\nlibrary(elevatr) # Access Elevation Data from Various APIs\nlibrary(readr) # read csv files \n\nlibrary(camtrapR) # Camera Trap Data Management and Preparation of Occupancy and Spatial Capture-Recapture Analyses \nlibrary(ubms) # bayesian occupancy modeling\nlibrary(lme4) # \nlibrary(DT) # nice tables\n\nlibrary(kableExtra) # Construct Complex Table with 'kable' and Pipe Syntax\nlibrary(tidyverse) # Load the 'Tidyverse'"
  },
  {
    "objectID": "posts/2024-07-17-stackmodel/index.html#load-data",
    "href": "posts/2024-07-17-stackmodel/index.html#load-data",
    "title": "“Stacked” Models",
    "section": "Load data",
    "text": "Load data\nThe data set is downloaded from Initiative Monitoreo Katios in Wildlife insights were we sampled with an array of 30 cameras on two consecutive years in Katios National Park in Colombia.\n\n\nInitiative Monitoreo Katios\n\n\nCode\npath &lt;- \"C:/CodigoR/CameraTrapCesar/data/katios/\"\ncameras &lt;- read_csv(paste(path, \"cameras.csv\", sep=\"\"))\ndeployment &lt;- read_csv(paste(path, \"deployments.csv\", sep=\"\"))\nimages &lt;- read_csv(paste(path, \"images.csv\", sep=\"\"))\nproject &lt;- read_csv(paste(path, \"projects.csv\", sep=\"\"))\n\n# join_by(project_id, camera_id, camera_name)`\ncam_deploy &lt;- cameras |&gt; left_join(deployment) |&gt; \n  dplyr::mutate(year=lubridate::year(start_date)) #|&gt; filter(year== 2023)\ncam_deploy_image &lt;- images  |&gt; \n  left_join(cam_deploy) |&gt; \n  mutate(scientificName= paste(genus, species, sep = \" \")) |&gt; \n   mutate(deployment_id_cam=paste(deployment_id, camera_id, sep = \"-\")) #|&gt; \n  # filter(year==2022)"
  },
  {
    "objectID": "posts/2024-07-17-stackmodel/index.html#convert-to-sf-and-view-the-map",
    "href": "posts/2024-07-17-stackmodel/index.html#convert-to-sf-and-view-the-map",
    "title": "“Stacked” Models",
    "section": "Convert to sf and view the map",
    "text": "Convert to sf and view the map\n\nCode\ndatos_distinct &lt;- cam_deploy_image |&gt; distinct(longitude, latitude, deployment_id, samp_year) |&gt; as.data.frame()\n\n# Fix NA camera 16\ndatos_distinct[16,] &lt;- c( -77.2787, 7.73855, \n                      \"CT-K1-31-124\", 2021)\n\nprojlatlon &lt;- \"+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0\"\n\ndatos_sf &lt;-  st_as_sf(x = datos_distinct,\n                         coords = c(\"longitude\", \n                                    \"latitude\"),\n                         crs = projlatlon)\n\nmapview(st_jitter(datos_sf, 0.00075) , zcol=\"samp_year\")\n\n\n\n\n\nNotice we used the function st_jitter() because the points are on top of the previous year."
  },
  {
    "objectID": "posts/2024-07-17-stackmodel/index.html#extract-site-covariates",
    "href": "posts/2024-07-17-stackmodel/index.html#extract-site-covariates",
    "title": "“Stacked” Models",
    "section": "Extract site covariates",
    "text": "Extract site covariates\nUsing the coordinates of the sf object (datos_sf) we put the cameras on top of the covaraies and with the function terra::extract() we get the covariate value.\nIn this case we used as covariates:\n\nCattle distribution as number of cows per 10 square kilometer (Gilbert et al. 2018).\nPercent of tree cover from MODIS product 44B.\nRoad density from (Meijer et al. 2018).\nLand cover types from MODIS.\n\n\nCode#load rasters\nper_tree_cov &lt;- rast(\"C:/CodigoR/WCS-CameraTrap/raster/latlon/Veg_Cont_Fields_Yearly_250m_v61/Perc_TreeCov/MOD44B_Perc_TreeCov_2021_065.tif\")\nroad_den &lt;- rast(\"C:/CodigoR/WCS-CameraTrap/raster/latlon/RoadDensity/grip4_total_dens_m_km2.asc\")\n# elev &lt;- rast(\"D:/CORREGIDAS/elevation_z7.tif\")\nlandcov &lt;- rast(\"C:/CodigoR/WCS-CameraTrap/raster/latlon/LandCover_Type_Yearly_500m_v61/LC1/MCD12Q1_LC1_2021_001.tif\") \ncattle &lt;- rast(\"C:/CodigoR/WCS-CameraTrap/raster/latlon/Global cattle distribution/5_Ct_2010_Da.tif\")\n#river &lt;- st_read(\"F:/WCS-CameraTrap/shp/DensidadRios/MCD12Q1_LC1_2001_001_RECLASS_MASK_GRID_3600m_DensDrenSouthAmer.shp\")\n\n# get elevation map\n# elevation_detailed &lt;- rast(get_elev_raster(sites, z = 10, clip=\"bbox\", neg_to_na=TRUE))\n# elevation_detailed &lt;- get_elev_point (datos_sf, src=\"aws\", overwrite=TRUE)\n\n\n# extract covs using points and add to sites\n# covs &lt;- cbind(sites, terra::extract(SiteCovsRast, sites))\nper_tre &lt;- terra::extract(per_tree_cov, datos_sf)\nroads &lt;- terra::extract(road_den, datos_sf)\n# eleva &lt;- terra::extract(elevation_detailed, sites)\nland_cov &lt;- terra::extract(landcov, datos_sf)\ncattle_den &lt;-  terra::extract(cattle, datos_sf)\n\n#### drop geometry \nsites &lt;- datos_sf %&gt;%\n  mutate(lat = st_coordinates(.)[,1],\n         lon = st_coordinates(.)[,2]) %&gt;%\n  st_drop_geometry() |&gt; as.data.frame()\n\n# remove decimals convert to factor\nsites$land_cover &lt;-  factor(land_cov$MCD12Q1_LC1_2021_001)\n# sites$elevation &lt;-  eleva$file3be898018c3\nsites$per_tree_cov &lt;- per_tre$MOD44B_Perc_TreeCov_2021_065 \n#  fix 200 isue\nind &lt;- which(sites$per_tree_cov== 200)\nsites$per_tree_cov[ind] &lt;- 0\n\n# sites$elevation &lt;- elevation_detailed$elevation\nsites$roads &lt;- roads$grip4_total_dens_m_km2\nsites$cattle &lt;- cattle_den[,2]\n\n\nwrite.csv(sites, \"C:/CodigoR/CameraTrapCesar/data/katios/stacked/site_covs.csv\")"
  },
  {
    "objectID": "posts/2024-07-17-stackmodel/index.html#select-by-years-and-convert-to-stacked-format",
    "href": "posts/2024-07-17-stackmodel/index.html#select-by-years-and-convert-to-stacked-format",
    "title": "“Stacked” Models",
    "section": "Select by years and convert to stacked format",
    "text": "Select by years and convert to stacked format\nTo get the detection history we use the function detectionHistory of the camtrapR package.\n\n\n\n\n\n\nTipTake in to account, at the end we need to stack the data in this format:\n\n\n\n\n\nobs1\nobs2\nobs3\nsite\nyear\n\n\n\n0\n0\n0\n1\n1\n\n\n0\n0\n0\n2\n1\n\n\n1\nNA\nNA\n3\n1\n\n\n0\n0\n0\n4\n1\n\n\n0\n0\n0\n1\n2\n\n\n1\n0\n1\n2\n2\n\n\n0\n1\nNA\n3\n2\n\n\n\n\n\nSo we need to go by years and then stack de two tables.\nFirst year 2021\nHere we use the function detectionHistory() from the package camtrapR to generate species detection histories that can be used later in occupancy analyses, with package unmarked and ubms. detectionHistory() generates detection histories in different formats, with adjustable occasion length and occasion start time and effort covariates. Notice we first need to get the camera operation dates using the function cameraOperation().\n\nCode\n# filter first year and make uniques\n\nCToperation_2021  &lt;- cam_deploy_image |&gt; #multi-season data\n  filter(samp_year==2021) |&gt; \n  group_by(deployment_id) |&gt; \n  mutate(minStart=min(start_date), maxEnd=max(end_date)) |&gt; \n  distinct(longitude, latitude, minStart, maxEnd, samp_year) |&gt; \n  ungroup() |&gt; as.data.frame()\n\n\n# Fix NA camera 16\nCToperation_2021[16,] &lt;- c(\"CT-K1-31-124\", -77.2787,    7.73855, \n                      \"2021-10-10\", \"2021-12-31\", 2021)\n\n# make numeric sampling year\nCToperation_2021$samp_year &lt;- as.numeric(CToperation_2021$samp_year)\n\n# camera operation matrix for _2021\n# multi-season data. Season1\ncamop_2021 &lt;- cameraOperation(CTtable= CToperation_2021, # Tabla de operación\n                         stationCol= \"deployment_id\", # Columna que define la estación\n                         setupCol= \"minStart\", #Columna fecha de colocación\n                         retrievalCol= \"maxEnd\", #Columna fecha de retiro\n                         sessionCol = \"samp_year\", # multi-season column\n                         #hasProblems= T, # Hubo fallos de cámaras\n                         dateFormat= \"%Y-%m-%d\")#, #, # Formato de las fechas\n                         #cameraCol=\"CT\")\n                         #sessionCol= \"samp_year\")\n\n# Generar las historias de detección ---------------------------------------\n## remove plroblem species\n# ind &lt;- which(datos_PCF$Species==\"Marmosa sp.\")\n# datos_PCF &lt;- datos_PCF[-ind,]\n\n# filter y1\ndatay_2021 &lt;- cam_deploy_image |&gt; filter(samp_year ==2021) # |&gt; \n  # filter(samp_year==2022) \n\nDetHist_list_2021 &lt;- lapply(unique(datay_2021$scientificName), FUN = function(x) {\n  detectionHistory(\n    recordTable         = datay_2021, # Tabla de registros\n    camOp                = camop_2021, # Matriz de operación de cámaras\n    stationCol           = \"deployment_id\",\n    speciesCol           = \"scientificName\",\n    recordDateTimeCol    = \"timestamp\",\n    recordDateTimeFormat  = \"%Y-%m-%d %H:%M:%S\",\n    species              = x,     # la función reemplaza x por cada una de las especies\n    occasionLength       = 15, # Colapso de las historias a días\n    day1                 = \"station\", #inicie en la fecha de cada survey\n    datesAsOccasionNames = FALSE,\n    includeEffort        = TRUE,\n    scaleEffort          = FALSE,\n    unmarkedMultFrameInput=TRUE,\n    timeZone             = \"America/Bogota\" \n    )\n  }\n)\n\n# names\nnames(DetHist_list_2021) &lt;- unique(datay_2021$scientificName)\n\n# Finalmente creamos una lista nueva donde estén solo las historias de detección\nylist_2021 &lt;- lapply(DetHist_list_2021, FUN = function(x) x$detection_history)\n# y el esfuerzo\neffortlist_2021 &lt;- lapply(DetHist_list_2021, FUN = function(x) x$effort)\n\n### Danta, Jaguar\nwhich(names(ylist_2021) ==\"Tapirus bairdii\")\n#&gt; integer(0)\nwhich(names(ylist_2021) ==\"Panthera onca\") \n#&gt; [1] 5\n\n\nNext, the year 2022\n\nCode\n# filter firs year and make uniques\n\nCToperation_2022  &lt;- cam_deploy_image |&gt; #multi-season data\n  filter(samp_year==2022) |&gt; \n  group_by(deployment_id) |&gt; \n  mutate(minStart=min(start_date), maxEnd=max(end_date)) |&gt; \n  distinct(longitude, latitude, minStart, maxEnd, samp_year) |&gt; \n  ungroup() |&gt; as.data.frame()\n\n\n# Fix NA camera 16\n# CToperation_2022[16,] &lt;- c(\"CT-K1-31-124\", -77.2787,  7.73855, \n#                       \"2022-10-10\", \"2022-12-31\", 2022)\n\n# make numeric sampling year\nCToperation_2022$samp_year &lt;- as.numeric(CToperation_2022$samp_year)\n\n# camera operation matrix for _2022\n# multi-season data. Season1\ncamop_2022 &lt;- cameraOperation(CTtable= CToperation_2022, # Tabla de operación\n                         stationCol= \"deployment_id\", # Columna que define la estación\n                         setupCol= \"minStart\", #Columna fecha de colocación\n                         retrievalCol= \"maxEnd\", #Columna fecha de retiro\n                         sessionCol = \"samp_year\", # multi-season column\n                         #hasProblems= T, # Hubo fallos de cámaras\n                         dateFormat= \"%Y-%m-%d\")#, #, # Formato de las fechas\n                         #cameraCol=\"CT\")\n                         #sessionCol= \"samp_year\")\n\n# Generar las historias de detección ---------------------------------------\n## remove plroblem species\n# ind &lt;- which(datos_PCF$Species==\"Marmosa sp.\")\n# datos_PCF &lt;- datos_PCF[-ind,]\n\n# filter y1\ndatay_2022 &lt;- cam_deploy_image |&gt; filter(samp_year ==2022) # |&gt; \n  # filter(samp_year==2022) \n\nDetHist_list_2022 &lt;- lapply(unique(datay_2022$scientificName), FUN = function(x) {\n  detectionHistory(\n    recordTable         = datay_2022, # Tabla de registros\n    camOp                = camop_2022, # Matriz de operación de cámaras\n    stationCol           = \"deployment_id\",\n    speciesCol           = \"scientificName\",\n    recordDateTimeCol    = \"timestamp\",\n    recordDateTimeFormat  = \"%Y-%m-%d %H:%M:%S\",\n    species              = x,     # la función reemplaza x por cada una de las especies\n    occasionLength       = 25, # Colapso de las historias a días\n    day1                 = \"station\", #inicie en la fecha de cada survey\n    datesAsOccasionNames = FALSE,\n    includeEffort        = TRUE,\n    scaleEffort          = FALSE,\n    unmarkedMultFrameInput=TRUE,\n    timeZone             = \"America/Bogota\" \n    )\n  }\n)\n\n# names\nnames(DetHist_list_2022) &lt;- unique(datay_2022$scientificName)\n\n# Finalmente creamos una lista nueva donde estén solo las historias de detección\nylist_2022 &lt;- lapply(DetHist_list_2022, FUN = function(x) x$detection_history)\neffortlist_2022 &lt;- lapply(DetHist_list_2022, FUN = function(x) x$effort)\n\n### Danta, Jaguar\n### Danta, Jaguar\nwhich(names(ylist_2022) ==\"Tapirus bairdii\")\n#&gt; [1] 21\nwhich(names(ylist_2022) ==\"Panthera onca\") \n#&gt; [1] 19"
  },
  {
    "objectID": "posts/2024-07-17-stackmodel/index.html#save-and-fix-in-excel-if-it-is-needed",
    "href": "posts/2024-07-17-stackmodel/index.html#save-and-fix-in-excel-if-it-is-needed",
    "title": "“Stacked” Models",
    "section": "Save and fix in excel if it is needed",
    "text": "Save and fix in excel if it is needed\nWe are using the data for the Jaguar\n\nCode# Jaguar\n# datatable (ylist_2021[[5]], caption = 'Jaguar 2021')\n# datatable (ylist_2022[[19]], caption = 'Jaguar 2022')\n\n# y obs\nwrite.csv(ylist_2021[[5]], \"C:/CodigoR/CameraTrapCesar/data/katios/stacked/y_jaguar2021.csv\")\n# effort\nwrite.csv(effortlist_2021[[5]], \"C:/CodigoR/CameraTrapCesar/data/katios/stacked/effort_jaguar2021.csv\")\n# y obs\nwrite.csv(ylist_2022[[19]], \"C:/CodigoR/CameraTrapCesar/data/katios/stacked/y_jaguar2022.csv\")\n# effort\nwrite.csv(effortlist_2022[[5]], \"C:/CodigoR/CameraTrapCesar/data/katios/stacked/effort_jaguar2022.csv\")"
  },
  {
    "objectID": "posts/2024-07-17-stackmodel/index.html#fitting-a-stacked-model-for-the-jaguar",
    "href": "posts/2024-07-17-stackmodel/index.html#fitting-a-stacked-model-for-the-jaguar",
    "title": "“Stacked” Models",
    "section": "Fitting a stacked model for the Jaguar",
    "text": "Fitting a stacked model for the Jaguar\nLets use the ubms package to make a stacked occupancy model pooling 2021 and 2022 data together and use the percent tree cover, the road density and the cattle density as covariates for the occupancy and the effort as the number of sampling days as covariate for detection.\nLoad the data\n\nCodejaguar &lt;- read.csv(\"C:/CodigoR/CameraTrapCesar/data/katios/stacked/y_jaguar_stacked.csv\")\n\n\nLook at the data\n\nCode\ndatatable(head(jaguar))\n\n\n\n\n\nNotice we collapsed the events to 15 days in the 2021 sampling season, and to 25 days in the 2022 sampling season, to end with 6 repeated observations in de matrix. In the matrix o1 to o6 are observations and e1 to e6 are sampling effort (observation-detection covariates). Land_cover, per_tree_cov and roads are site covariates (occupancy covariate).\nCreate an unmarked frame\nWith our stacked dataset constructed, we build the unmarkedFrameOccu() object, organizing detection, non-detection data along with the covariates.\n\nCode\n# fix NA spread\n# yj &lt;- rbind(ylist[[62]][1:30,1:8], # 62 is Jaguar\n#             ylist[[62]][31:50,12:19])\n\n# ej &lt;- rbind(effortlist[[4]][1:30,1:8],\n#             effortlist[[4]][31:50,12:19])\n    \n  \njaguar_covs &lt;- jaguar[,c(8,9,16:19)]\njaguar_covs$year &lt;- as.factor(jaguar_covs$year)\n\numf &lt;- unmarkedFrameOccu(y=jaguar[,2:7], \n                         siteCovs=jaguar_covs,\n                         obsCovs=list(effort=jaguar[10:15])\n                      )\n\nplot(umf)\n\n\n\n\n\n\n\nFit models\nFit the Stacked Model\nWe’ll now we fit a model with fixed effects of percent tree cover road density and cattle density (per_tree_cov, roads and cattle) on occupancy, and a effort as the detection covariate. In addition, we will include random intercepts by site, since in stacking the data we have pseudoreplication by site. To remember, random effects are specified using the same notation used in with the lme4 package. For example, a random intercept for each level of the covariate site is specified with the formula component (1|site). Take in to account, Including random effects in a model in ubms usually significantly increases the run time, but at the end is worth the waiting time.\nNext we perform model selection.\n\nCode# fit_0 &lt;- occu(~1~1, data=umf) # unmarked\n\nfit_j0 &lt;- stan_occu(~1~1 + (1|site),\n                       data=umf, chains=3, iter=50000, cores=3)\nfit_j1 &lt;- stan_occu(~scale(effort) ~1 + (1|site), \n                       data=umf, chains=3, iter=50000)\n#&gt; \n#&gt; SAMPLING FOR MODEL 'occu' NOW (CHAIN 1).\n#&gt; Chain 1: \n#&gt; Chain 1: Gradient evaluation took 0.000159 seconds\n#&gt; Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 1.59 seconds.\n#&gt; Chain 1: Adjust your expectations accordingly!\n#&gt; Chain 1: \n#&gt; Chain 1: \n#&gt; Chain 1: Iteration:     1 / 50000 [  0%]  (Warmup)\n#&gt; Chain 1: Iteration:  5000 / 50000 [ 10%]  (Warmup)\n#&gt; Chain 1: Iteration: 10000 / 50000 [ 20%]  (Warmup)\n#&gt; Chain 1: Iteration: 15000 / 50000 [ 30%]  (Warmup)\n#&gt; Chain 1: Iteration: 20000 / 50000 [ 40%]  (Warmup)\n#&gt; Chain 1: Iteration: 25000 / 50000 [ 50%]  (Warmup)\n#&gt; Chain 1: Iteration: 25001 / 50000 [ 50%]  (Sampling)\n#&gt; Chain 1: Iteration: 30000 / 50000 [ 60%]  (Sampling)\n#&gt; Chain 1: Iteration: 35000 / 50000 [ 70%]  (Sampling)\n#&gt; Chain 1: Iteration: 40000 / 50000 [ 80%]  (Sampling)\n#&gt; Chain 1: Iteration: 45000 / 50000 [ 90%]  (Sampling)\n#&gt; Chain 1: Iteration: 50000 / 50000 [100%]  (Sampling)\n#&gt; Chain 1: \n#&gt; Chain 1:  Elapsed Time: 62.024 seconds (Warm-up)\n#&gt; Chain 1:                62.32 seconds (Sampling)\n#&gt; Chain 1:                124.344 seconds (Total)\n#&gt; Chain 1: \n#&gt; \n#&gt; SAMPLING FOR MODEL 'occu' NOW (CHAIN 2).\n#&gt; Chain 2: \n#&gt; Chain 2: Gradient evaluation took 0.0001 seconds\n#&gt; Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 1 seconds.\n#&gt; Chain 2: Adjust your expectations accordingly!\n#&gt; Chain 2: \n#&gt; Chain 2: \n#&gt; Chain 2: Iteration:     1 / 50000 [  0%]  (Warmup)\n#&gt; Chain 2: Iteration:  5000 / 50000 [ 10%]  (Warmup)\n#&gt; Chain 2: Iteration: 10000 / 50000 [ 20%]  (Warmup)\n#&gt; Chain 2: Iteration: 15000 / 50000 [ 30%]  (Warmup)\n#&gt; Chain 2: Iteration: 20000 / 50000 [ 40%]  (Warmup)\n#&gt; Chain 2: Iteration: 25000 / 50000 [ 50%]  (Warmup)\n#&gt; Chain 2: Iteration: 25001 / 50000 [ 50%]  (Sampling)\n#&gt; Chain 2: Iteration: 30000 / 50000 [ 60%]  (Sampling)\n#&gt; Chain 2: Iteration: 35000 / 50000 [ 70%]  (Sampling)\n#&gt; Chain 2: Iteration: 40000 / 50000 [ 80%]  (Sampling)\n#&gt; Chain 2: Iteration: 45000 / 50000 [ 90%]  (Sampling)\n#&gt; Chain 2: Iteration: 50000 / 50000 [100%]  (Sampling)\n#&gt; Chain 2: \n#&gt; Chain 2:  Elapsed Time: 51.342 seconds (Warm-up)\n#&gt; Chain 2:                99.149 seconds (Sampling)\n#&gt; Chain 2:                150.491 seconds (Total)\n#&gt; Chain 2: \n#&gt; \n#&gt; SAMPLING FOR MODEL 'occu' NOW (CHAIN 3).\n#&gt; Chain 3: \n#&gt; Chain 3: Gradient evaluation took 9.7e-05 seconds\n#&gt; Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.97 seconds.\n#&gt; Chain 3: Adjust your expectations accordingly!\n#&gt; Chain 3: \n#&gt; Chain 3: \n#&gt; Chain 3: Iteration:     1 / 50000 [  0%]  (Warmup)\n#&gt; Chain 3: Iteration:  5000 / 50000 [ 10%]  (Warmup)\n#&gt; Chain 3: Iteration: 10000 / 50000 [ 20%]  (Warmup)\n#&gt; Chain 3: Iteration: 15000 / 50000 [ 30%]  (Warmup)\n#&gt; Chain 3: Iteration: 20000 / 50000 [ 40%]  (Warmup)\n#&gt; Chain 3: Iteration: 25000 / 50000 [ 50%]  (Warmup)\n#&gt; Chain 3: Iteration: 25001 / 50000 [ 50%]  (Sampling)\n#&gt; Chain 3: Iteration: 30000 / 50000 [ 60%]  (Sampling)\n#&gt; Chain 3: Iteration: 35000 / 50000 [ 70%]  (Sampling)\n#&gt; Chain 3: Iteration: 40000 / 50000 [ 80%]  (Sampling)\n#&gt; Chain 3: Iteration: 45000 / 50000 [ 90%]  (Sampling)\n#&gt; Chain 3: Iteration: 50000 / 50000 [100%]  (Sampling)\n#&gt; Chain 3: \n#&gt; Chain 3:  Elapsed Time: 81.282 seconds (Warm-up)\n#&gt; Chain 3:                81.823 seconds (Sampling)\n#&gt; Chain 3:                163.105 seconds (Total)\n#&gt; Chain 3:\nfit_j2 &lt;- stan_occu(~scale(effort) ~scale(per_tree_cov) + (1|site), \n                       data=umf, chains=3, iter=50000)\n#&gt; \n#&gt; SAMPLING FOR MODEL 'occu' NOW (CHAIN 1).\n#&gt; Chain 1: \n#&gt; Chain 1: Gradient evaluation took 0.000104 seconds\n#&gt; Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 1.04 seconds.\n#&gt; Chain 1: Adjust your expectations accordingly!\n#&gt; Chain 1: \n#&gt; Chain 1: \n#&gt; Chain 1: Iteration:     1 / 50000 [  0%]  (Warmup)\n#&gt; Chain 1: Iteration:  5000 / 50000 [ 10%]  (Warmup)\n#&gt; Chain 1: Iteration: 10000 / 50000 [ 20%]  (Warmup)\n#&gt; Chain 1: Iteration: 15000 / 50000 [ 30%]  (Warmup)\n#&gt; Chain 1: Iteration: 20000 / 50000 [ 40%]  (Warmup)\n#&gt; Chain 1: Iteration: 25000 / 50000 [ 50%]  (Warmup)\n#&gt; Chain 1: Iteration: 25001 / 50000 [ 50%]  (Sampling)\n#&gt; Chain 1: Iteration: 30000 / 50000 [ 60%]  (Sampling)\n#&gt; Chain 1: Iteration: 35000 / 50000 [ 70%]  (Sampling)\n#&gt; Chain 1: Iteration: 40000 / 50000 [ 80%]  (Sampling)\n#&gt; Chain 1: Iteration: 45000 / 50000 [ 90%]  (Sampling)\n#&gt; Chain 1: Iteration: 50000 / 50000 [100%]  (Sampling)\n#&gt; Chain 1: \n#&gt; Chain 1:  Elapsed Time: 82.055 seconds (Warm-up)\n#&gt; Chain 1:                70.156 seconds (Sampling)\n#&gt; Chain 1:                152.211 seconds (Total)\n#&gt; Chain 1: \n#&gt; \n#&gt; SAMPLING FOR MODEL 'occu' NOW (CHAIN 2).\n#&gt; Chain 2: \n#&gt; Chain 2: Gradient evaluation took 9.8e-05 seconds\n#&gt; Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.98 seconds.\n#&gt; Chain 2: Adjust your expectations accordingly!\n#&gt; Chain 2: \n#&gt; Chain 2: \n#&gt; Chain 2: Iteration:     1 / 50000 [  0%]  (Warmup)\n#&gt; Chain 2: Iteration:  5000 / 50000 [ 10%]  (Warmup)\n#&gt; Chain 2: Iteration: 10000 / 50000 [ 20%]  (Warmup)\n#&gt; Chain 2: Iteration: 15000 / 50000 [ 30%]  (Warmup)\n#&gt; Chain 2: Iteration: 20000 / 50000 [ 40%]  (Warmup)\n#&gt; Chain 2: Iteration: 25000 / 50000 [ 50%]  (Warmup)\n#&gt; Chain 2: Iteration: 25001 / 50000 [ 50%]  (Sampling)\n#&gt; Chain 2: Iteration: 30000 / 50000 [ 60%]  (Sampling)\n#&gt; Chain 2: Iteration: 35000 / 50000 [ 70%]  (Sampling)\n#&gt; Chain 2: Iteration: 40000 / 50000 [ 80%]  (Sampling)\n#&gt; Chain 2: Iteration: 45000 / 50000 [ 90%]  (Sampling)\n#&gt; Chain 2: Iteration: 50000 / 50000 [100%]  (Sampling)\n#&gt; Chain 2: \n#&gt; Chain 2:  Elapsed Time: 60.193 seconds (Warm-up)\n#&gt; Chain 2:                82.636 seconds (Sampling)\n#&gt; Chain 2:                142.829 seconds (Total)\n#&gt; Chain 2: \n#&gt; \n#&gt; SAMPLING FOR MODEL 'occu' NOW (CHAIN 3).\n#&gt; Chain 3: \n#&gt; Chain 3: Gradient evaluation took 0.000138 seconds\n#&gt; Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 1.38 seconds.\n#&gt; Chain 3: Adjust your expectations accordingly!\n#&gt; Chain 3: \n#&gt; Chain 3: \n#&gt; Chain 3: Iteration:     1 / 50000 [  0%]  (Warmup)\n#&gt; Chain 3: Iteration:  5000 / 50000 [ 10%]  (Warmup)\n#&gt; Chain 3: Iteration: 10000 / 50000 [ 20%]  (Warmup)\n#&gt; Chain 3: Iteration: 15000 / 50000 [ 30%]  (Warmup)\n#&gt; Chain 3: Iteration: 20000 / 50000 [ 40%]  (Warmup)\n#&gt; Chain 3: Iteration: 25000 / 50000 [ 50%]  (Warmup)\n#&gt; Chain 3: Iteration: 25001 / 50000 [ 50%]  (Sampling)\n#&gt; Chain 3: Iteration: 30000 / 50000 [ 60%]  (Sampling)\n#&gt; Chain 3: Iteration: 35000 / 50000 [ 70%]  (Sampling)\n#&gt; Chain 3: Iteration: 40000 / 50000 [ 80%]  (Sampling)\n#&gt; Chain 3: Iteration: 45000 / 50000 [ 90%]  (Sampling)\n#&gt; Chain 3: Iteration: 50000 / 50000 [100%]  (Sampling)\n#&gt; Chain 3: \n#&gt; Chain 3:  Elapsed Time: 62.106 seconds (Warm-up)\n#&gt; Chain 3:                69.241 seconds (Sampling)\n#&gt; Chain 3:                131.347 seconds (Total)\n#&gt; Chain 3:\nfit_j3 &lt;- stan_occu(~scale(effort) ~scale(roads) + (1|site), \n                       data=umf, chains=3, iter=50000)\n#&gt; \n#&gt; SAMPLING FOR MODEL 'occu' NOW (CHAIN 1).\n#&gt; Chain 1: \n#&gt; Chain 1: Gradient evaluation took 9.9e-05 seconds\n#&gt; Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.99 seconds.\n#&gt; Chain 1: Adjust your expectations accordingly!\n#&gt; Chain 1: \n#&gt; Chain 1: \n#&gt; Chain 1: Iteration:     1 / 50000 [  0%]  (Warmup)\n#&gt; Chain 1: Iteration:  5000 / 50000 [ 10%]  (Warmup)\n#&gt; Chain 1: Iteration: 10000 / 50000 [ 20%]  (Warmup)\n#&gt; Chain 1: Iteration: 15000 / 50000 [ 30%]  (Warmup)\n#&gt; Chain 1: Iteration: 20000 / 50000 [ 40%]  (Warmup)\n#&gt; Chain 1: Iteration: 25000 / 50000 [ 50%]  (Warmup)\n#&gt; Chain 1: Iteration: 25001 / 50000 [ 50%]  (Sampling)\n#&gt; Chain 1: Iteration: 30000 / 50000 [ 60%]  (Sampling)\n#&gt; Chain 1: Iteration: 35000 / 50000 [ 70%]  (Sampling)\n#&gt; Chain 1: Iteration: 40000 / 50000 [ 80%]  (Sampling)\n#&gt; Chain 1: Iteration: 45000 / 50000 [ 90%]  (Sampling)\n#&gt; Chain 1: Iteration: 50000 / 50000 [100%]  (Sampling)\n#&gt; Chain 1: \n#&gt; Chain 1:  Elapsed Time: 56.59 seconds (Warm-up)\n#&gt; Chain 1:                79.364 seconds (Sampling)\n#&gt; Chain 1:                135.954 seconds (Total)\n#&gt; Chain 1: \n#&gt; \n#&gt; SAMPLING FOR MODEL 'occu' NOW (CHAIN 2).\n#&gt; Chain 2: \n#&gt; Chain 2: Gradient evaluation took 9.7e-05 seconds\n#&gt; Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.97 seconds.\n#&gt; Chain 2: Adjust your expectations accordingly!\n#&gt; Chain 2: \n#&gt; Chain 2: \n#&gt; Chain 2: Iteration:     1 / 50000 [  0%]  (Warmup)\n#&gt; Chain 2: Iteration:  5000 / 50000 [ 10%]  (Warmup)\n#&gt; Chain 2: Iteration: 10000 / 50000 [ 20%]  (Warmup)\n#&gt; Chain 2: Iteration: 15000 / 50000 [ 30%]  (Warmup)\n#&gt; Chain 2: Iteration: 20000 / 50000 [ 40%]  (Warmup)\n#&gt; Chain 2: Iteration: 25000 / 50000 [ 50%]  (Warmup)\n#&gt; Chain 2: Iteration: 25001 / 50000 [ 50%]  (Sampling)\n#&gt; Chain 2: Iteration: 30000 / 50000 [ 60%]  (Sampling)\n#&gt; Chain 2: Iteration: 35000 / 50000 [ 70%]  (Sampling)\n#&gt; Chain 2: Iteration: 40000 / 50000 [ 80%]  (Sampling)\n#&gt; Chain 2: Iteration: 45000 / 50000 [ 90%]  (Sampling)\n#&gt; Chain 2: Iteration: 50000 / 50000 [100%]  (Sampling)\n#&gt; Chain 2: \n#&gt; Chain 2:  Elapsed Time: 79.361 seconds (Warm-up)\n#&gt; Chain 2:                83.312 seconds (Sampling)\n#&gt; Chain 2:                162.673 seconds (Total)\n#&gt; Chain 2: \n#&gt; \n#&gt; SAMPLING FOR MODEL 'occu' NOW (CHAIN 3).\n#&gt; Chain 3: \n#&gt; Chain 3: Gradient evaluation took 9.8e-05 seconds\n#&gt; Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.98 seconds.\n#&gt; Chain 3: Adjust your expectations accordingly!\n#&gt; Chain 3: \n#&gt; Chain 3: \n#&gt; Chain 3: Iteration:     1 / 50000 [  0%]  (Warmup)\n#&gt; Chain 3: Iteration:  5000 / 50000 [ 10%]  (Warmup)\n#&gt; Chain 3: Iteration: 10000 / 50000 [ 20%]  (Warmup)\n#&gt; Chain 3: Iteration: 15000 / 50000 [ 30%]  (Warmup)\n#&gt; Chain 3: Iteration: 20000 / 50000 [ 40%]  (Warmup)\n#&gt; Chain 3: Iteration: 25000 / 50000 [ 50%]  (Warmup)\n#&gt; Chain 3: Iteration: 25001 / 50000 [ 50%]  (Sampling)\n#&gt; Chain 3: Iteration: 30000 / 50000 [ 60%]  (Sampling)\n#&gt; Chain 3: Iteration: 35000 / 50000 [ 70%]  (Sampling)\n#&gt; Chain 3: Iteration: 40000 / 50000 [ 80%]  (Sampling)\n#&gt; Chain 3: Iteration: 45000 / 50000 [ 90%]  (Sampling)\n#&gt; Chain 3: Iteration: 50000 / 50000 [100%]  (Sampling)\n#&gt; Chain 3: \n#&gt; Chain 3:  Elapsed Time: 90.606 seconds (Warm-up)\n#&gt; Chain 3:                142.612 seconds (Sampling)\n#&gt; Chain 3:                233.218 seconds (Total)\n#&gt; Chain 3:\nfit_j4 &lt;- stan_occu(~scale(effort) ~scale(cattle) + (1|site), \n                       data=umf, chains=3, iter=50000)\n#&gt; \n#&gt; SAMPLING FOR MODEL 'occu' NOW (CHAIN 1).\n#&gt; Chain 1: \n#&gt; Chain 1: Gradient evaluation took 9.9e-05 seconds\n#&gt; Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.99 seconds.\n#&gt; Chain 1: Adjust your expectations accordingly!\n#&gt; Chain 1: \n#&gt; Chain 1: \n#&gt; Chain 1: Iteration:     1 / 50000 [  0%]  (Warmup)\n#&gt; Chain 1: Iteration:  5000 / 50000 [ 10%]  (Warmup)\n#&gt; Chain 1: Iteration: 10000 / 50000 [ 20%]  (Warmup)\n#&gt; Chain 1: Iteration: 15000 / 50000 [ 30%]  (Warmup)\n#&gt; Chain 1: Iteration: 20000 / 50000 [ 40%]  (Warmup)\n#&gt; Chain 1: Iteration: 25000 / 50000 [ 50%]  (Warmup)\n#&gt; Chain 1: Iteration: 25001 / 50000 [ 50%]  (Sampling)\n#&gt; Chain 1: Iteration: 30000 / 50000 [ 60%]  (Sampling)\n#&gt; Chain 1: Iteration: 35000 / 50000 [ 70%]  (Sampling)\n#&gt; Chain 1: Iteration: 40000 / 50000 [ 80%]  (Sampling)\n#&gt; Chain 1: Iteration: 45000 / 50000 [ 90%]  (Sampling)\n#&gt; Chain 1: Iteration: 50000 / 50000 [100%]  (Sampling)\n#&gt; Chain 1: \n#&gt; Chain 1:  Elapsed Time: 58.057 seconds (Warm-up)\n#&gt; Chain 1:                83.491 seconds (Sampling)\n#&gt; Chain 1:                141.548 seconds (Total)\n#&gt; Chain 1: \n#&gt; \n#&gt; SAMPLING FOR MODEL 'occu' NOW (CHAIN 2).\n#&gt; Chain 2: \n#&gt; Chain 2: Gradient evaluation took 9.7e-05 seconds\n#&gt; Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.97 seconds.\n#&gt; Chain 2: Adjust your expectations accordingly!\n#&gt; Chain 2: \n#&gt; Chain 2: \n#&gt; Chain 2: Iteration:     1 / 50000 [  0%]  (Warmup)\n#&gt; Chain 2: Iteration:  5000 / 50000 [ 10%]  (Warmup)\n#&gt; Chain 2: Iteration: 10000 / 50000 [ 20%]  (Warmup)\n#&gt; Chain 2: Iteration: 15000 / 50000 [ 30%]  (Warmup)\n#&gt; Chain 2: Iteration: 20000 / 50000 [ 40%]  (Warmup)\n#&gt; Chain 2: Iteration: 25000 / 50000 [ 50%]  (Warmup)\n#&gt; Chain 2: Iteration: 25001 / 50000 [ 50%]  (Sampling)\n#&gt; Chain 2: Iteration: 30000 / 50000 [ 60%]  (Sampling)\n#&gt; Chain 2: Iteration: 35000 / 50000 [ 70%]  (Sampling)\n#&gt; Chain 2: Iteration: 40000 / 50000 [ 80%]  (Sampling)\n#&gt; Chain 2: Iteration: 45000 / 50000 [ 90%]  (Sampling)\n#&gt; Chain 2: Iteration: 50000 / 50000 [100%]  (Sampling)\n#&gt; Chain 2: \n#&gt; Chain 2:  Elapsed Time: 67.705 seconds (Warm-up)\n#&gt; Chain 2:                81.827 seconds (Sampling)\n#&gt; Chain 2:                149.532 seconds (Total)\n#&gt; Chain 2: \n#&gt; \n#&gt; SAMPLING FOR MODEL 'occu' NOW (CHAIN 3).\n#&gt; Chain 3: \n#&gt; Chain 3: Gradient evaluation took 9.5e-05 seconds\n#&gt; Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.95 seconds.\n#&gt; Chain 3: Adjust your expectations accordingly!\n#&gt; Chain 3: \n#&gt; Chain 3: \n#&gt; Chain 3: Iteration:     1 / 50000 [  0%]  (Warmup)\n#&gt; Chain 3: Iteration:  5000 / 50000 [ 10%]  (Warmup)\n#&gt; Chain 3: Iteration: 10000 / 50000 [ 20%]  (Warmup)\n#&gt; Chain 3: Iteration: 15000 / 50000 [ 30%]  (Warmup)\n#&gt; Chain 3: Iteration: 20000 / 50000 [ 40%]  (Warmup)\n#&gt; Chain 3: Iteration: 25000 / 50000 [ 50%]  (Warmup)\n#&gt; Chain 3: Iteration: 25001 / 50000 [ 50%]  (Sampling)\n#&gt; Chain 3: Iteration: 30000 / 50000 [ 60%]  (Sampling)\n#&gt; Chain 3: Iteration: 35000 / 50000 [ 70%]  (Sampling)\n#&gt; Chain 3: Iteration: 40000 / 50000 [ 80%]  (Sampling)\n#&gt; Chain 3: Iteration: 45000 / 50000 [ 90%]  (Sampling)\n#&gt; Chain 3: Iteration: 50000 / 50000 [100%]  (Sampling)\n#&gt; Chain 3: \n#&gt; Chain 3:  Elapsed Time: 50.122 seconds (Warm-up)\n#&gt; Chain 3:                91.64 seconds (Sampling)\n#&gt; Chain 3:                141.762 seconds (Total)\n#&gt; Chain 3:\n# compare\nmodels &lt;- list(Null = fit_j0,\n                effort = fit_j1,\n                effort_treecov = fit_j2,\n                effort_road = fit_j3,\n                effort_cattle = fit_j4)\n\nmods &lt;- fitList(fits = models)\n\n\n## see model selection as a table\ndatatable( \n  round(modSel(mods), 3)\n  )\n\n\n\n\n\nInstead of AIC, models are compared using leave-one-out cross-validation (LOO) (Vehtari, Gelman, and Gabry 2017) via the loo package. Based on this cross-validation, the expected predictive accuracy (elpd) for each model is calculated. The model with the largest elpd (effort_cattle) performed best. The looic value is analogous to AIC.\n\nCodeloo(fit_j4)\n#&gt; \n#&gt; Computed from 75000 by 53 log-likelihood matrix.\n#&gt; \n#&gt;          Estimate   SE\n#&gt; elpd_loo    -54.8 13.5\n#&gt; p_loo         4.3  1.0\n#&gt; looic       109.5 27.0\n#&gt; ------\n#&gt; MCSE of elpd_loo is 0.0.\n#&gt; MCSE and ESS estimates assume MCMC draws (r_eff in [0.1, 0.7]).\n#&gt; \n#&gt; All Pareto k estimates are good (k &lt; 0.7).\n#&gt; See help('pareto-k-diagnostic') for details.\n\n\n\nBest model is effort_cattle (fit_j4) which has effort on detection and percent tree cover on occupancy.\n\n\nCodefit_j4\n#&gt; \n#&gt; Call:\n#&gt; stan_occu(formula = ~scale(effort) ~ scale(cattle) + (1 | site), \n#&gt;     data = umf, chains = 3, iter = 50000)\n#&gt; \n#&gt; Occupancy (logit-scale):\n#&gt;                Estimate    SD    2.5% 97.5% n_eff Rhat\n#&gt; (Intercept)      -1.301 0.770 -2.7196 0.358  8064    1\n#&gt; scale(cattle)    -1.252 1.066 -3.7744 0.345 14017    1\n#&gt; sigma [1|site]    0.685 0.659  0.0652 2.460   946    1\n#&gt; \n#&gt; Detection (logit-scale):\n#&gt;               Estimate    SD   2.5%  97.5% n_eff Rhat\n#&gt; (Intercept)     -1.630 0.484 -2.656 -0.772  8482    1\n#&gt; scale(effort)    0.326 0.355 -0.341  1.050 17670    1\n#&gt; \n#&gt; LOOIC: 109.528\n#&gt; Runtime: 7.214 min\n\n\nLooking at the summary of fit_j4, we conclude MCMC chains have converged if all R^&gt;1.05 To visualize convergence, look at the traceplots:\n\nCodetraceplot(fit_j4, pars=c(\"beta_state\", \"beta_det\"))\n\n\n\n\n\n\n\nEvaluate model fit\nStatistic should be near 0.5 if the model fits well.\n\nCode# eval\nfit_top_gof &lt;- gof(fit_j4, draws=500, quiet=TRUE)\nfit_top_gof\n#&gt; MacKenzie-Bailey Chi-square \n#&gt; Point estimate = 52.16\n#&gt; Posterior predictive p = 0.474\n\nplot(fit_top_gof)\n\n\n\n\n\n\n\nModel inference\nEffort in detection and cattle density in occupancy\n\nCodeubms::plot_effects(fit_j4, \"det\")\n\n\n\n\n\n\nCodeubms::plot_effects(fit_j4, \"state\")"
  },
  {
    "objectID": "posts/2024-07-17-stackmodel/index.html#comparing-occupancy-between-years",
    "href": "posts/2024-07-17-stackmodel/index.html#comparing-occupancy-between-years",
    "title": "“Stacked” Models",
    "section": "Comparing occupancy between years",
    "text": "Comparing occupancy between years\nUsing the posterior_predict function in ubms, you can generate an equivalent posterior distribution of z, and latter to do a post-hoc analyses to test for a difference in mean occupancy probability between sites 2021 and sites 2022.\n\nCodezpost &lt;- posterior_predict(fit_j4, \"z\", draws=1000)\ndim(zpost)\n#&gt; [1] 1000   55\n\nyear_2021 &lt;- rowMeans(zpost[,1:32], na.rm=TRUE) \nyear_2022 &lt;- rowMeans(zpost[,33:55], na.rm=TRUE)\n\nplot_dat &lt;- rbind(data.frame(group=\"year_2021\", occ=mean(year_2021),\n                             lower=quantile(year_2021, 0.025),\n                             upper=quantile(year_2021, 0.975)),\n                  data.frame(group=\"year_2022\", occ=mean(year_2022),\n                             lower=quantile(year_2022, 0.025),\n                             upper=quantile(year_2022, 0.975)))\n\n# Now plot the posterior distributions of the two means:\n\n\na &lt;- ggplot(plot_dat, aes(x=group, y=occ)) +\n  geom_errorbar(aes(ymin=lower, ymax=upper), width=0.2) +\n  geom_point(size=3) +\n  ylim(0.1, 0.85) +\n  labs(x=\"Year\", y=\"Occupancy + 95% UI\") +\n  theme_bw() +\n  theme(panel.grid.major=element_blank(), panel.grid.minor=element_blank(),\n        axis.text=element_text(size=12), axis.title=element_text(size=14))\n\n# print graph\na\n\n\n\n\n\n\n\nIt seems there is a reduction in mean occupancy probability, but the difference in mean occupancy probability between years is not significant.\nComparing against year in occupancy\n\nCodefit_j5 &lt;- stan_occu(~scale(effort) ~scale(cattle) + year + (1|site), \n                       data=umf, chains=3, iter=50000)\n#&gt; \n#&gt; SAMPLING FOR MODEL 'occu' NOW (CHAIN 1).\n#&gt; Chain 1: \n#&gt; Chain 1: Gradient evaluation took 0.000101 seconds\n#&gt; Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 1.01 seconds.\n#&gt; Chain 1: Adjust your expectations accordingly!\n#&gt; Chain 1: \n#&gt; Chain 1: \n#&gt; Chain 1: Iteration:     1 / 50000 [  0%]  (Warmup)\n#&gt; Chain 1: Iteration:  5000 / 50000 [ 10%]  (Warmup)\n#&gt; Chain 1: Iteration: 10000 / 50000 [ 20%]  (Warmup)\n#&gt; Chain 1: Iteration: 15000 / 50000 [ 30%]  (Warmup)\n#&gt; Chain 1: Iteration: 20000 / 50000 [ 40%]  (Warmup)\n#&gt; Chain 1: Iteration: 25000 / 50000 [ 50%]  (Warmup)\n#&gt; Chain 1: Iteration: 25001 / 50000 [ 50%]  (Sampling)\n#&gt; Chain 1: Iteration: 30000 / 50000 [ 60%]  (Sampling)\n#&gt; Chain 1: Iteration: 35000 / 50000 [ 70%]  (Sampling)\n#&gt; Chain 1: Iteration: 40000 / 50000 [ 80%]  (Sampling)\n#&gt; Chain 1: Iteration: 45000 / 50000 [ 90%]  (Sampling)\n#&gt; Chain 1: Iteration: 50000 / 50000 [100%]  (Sampling)\n#&gt; Chain 1: \n#&gt; Chain 1:  Elapsed Time: 81.797 seconds (Warm-up)\n#&gt; Chain 1:                110.592 seconds (Sampling)\n#&gt; Chain 1:                192.389 seconds (Total)\n#&gt; Chain 1: \n#&gt; \n#&gt; SAMPLING FOR MODEL 'occu' NOW (CHAIN 2).\n#&gt; Chain 2: \n#&gt; Chain 2: Gradient evaluation took 9.9e-05 seconds\n#&gt; Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.99 seconds.\n#&gt; Chain 2: Adjust your expectations accordingly!\n#&gt; Chain 2: \n#&gt; Chain 2: \n#&gt; Chain 2: Iteration:     1 / 50000 [  0%]  (Warmup)\n#&gt; Chain 2: Iteration:  5000 / 50000 [ 10%]  (Warmup)\n#&gt; Chain 2: Iteration: 10000 / 50000 [ 20%]  (Warmup)\n#&gt; Chain 2: Iteration: 15000 / 50000 [ 30%]  (Warmup)\n#&gt; Chain 2: Iteration: 20000 / 50000 [ 40%]  (Warmup)\n#&gt; Chain 2: Iteration: 25000 / 50000 [ 50%]  (Warmup)\n#&gt; Chain 2: Iteration: 25001 / 50000 [ 50%]  (Sampling)\n#&gt; Chain 2: Iteration: 30000 / 50000 [ 60%]  (Sampling)\n#&gt; Chain 2: Iteration: 35000 / 50000 [ 70%]  (Sampling)\n#&gt; Chain 2: Iteration: 40000 / 50000 [ 80%]  (Sampling)\n#&gt; Chain 2: Iteration: 45000 / 50000 [ 90%]  (Sampling)\n#&gt; Chain 2: Iteration: 50000 / 50000 [100%]  (Sampling)\n#&gt; Chain 2: \n#&gt; Chain 2:  Elapsed Time: 54.83 seconds (Warm-up)\n#&gt; Chain 2:                93.65 seconds (Sampling)\n#&gt; Chain 2:                148.48 seconds (Total)\n#&gt; Chain 2: \n#&gt; \n#&gt; SAMPLING FOR MODEL 'occu' NOW (CHAIN 3).\n#&gt; Chain 3: \n#&gt; Chain 3: Gradient evaluation took 0.000101 seconds\n#&gt; Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 1.01 seconds.\n#&gt; Chain 3: Adjust your expectations accordingly!\n#&gt; Chain 3: \n#&gt; Chain 3: \n#&gt; Chain 3: Iteration:     1 / 50000 [  0%]  (Warmup)\n#&gt; Chain 3: Iteration:  5000 / 50000 [ 10%]  (Warmup)\n#&gt; Chain 3: Iteration: 10000 / 50000 [ 20%]  (Warmup)\n#&gt; Chain 3: Iteration: 15000 / 50000 [ 30%]  (Warmup)\n#&gt; Chain 3: Iteration: 20000 / 50000 [ 40%]  (Warmup)\n#&gt; Chain 3: Iteration: 25000 / 50000 [ 50%]  (Warmup)\n#&gt; Chain 3: Iteration: 25001 / 50000 [ 50%]  (Sampling)\n#&gt; Chain 3: Iteration: 30000 / 50000 [ 60%]  (Sampling)\n#&gt; Chain 3: Iteration: 35000 / 50000 [ 70%]  (Sampling)\n#&gt; Chain 3: Iteration: 40000 / 50000 [ 80%]  (Sampling)\n#&gt; Chain 3: Iteration: 45000 / 50000 [ 90%]  (Sampling)\n#&gt; Chain 3: Iteration: 50000 / 50000 [100%]  (Sampling)\n#&gt; Chain 3: \n#&gt; Chain 3:  Elapsed Time: 68.66 seconds (Warm-up)\n#&gt; Chain 3:                70.125 seconds (Sampling)\n#&gt; Chain 3:                138.785 seconds (Total)\n#&gt; Chain 3:\n\nfit_j6 &lt;- stan_occu(~scale(effort) ~ year + (1|site), \n                       data=umf, chains=3, iter=50000)\n#&gt; \n#&gt; SAMPLING FOR MODEL 'occu' NOW (CHAIN 1).\n#&gt; Chain 1: \n#&gt; Chain 1: Gradient evaluation took 9.8e-05 seconds\n#&gt; Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.98 seconds.\n#&gt; Chain 1: Adjust your expectations accordingly!\n#&gt; Chain 1: \n#&gt; Chain 1: \n#&gt; Chain 1: Iteration:     1 / 50000 [  0%]  (Warmup)\n#&gt; Chain 1: Iteration:  5000 / 50000 [ 10%]  (Warmup)\n#&gt; Chain 1: Iteration: 10000 / 50000 [ 20%]  (Warmup)\n#&gt; Chain 1: Iteration: 15000 / 50000 [ 30%]  (Warmup)\n#&gt; Chain 1: Iteration: 20000 / 50000 [ 40%]  (Warmup)\n#&gt; Chain 1: Iteration: 25000 / 50000 [ 50%]  (Warmup)\n#&gt; Chain 1: Iteration: 25001 / 50000 [ 50%]  (Sampling)\n#&gt; Chain 1: Iteration: 30000 / 50000 [ 60%]  (Sampling)\n#&gt; Chain 1: Iteration: 35000 / 50000 [ 70%]  (Sampling)\n#&gt; Chain 1: Iteration: 40000 / 50000 [ 80%]  (Sampling)\n#&gt; Chain 1: Iteration: 45000 / 50000 [ 90%]  (Sampling)\n#&gt; Chain 1: Iteration: 50000 / 50000 [100%]  (Sampling)\n#&gt; Chain 1: \n#&gt; Chain 1:  Elapsed Time: 58.518 seconds (Warm-up)\n#&gt; Chain 1:                63.123 seconds (Sampling)\n#&gt; Chain 1:                121.641 seconds (Total)\n#&gt; Chain 1: \n#&gt; \n#&gt; SAMPLING FOR MODEL 'occu' NOW (CHAIN 2).\n#&gt; Chain 2: \n#&gt; Chain 2: Gradient evaluation took 9.8e-05 seconds\n#&gt; Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.98 seconds.\n#&gt; Chain 2: Adjust your expectations accordingly!\n#&gt; Chain 2: \n#&gt; Chain 2: \n#&gt; Chain 2: Iteration:     1 / 50000 [  0%]  (Warmup)\n#&gt; Chain 2: Iteration:  5000 / 50000 [ 10%]  (Warmup)\n#&gt; Chain 2: Iteration: 10000 / 50000 [ 20%]  (Warmup)\n#&gt; Chain 2: Iteration: 15000 / 50000 [ 30%]  (Warmup)\n#&gt; Chain 2: Iteration: 20000 / 50000 [ 40%]  (Warmup)\n#&gt; Chain 2: Iteration: 25000 / 50000 [ 50%]  (Warmup)\n#&gt; Chain 2: Iteration: 25001 / 50000 [ 50%]  (Sampling)\n#&gt; Chain 2: Iteration: 30000 / 50000 [ 60%]  (Sampling)\n#&gt; Chain 2: Iteration: 35000 / 50000 [ 70%]  (Sampling)\n#&gt; Chain 2: Iteration: 40000 / 50000 [ 80%]  (Sampling)\n#&gt; Chain 2: Iteration: 45000 / 50000 [ 90%]  (Sampling)\n#&gt; Chain 2: Iteration: 50000 / 50000 [100%]  (Sampling)\n#&gt; Chain 2: \n#&gt; Chain 2:  Elapsed Time: 49.211 seconds (Warm-up)\n#&gt; Chain 2:                78.764 seconds (Sampling)\n#&gt; Chain 2:                127.975 seconds (Total)\n#&gt; Chain 2: \n#&gt; \n#&gt; SAMPLING FOR MODEL 'occu' NOW (CHAIN 3).\n#&gt; Chain 3: \n#&gt; Chain 3: Gradient evaluation took 9.8e-05 seconds\n#&gt; Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.98 seconds.\n#&gt; Chain 3: Adjust your expectations accordingly!\n#&gt; Chain 3: \n#&gt; Chain 3: \n#&gt; Chain 3: Iteration:     1 / 50000 [  0%]  (Warmup)\n#&gt; Chain 3: Iteration:  5000 / 50000 [ 10%]  (Warmup)\n#&gt; Chain 3: Iteration: 10000 / 50000 [ 20%]  (Warmup)\n#&gt; Chain 3: Iteration: 15000 / 50000 [ 30%]  (Warmup)\n#&gt; Chain 3: Iteration: 20000 / 50000 [ 40%]  (Warmup)\n#&gt; Chain 3: Iteration: 25000 / 50000 [ 50%]  (Warmup)\n#&gt; Chain 3: Iteration: 25001 / 50000 [ 50%]  (Sampling)\n#&gt; Chain 3: Iteration: 30000 / 50000 [ 60%]  (Sampling)\n#&gt; Chain 3: Iteration: 35000 / 50000 [ 70%]  (Sampling)\n#&gt; Chain 3: Iteration: 40000 / 50000 [ 80%]  (Sampling)\n#&gt; Chain 3: Iteration: 45000 / 50000 [ 90%]  (Sampling)\n#&gt; Chain 3: Iteration: 50000 / 50000 [100%]  (Sampling)\n#&gt; Chain 3: \n#&gt; Chain 3:  Elapsed Time: 58.802 seconds (Warm-up)\n#&gt; Chain 3:                232.844 seconds (Sampling)\n#&gt; Chain 3:                291.646 seconds (Total)\n#&gt; Chain 3:\n\n# compare\nmodels2 &lt;- list(Null = fit_j0,\n                effort_cattle = fit_j4,\n                effort_cattle_yr = fit_j5,\n                effort_yr = fit_j6)\n\nmods2 &lt;- fitList(fits = models2)\n\n## see model selection as a table\ndatatable( \n  round(modSel(mods2), 3)\n  )\n\n\n\n\n\nPlot year in occupancy model\nFirst the plot extracting posteriors, second using year as covariate\n\nCodeb &lt;- ubms::plot_effects(fit_j6, \"state\", level=0.95)\n\nlibrary(patchwork)\na + b\n\n\n\n\n\n\n\nIt seems to be better to extract the years from the posteriors.\nLets make a Bayes two Sample t-test to check differences in posteriors of occupancy between years\nFor this we use the old but reliable BayesianFirstAid package. Notice you need to install the package from github. The goal of Bayesian First Aid is to bring in some of the benefits of cookbook solutions and make it easy to start doing Bayesian data analysis. The target audience is people that are curious about Bayesian statistics, that perhaps have some experience with classical statistics and that would want to see what reasonable Bayesian alternatives would be to their favorite statistical tests.\n\nCodeposterior_totest &lt;- data.frame(posterior_occu=\n                                 as.vector(c(year_2021, \n                                             year_2022)))\nposterior_totest$year &lt;- as.factor(c(rep(\"2021\",1000), rep(\"2022\",1000)))\n\n# \n# devtools::install_github(\"rasmusab/bayesian_first_aid\")\nlibrary(BayesianFirstAid)\nfit &lt;- bayes.t.test(year_2021, year_2022)\nprint(fit)\n#&gt; \n#&gt;  Bayesian estimation supersedes the t test (BEST) - two sample\n#&gt; \n#&gt; data: year_2021 (n = 1000) and year_2022 (n = 1000)\n#&gt; \n#&gt;   Estimates [95% credible interval]\n#&gt; mean of year_2021: 0.30 [0.29, 0.30]\n#&gt; mean of year_2022: 0.20 [0.20, 0.21]\n#&gt; difference of the means: 0.094 [0.086, 0.10]\n#&gt; sd of year_2021: 0.078 [0.072, 0.084]\n#&gt; sd of year_2022: 0.071 [0.066, 0.077]\n#&gt; \n#&gt; The difference of the means is greater than 0 by a probability of &gt;0.999 \n#&gt; and less than 0 by a probability of &lt;0.001\nplot(fit)\n\n\n\n\n\n\nCode\n# traditional anova\n# anov &lt;- glm(posterior_occu ~ year, data = posterior_totest)\n\n# Another Bayes t test\n# library(bayesAB)\n# AB1 &lt;- bayesTest(as.vector(year_2021), \n#                 as.vector(year_2022), \n#                  priors = c('mu' = 0.5, \n#                             'lambda' = 1, \n#                             'alpha' = 3, \n#                             'beta' = 1), \n#                 distribution = 'normal')\n\n# summary(AB1)\n# plot(AB1)\n\n\nLets make a similar test using Bayes Factors\nHowever this time we test if occupancy from the posteriors in 2022 is &lt; than occupancy from the posteriors in 2021.\n\nCode\nlibrary(rstanarm)\n\nmodel &lt;- stan_glm(\n  formula = posterior_occu ~ year,\n  data = posterior_totest,\n  prior = student_t(1, 0.3, autoscale = TRUE),\n  chains = 3, iter = 50000, warmup = 1000\n)\n#&gt; \n#&gt; SAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).\n#&gt; Chain 1: \n#&gt; Chain 1: Gradient evaluation took 0.000141 seconds\n#&gt; Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 1.41 seconds.\n#&gt; Chain 1: Adjust your expectations accordingly!\n#&gt; Chain 1: \n#&gt; Chain 1: \n#&gt; Chain 1: Iteration:     1 / 50000 [  0%]  (Warmup)\n#&gt; Chain 1: Iteration:  1001 / 50000 [  2%]  (Sampling)\n#&gt; Chain 1: Iteration:  6000 / 50000 [ 12%]  (Sampling)\n#&gt; Chain 1: Iteration: 11000 / 50000 [ 22%]  (Sampling)\n#&gt; Chain 1: Iteration: 16000 / 50000 [ 32%]  (Sampling)\n#&gt; Chain 1: Iteration: 21000 / 50000 [ 42%]  (Sampling)\n#&gt; Chain 1: Iteration: 26000 / 50000 [ 52%]  (Sampling)\n#&gt; Chain 1: Iteration: 31000 / 50000 [ 62%]  (Sampling)\n#&gt; Chain 1: Iteration: 36000 / 50000 [ 72%]  (Sampling)\n#&gt; Chain 1: Iteration: 41000 / 50000 [ 82%]  (Sampling)\n#&gt; Chain 1: Iteration: 46000 / 50000 [ 92%]  (Sampling)\n#&gt; Chain 1: Iteration: 50000 / 50000 [100%]  (Sampling)\n#&gt; Chain 1: \n#&gt; Chain 1:  Elapsed Time: 0.079 seconds (Warm-up)\n#&gt; Chain 1:                9.322 seconds (Sampling)\n#&gt; Chain 1:                9.401 seconds (Total)\n#&gt; Chain 1: \n#&gt; \n#&gt; SAMPLING FOR MODEL 'continuous' NOW (CHAIN 2).\n#&gt; Chain 2: \n#&gt; Chain 2: Gradient evaluation took 1.8e-05 seconds\n#&gt; Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.18 seconds.\n#&gt; Chain 2: Adjust your expectations accordingly!\n#&gt; Chain 2: \n#&gt; Chain 2: \n#&gt; Chain 2: Iteration:     1 / 50000 [  0%]  (Warmup)\n#&gt; Chain 2: Iteration:  1001 / 50000 [  2%]  (Sampling)\n#&gt; Chain 2: Iteration:  6000 / 50000 [ 12%]  (Sampling)\n#&gt; Chain 2: Iteration: 11000 / 50000 [ 22%]  (Sampling)\n#&gt; Chain 2: Iteration: 16000 / 50000 [ 32%]  (Sampling)\n#&gt; Chain 2: Iteration: 21000 / 50000 [ 42%]  (Sampling)\n#&gt; Chain 2: Iteration: 26000 / 50000 [ 52%]  (Sampling)\n#&gt; Chain 2: Iteration: 31000 / 50000 [ 62%]  (Sampling)\n#&gt; Chain 2: Iteration: 36000 / 50000 [ 72%]  (Sampling)\n#&gt; Chain 2: Iteration: 41000 / 50000 [ 82%]  (Sampling)\n#&gt; Chain 2: Iteration: 46000 / 50000 [ 92%]  (Sampling)\n#&gt; Chain 2: Iteration: 50000 / 50000 [100%]  (Sampling)\n#&gt; Chain 2: \n#&gt; Chain 2:  Elapsed Time: 0.088 seconds (Warm-up)\n#&gt; Chain 2:                9.335 seconds (Sampling)\n#&gt; Chain 2:                9.423 seconds (Total)\n#&gt; Chain 2: \n#&gt; \n#&gt; SAMPLING FOR MODEL 'continuous' NOW (CHAIN 3).\n#&gt; Chain 3: \n#&gt; Chain 3: Gradient evaluation took 1.9e-05 seconds\n#&gt; Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.19 seconds.\n#&gt; Chain 3: Adjust your expectations accordingly!\n#&gt; Chain 3: \n#&gt; Chain 3: \n#&gt; Chain 3: Iteration:     1 / 50000 [  0%]  (Warmup)\n#&gt; Chain 3: Iteration:  1001 / 50000 [  2%]  (Sampling)\n#&gt; Chain 3: Iteration:  6000 / 50000 [ 12%]  (Sampling)\n#&gt; Chain 3: Iteration: 11000 / 50000 [ 22%]  (Sampling)\n#&gt; Chain 3: Iteration: 16000 / 50000 [ 32%]  (Sampling)\n#&gt; Chain 3: Iteration: 21000 / 50000 [ 42%]  (Sampling)\n#&gt; Chain 3: Iteration: 26000 / 50000 [ 52%]  (Sampling)\n#&gt; Chain 3: Iteration: 31000 / 50000 [ 62%]  (Sampling)\n#&gt; Chain 3: Iteration: 36000 / 50000 [ 72%]  (Sampling)\n#&gt; Chain 3: Iteration: 41000 / 50000 [ 82%]  (Sampling)\n#&gt; Chain 3: Iteration: 46000 / 50000 [ 92%]  (Sampling)\n#&gt; Chain 3: Iteration: 50000 / 50000 [100%]  (Sampling)\n#&gt; Chain 3: \n#&gt; Chain 3:  Elapsed Time: 0.065 seconds (Warm-up)\n#&gt; Chain 3:                9.102 seconds (Sampling)\n#&gt; Chain 3:                9.167 seconds (Total)\n#&gt; Chain 3:\n\n\nlibrary(bayestestR)\n\nMy_first_BF &lt;- bayesfactor_parameters(model, direction = \"&lt;\")\nMy_first_BF\n#&gt; Bayes Factor (Savage-Dickey density ratio)\n#&gt; \n#&gt; Parameter   |       BF\n#&gt; ----------------------\n#&gt; (Intercept) |    0.002\n#&gt; year2022    | 6.93e+22\n#&gt; \n#&gt; * Evidence Against The Null: 0\n#&gt; *                 Direction: Left-Sided test\n\nprint(\n  effectsize::interpret_bf(exp(My_first_BF$log_BF[2]), include_value = TRUE)\n)\n#&gt; [1] \"extreme evidence (BF = 6.93e+22) in favour of\"\n#&gt; (Rules: jeffreys1961)\n\n#library(see)\n#plot(My_first_BF)\n\n\nIn fact occupancy from posteriors are different, and 2022 is &lt; than 2021."
  },
  {
    "objectID": "posts/2024-07-17-stackmodel/index.html#package-citation",
    "href": "posts/2024-07-17-stackmodel/index.html#package-citation",
    "title": "“Stacked” Models",
    "section": "Package Citation",
    "text": "Package Citation\n\nCodepkgs &lt;- cite_packages(output = \"paragraph\", out.dir = \".\") #knitr::kable(pkgs)\npkgs\n\nWe used R v. 4.4.2 (R Core Team 2024) and the following R packages: BayesianFirstAid v. 0.1 (Bååth 2013), bayestestR v. 0.17.0 (Makowski, Ben-Shachar, and Lüdecke 2019), camtrapR v. 3.0.0 (Niedballa et al. 2016), devtools v. 2.4.6 (Wickham et al. 2025), DT v. 0.34.0 (Xie et al. 2025), effectsize v. 1.0.1 (Ben-Shachar, Lüdecke, and Makowski 2020), elevatr v. 0.99.0 (Hollister et al. 2023), kableExtra v. 1.4.0 (Zhu 2024), lme4 v. 1.1.35.5 (Bates et al. 2015), mapview v. 2.11.4 (Appelhans et al. 2025), patchwork v. 1.3.2 (Pedersen 2025), quarto v. 1.5.1 (Allaire and Dervieux 2025), rmarkdown v. 2.30 (Xie, Allaire, and Grolemund 2018; Xie, Dervieux, and Riederer 2020; Allaire et al. 2025), rstanarm v. 2.32.2 (Brilleman et al. 2018; Goodrich et al. 2025), sf v. 1.0.21 (Pebesma 2018; Pebesma and Bivand 2023), styler v. 1.10.3 (Müller and Walthert 2024), terra v. 1.8.70 (Hijmans 2025), tidyverse v. 2.0.0 (Wickham et al. 2019), ubms v. 1.2.8 (Kellner et al. 2021)."
  },
  {
    "objectID": "posts/2024-07-17-stackmodel/index.html#session-info",
    "href": "posts/2024-07-17-stackmodel/index.html#session-info",
    "title": "“Stacked” Models",
    "section": "Session info",
    "text": "Session info\n\nSession info\n\n#&gt; ─ Session info ───────────────────────────────────────────────────────────────────────────────────────────────────────\n#&gt;  setting  value\n#&gt;  version  R version 4.4.2 (2024-10-31 ucrt)\n#&gt;  os       Windows 10 x64 (build 19045)\n#&gt;  system   x86_64, mingw32\n#&gt;  ui       RTerm\n#&gt;  language (EN)\n#&gt;  collate  Spanish_Colombia.utf8\n#&gt;  ctype    Spanish_Colombia.utf8\n#&gt;  tz       America/Bogota\n#&gt;  date     2025-11-05\n#&gt;  pandoc   3.6.3 @ C:/Program Files/RStudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n#&gt;  quarto   NA @ C:\\\\Users\\\\usuario\\\\AppData\\\\Local\\\\Programs\\\\Quarto\\\\bin\\\\quarto.exe\n#&gt; \n#&gt; ─ Packages ───────────────────────────────────────────────────────────────────────────────────────────────────────────\n#&gt;  ! package           * version  date (UTC) lib source\n#&gt;    abind               1.4-8    2024-09-12 [1] CRAN (R 4.4.1)\n#&gt;  D archive             1.1.12   2025-03-20 [1] CRAN (R 4.4.3)\n#&gt;    backports           1.5.0    2024-05-23 [1] CRAN (R 4.4.0)\n#&gt;    base64enc           0.1-3    2015-07-28 [1] CRAN (R 4.4.0)\n#&gt;    BayesianFirstAid  * 0.1      2025-07-18 [1] Github (rasmusab/bayesian_first_aid@d80c0fd)\n#&gt;    bayesplot           1.14.0   2025-08-31 [1] CRAN (R 4.4.3)\n#&gt;    bayestestR        * 0.17.0   2025-08-29 [1] CRAN (R 4.4.3)\n#&gt;    bit                 4.5.0.1  2024-12-03 [1] CRAN (R 4.4.2)\n#&gt;    bit64               4.5.2    2024-09-22 [1] CRAN (R 4.4.2)\n#&gt;    boot                1.3-31   2024-08-28 [2] CRAN (R 4.4.2)\n#&gt;    brew                1.0-10   2023-12-16 [1] CRAN (R 4.4.2)\n#&gt;    bslib               0.9.0    2025-01-30 [1] CRAN (R 4.4.3)\n#&gt;    cachem              1.1.0    2024-05-16 [1] CRAN (R 4.4.2)\n#&gt;    camtrapR          * 3.0.0    2025-09-28 [1] CRAN (R 4.4.3)\n#&gt;    cellranger          1.1.0    2016-07-27 [1] CRAN (R 4.4.2)\n#&gt;    checkmate           2.3.2    2024-07-29 [1] CRAN (R 4.4.2)\n#&gt;    class               7.3-22   2023-05-03 [2] CRAN (R 4.4.2)\n#&gt;    classInt            0.4-11   2025-01-08 [1] CRAN (R 4.4.3)\n#&gt;    cli                 3.6.5    2025-04-23 [1] CRAN (R 4.4.3)\n#&gt;    cluster             2.1.6    2023-12-01 [2] CRAN (R 4.4.2)\n#&gt;    coda              * 0.19-4.1 2024-01-31 [1] CRAN (R 4.4.2)\n#&gt;    codetools           0.2-20   2024-03-31 [2] CRAN (R 4.4.2)\n#&gt;    colourpicker        1.3.0    2023-08-21 [1] CRAN (R 4.4.3)\n#&gt;    crayon              1.5.3    2024-06-20 [1] CRAN (R 4.4.2)\n#&gt;    crosstalk           1.2.1    2023-11-23 [1] CRAN (R 4.4.2)\n#&gt;    curl                7.0.0    2025-08-19 [1] CRAN (R 4.4.3)\n#&gt;    data.table          1.17.8   2025-07-10 [1] CRAN (R 4.4.3)\n#&gt;    datawizard          1.2.0    2025-07-17 [1] CRAN (R 4.4.2)\n#&gt;    DBI                 1.2.3    2024-06-02 [1] CRAN (R 4.4.2)\n#&gt;    devtools            2.4.6    2025-10-03 [1] CRAN (R 4.4.3)\n#&gt;    dichromat           2.0-0.1  2022-05-02 [1] CRAN (R 4.4.0)\n#&gt;    digest              0.6.37   2024-08-19 [1] CRAN (R 4.4.2)\n#&gt;    distributional      0.5.0    2024-09-17 [1] CRAN (R 4.4.2)\n#&gt;    dplyr             * 1.1.4    2023-11-17 [1] CRAN (R 4.4.2)\n#&gt;    DT                * 0.34.0   2025-09-02 [1] CRAN (R 4.4.3)\n#&gt;    dygraphs            1.1.1.6  2018-07-11 [1] CRAN (R 4.4.3)\n#&gt;    e1071               1.7-16   2024-09-16 [1] CRAN (R 4.4.2)\n#&gt;    effectsize          1.0.1    2025-05-27 [1] CRAN (R 4.4.3)\n#&gt;    elevatr           * 0.99.0   2023-09-12 [1] CRAN (R 4.4.2)\n#&gt;    ellipsis            0.3.2    2021-04-29 [1] CRAN (R 4.4.2)\n#&gt;    emmeans             1.11.1   2025-05-04 [1] CRAN (R 4.4.3)\n#&gt;    estimability        1.5.1    2024-05-12 [1] CRAN (R 4.4.3)\n#&gt;    evaluate            1.0.4    2025-06-18 [1] CRAN (R 4.4.3)\n#&gt;    farver              2.1.2    2024-05-13 [1] CRAN (R 4.4.2)\n#&gt;    fastmap             1.2.0    2024-05-15 [1] CRAN (R 4.4.2)\n#&gt;    forcats           * 1.0.0    2023-01-29 [1] CRAN (R 4.4.2)\n#&gt;    fs                  1.6.6    2025-04-12 [1] CRAN (R 4.4.3)\n#&gt;    generics            0.1.3    2022-07-05 [1] CRAN (R 4.4.2)\n#&gt;    ggplot2           * 4.0.0    2025-09-11 [1] CRAN (R 4.4.3)\n#&gt;    glue                1.8.0    2024-09-30 [1] CRAN (R 4.4.2)\n#&gt;    grateful          * 0.3.0    2025-09-04 [1] CRAN (R 4.4.3)\n#&gt;    gridExtra           2.3      2017-09-09 [1] CRAN (R 4.4.2)\n#&gt;    gtable              0.3.6    2024-10-25 [1] CRAN (R 4.4.2)\n#&gt;    gtools              3.9.5    2023-11-20 [1] CRAN (R 4.4.2)\n#&gt;    hms                 1.1.3    2023-03-21 [1] CRAN (R 4.4.2)\n#&gt;    htmltools           0.5.8.1  2024-04-04 [1] CRAN (R 4.4.2)\n#&gt;    htmlwidgets         1.6.4    2023-12-06 [1] CRAN (R 4.4.2)\n#&gt;    httpuv              1.6.16   2025-04-16 [1] CRAN (R 4.4.3)\n#&gt;    igraph              2.1.4    2025-01-23 [1] CRAN (R 4.4.2)\n#&gt;    inline              0.3.20   2024-11-10 [1] CRAN (R 4.4.2)\n#&gt;    insight             1.4.2    2025-09-02 [1] CRAN (R 4.4.3)\n#&gt;    jquerylib           0.1.4    2021-04-26 [1] CRAN (R 4.4.2)\n#&gt;    jsonlite            2.0.0    2025-03-27 [1] CRAN (R 4.4.3)\n#&gt;    kableExtra        * 1.4.0    2024-01-24 [1] CRAN (R 4.4.2)\n#&gt;    KernSmooth          2.23-24  2024-05-17 [2] CRAN (R 4.4.2)\n#&gt;    knitr               1.50     2025-03-16 [1] CRAN (R 4.4.3)\n#&gt;    labeling            0.4.3    2023-08-29 [1] CRAN (R 4.4.0)\n#&gt;    later               1.4.2    2025-04-08 [1] CRAN (R 4.4.3)\n#&gt;    lattice             0.22-6   2024-03-20 [2] CRAN (R 4.4.2)\n#&gt;    leafem              0.2.4    2025-05-01 [1] CRAN (R 4.4.3)\n#&gt;    leaflet             2.2.3    2025-09-04 [1] CRAN (R 4.4.3)\n#&gt;    leaflet.providers   2.0.0    2023-10-17 [1] CRAN (R 4.4.2)\n#&gt;    leafpop             0.1.0    2021-05-22 [1] CRAN (R 4.4.2)\n#&gt;    lifecycle           1.0.4    2023-11-07 [1] CRAN (R 4.4.2)\n#&gt;    lme4              * 1.1-35.5 2024-07-03 [1] CRAN (R 4.4.2)\n#&gt;    logspline           2.1.22   2024-05-10 [1] CRAN (R 4.4.0)\n#&gt;    loo                 2.8.0    2024-07-03 [1] CRAN (R 4.4.2)\n#&gt;    lubridate         * 1.9.4    2024-12-08 [1] CRAN (R 4.4.2)\n#&gt;    magrittr            2.0.3    2022-03-30 [1] CRAN (R 4.4.2)\n#&gt;    mapview           * 2.11.4   2025-09-08 [1] CRAN (R 4.4.3)\n#&gt;    markdown            2.0      2025-03-23 [1] CRAN (R 4.4.3)\n#&gt;    MASS                7.3-61   2024-06-13 [2] CRAN (R 4.4.2)\n#&gt;    Matrix            * 1.7-1    2024-10-18 [2] CRAN (R 4.4.2)\n#&gt;    matrixStats         1.5.0    2025-01-07 [1] CRAN (R 4.4.2)\n#&gt;    memoise             2.0.1    2021-11-26 [1] CRAN (R 4.4.2)\n#&gt;    mgcv                1.9-1    2023-12-21 [2] CRAN (R 4.4.2)\n#&gt;    mime                0.13     2025-03-17 [1] CRAN (R 4.4.3)\n#&gt;    miniUI              0.1.2    2025-04-17 [1] CRAN (R 4.4.3)\n#&gt;    minqa               1.2.8    2024-08-17 [1] CRAN (R 4.4.2)\n#&gt;    multcomp            1.4-28   2025-01-29 [1] CRAN (R 4.4.3)\n#&gt;    mvtnorm             1.3-2    2024-11-04 [1] CRAN (R 4.4.2)\n#&gt;    nlme                3.1-166  2024-08-14 [2] CRAN (R 4.4.2)\n#&gt;    nloptr              2.1.1    2024-06-25 [1] CRAN (R 4.4.2)\n#&gt;    parameters          0.28.2   2025-09-10 [1] CRAN (R 4.4.3)\n#&gt;    patchwork         * 1.3.2    2025-08-25 [1] CRAN (R 4.4.3)\n#&gt;    pbapply             1.7-2    2023-06-27 [1] CRAN (R 4.4.2)\n#&gt;    pillar              1.11.1   2025-09-17 [1] CRAN (R 4.4.2)\n#&gt;    pkgbuild            1.4.8    2025-05-26 [1] CRAN (R 4.4.3)\n#&gt;    pkgconfig           2.0.3    2019-09-22 [1] CRAN (R 4.4.2)\n#&gt;    pkgload             1.4.1    2025-09-23 [1] CRAN (R 4.4.3)\n#&gt;    plyr                1.8.9    2023-10-02 [1] CRAN (R 4.4.2)\n#&gt;    png                 0.1-8    2022-11-29 [1] CRAN (R 4.4.0)\n#&gt;    posterior           1.6.1    2025-03-12 [1] Github (jgabry/posterior@307260e)\n#&gt;    processx            3.8.4    2024-03-16 [1] CRAN (R 4.4.2)\n#&gt;    progressr           0.15.0   2024-10-29 [1] CRAN (R 4.4.2)\n#&gt;    promises            1.3.3    2025-05-29 [1] CRAN (R 4.4.3)\n#&gt;    proxy               0.4-27   2022-06-09 [1] CRAN (R 4.4.2)\n#&gt;    ps                  1.8.1    2024-10-28 [1] CRAN (R 4.4.2)\n#&gt;    purrr             * 1.1.0    2025-07-10 [1] CRAN (R 4.4.3)\n#&gt;    quarto            * 1.5.1    2025-09-04 [1] CRAN (R 4.4.3)\n#&gt;    QuickJSR            1.4.0    2024-10-01 [1] CRAN (R 4.4.2)\n#&gt;    R.cache             0.16.0   2022-07-21 [1] CRAN (R 4.4.2)\n#&gt;    R.methodsS3         1.8.2    2022-06-13 [1] CRAN (R 4.4.0)\n#&gt;    R.oo                1.27.0   2024-11-01 [1] CRAN (R 4.4.1)\n#&gt;    R.utils             2.13.0   2025-02-24 [1] CRAN (R 4.4.3)\n#&gt;    R6                  2.6.1    2025-02-15 [1] CRAN (R 4.4.2)\n#&gt;    raster              3.6-32   2025-03-28 [1] CRAN (R 4.4.3)\n#&gt;    rbibutils           2.3      2024-10-04 [1] CRAN (R 4.4.2)\n#&gt;    RColorBrewer        1.1-3    2022-04-03 [1] CRAN (R 4.4.0)\n#&gt;    Rcpp              * 1.1.0    2025-07-02 [1] CRAN (R 4.4.3)\n#&gt;    RcppNumerical       0.6-0    2023-09-06 [1] CRAN (R 4.4.2)\n#&gt;  D RcppParallel        5.1.9    2024-08-19 [1] CRAN (R 4.4.2)\n#&gt;    Rdpack              2.6.2    2024-11-15 [1] CRAN (R 4.4.2)\n#&gt;    readr             * 2.1.5    2024-01-10 [1] CRAN (R 4.4.2)\n#&gt;    readxl            * 1.4.3    2023-07-06 [1] CRAN (R 4.4.2)\n#&gt;    reformulas          0.4.1    2025-04-30 [1] CRAN (R 4.4.3)\n#&gt;    remotes             2.5.0    2024-03-17 [1] CRAN (R 4.4.3)\n#&gt;    renv                1.0.11   2024-10-12 [1] CRAN (R 4.4.2)\n#&gt;    reshape2            1.4.4    2020-04-09 [1] CRAN (R 4.4.2)\n#&gt;    rjags             * 4-17     2025-03-24 [1] CRAN (R 4.4.3)\n#&gt;    rlang               1.1.6    2025-04-11 [1] CRAN (R 4.4.3)\n#&gt;    rmarkdown           2.30     2025-09-28 [1] CRAN (R 4.4.3)\n#&gt;    RSpectra            0.16-2   2024-07-18 [1] CRAN (R 4.4.2)\n#&gt;    rstan               2.32.7   2025-03-10 [1] CRAN (R 4.4.3)\n#&gt;    rstanarm          * 2.32.2   2025-09-30 [1] CRAN (R 4.4.3)\n#&gt;    rstantools          2.5.0    2025-09-01 [1] CRAN (R 4.4.3)\n#&gt;    rstudioapi          0.17.1   2024-10-22 [1] CRAN (R 4.4.2)\n#&gt;    S7                  0.2.0    2024-11-07 [1] CRAN (R 4.4.3)\n#&gt;    sandwich            3.1-1    2024-09-15 [1] CRAN (R 4.4.2)\n#&gt;    sass                0.4.10   2025-04-11 [1] CRAN (R 4.4.3)\n#&gt;    satellite           1.0.5    2024-02-10 [1] CRAN (R 4.4.2)\n#&gt;    scales              1.4.0    2025-04-24 [1] CRAN (R 4.4.3)\n#&gt;    secr                5.1.0    2024-11-04 [1] CRAN (R 4.4.2)\n#&gt;    sessioninfo         1.2.3    2025-02-05 [1] CRAN (R 4.4.3)\n#&gt;    sf                * 1.0-21   2025-05-15 [1] CRAN (R 4.4.3)\n#&gt;    shiny               1.9.1    2024-08-01 [1] CRAN (R 4.4.2)\n#&gt;    shinyBS             0.61.1   2022-04-17 [1] CRAN (R 4.4.3)\n#&gt;    shinydashboard      0.7.3    2025-04-21 [1] CRAN (R 4.4.3)\n#&gt;    shinyjs             2.1.0    2021-12-23 [1] CRAN (R 4.4.3)\n#&gt;    shinystan           2.6.0    2022-03-03 [1] CRAN (R 4.4.3)\n#&gt;    shinythemes         1.2.0    2021-01-25 [1] CRAN (R 4.4.3)\n#&gt;    sp                  2.2-0    2025-02-01 [1] CRAN (R 4.4.3)\n#&gt;    StanHeaders         2.32.10  2024-07-15 [1] CRAN (R 4.4.2)\n#&gt;    stringi             1.8.4    2024-05-06 [1] CRAN (R 4.4.0)\n#&gt;    stringr           * 1.5.2    2025-09-08 [1] CRAN (R 4.4.3)\n#&gt;    styler            * 1.10.3   2024-04-07 [1] CRAN (R 4.4.2)\n#&gt;    survival            3.7-0    2024-06-05 [2] CRAN (R 4.4.2)\n#&gt;    svglite             2.1.3    2023-12-08 [1] CRAN (R 4.4.2)\n#&gt;    systemfonts         1.1.0    2024-05-15 [1] CRAN (R 4.4.2)\n#&gt;    tensorA             0.36.2.1 2023-12-13 [1] CRAN (R 4.4.0)\n#&gt;    terra             * 1.8-70   2025-09-27 [1] CRAN (R 4.4.3)\n#&gt;    TH.data             1.1-3    2025-01-17 [1] CRAN (R 4.4.3)\n#&gt;    threejs             0.3.4    2025-04-21 [1] CRAN (R 4.4.3)\n#&gt;    tibble            * 3.2.1    2023-03-20 [1] CRAN (R 4.4.2)\n#&gt;    tidyr             * 1.3.1    2024-01-24 [1] CRAN (R 4.4.2)\n#&gt;    tidyselect          1.2.1    2024-03-11 [1] CRAN (R 4.4.2)\n#&gt;    tidyverse         * 2.0.0    2023-02-22 [1] CRAN (R 4.4.2)\n#&gt;    timechange          0.3.0    2024-01-18 [1] CRAN (R 4.4.2)\n#&gt;    tzdb                0.4.0    2023-05-12 [1] CRAN (R 4.4.2)\n#&gt;    ubms              * 1.2.8    2025-09-29 [1] CRAN (R 4.4.3)\n#&gt;    units               0.8-7    2025-03-11 [1] CRAN (R 4.4.3)\n#&gt;    unmarked          * 1.5.1    2025-09-26 [1] CRAN (R 4.4.3)\n#&gt;    usethis             3.2.1    2025-09-06 [1] CRAN (R 4.4.3)\n#&gt;    uuid                1.2-1    2024-07-29 [1] CRAN (R 4.4.1)\n#&gt;    V8                  6.0.0    2024-10-12 [1] CRAN (R 4.4.2)\n#&gt;    vctrs               0.6.5    2023-12-01 [1] CRAN (R 4.4.2)\n#&gt;    viridisLite         0.4.2    2023-05-02 [1] CRAN (R 4.4.2)\n#&gt;    vroom               1.6.5    2023-12-05 [1] CRAN (R 4.4.2)\n#&gt;    withr               3.0.2    2024-10-28 [1] CRAN (R 4.4.2)\n#&gt;    xfun                0.52     2025-04-02 [1] CRAN (R 4.4.3)\n#&gt;    xml2                1.4.0    2025-08-20 [1] CRAN (R 4.4.3)\n#&gt;    xtable              1.8-4    2019-04-21 [1] CRAN (R 4.4.2)\n#&gt;    xts                 0.14.1   2024-10-15 [1] CRAN (R 4.4.2)\n#&gt;    yaml                2.3.10   2024-07-26 [1] CRAN (R 4.4.1)\n#&gt;    zoo                 1.8-12   2023-04-13 [1] CRAN (R 4.4.2)\n#&gt; \n#&gt;  [1] C:/Users/usuario/AppData/Local/R/win-library/4.4\n#&gt;  [2] C:/Program Files/R/R-4.4.2/library\n#&gt; \n#&gt;  * ── Packages attached to the search path.\n#&gt;  D ── DLL MD5 mismatch, broken installation.\n#&gt; \n#&gt; ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/2024-06-25-species-diversity/index.html",
    "href": "posts/2024-06-25-species-diversity/index.html",
    "title": "Species diversity",
    "section": "",
    "text": "There are two commonly used ways to account for survey effort when estimating species richness using camera traps:\n\nusing the rarefaction of observed richness.\nusing multispecies occupancy models to account for the species present but not observed (occupancy model, taking in to account imperfect detection).\n\nIn this post we can see an example of No 1. using the classical approach of community ecology using the vegan package. The vegan package (https://cran.r-project.org/package=vegan) provides tools for descriptive community ecology. It has basic functions of diversity analysis, community ordination and dissimilarity analysis. The vegan package provides most standard tools of descriptive community analysis. Later in the post we carry out another diversity analysis using functions of the package iNEXT.\nThe modern approach to measure species diversity include the “Sample Hill diversities” also known as Hill numbers. Rarefaction and extrapolation with Hill numbers have gain popularity in the last decade and can be computed using the function renyi in the R package vegan (Oksanen 2016) and the function rarity in the R package MeanRarity (Roswell and Dushoff 2020), and Hill diversities of equal-sized or equal-coverage samples can be approximately compared using the functions iNEXT and estimateD in the R package iNEXT (Hsieh et al. 2016). Estimates for asymptotic values of Hill diversity are available in SpadeR (Chao and Jost 2015, Chao et al. 2015)."
  },
  {
    "objectID": "posts/2024-06-25-species-diversity/index.html#species-richness-and-sampling-effort",
    "href": "posts/2024-06-25-species-diversity/index.html#species-richness-and-sampling-effort",
    "title": "Species diversity",
    "section": "",
    "text": "There are two commonly used ways to account for survey effort when estimating species richness using camera traps:\n\nusing the rarefaction of observed richness.\nusing multispecies occupancy models to account for the species present but not observed (occupancy model, taking in to account imperfect detection).\n\nIn this post we can see an example of No 1. using the classical approach of community ecology using the vegan package. The vegan package (https://cran.r-project.org/package=vegan) provides tools for descriptive community ecology. It has basic functions of diversity analysis, community ordination and dissimilarity analysis. The vegan package provides most standard tools of descriptive community analysis. Later in the post we carry out another diversity analysis using functions of the package iNEXT.\nThe modern approach to measure species diversity include the “Sample Hill diversities” also known as Hill numbers. Rarefaction and extrapolation with Hill numbers have gain popularity in the last decade and can be computed using the function renyi in the R package vegan (Oksanen 2016) and the function rarity in the R package MeanRarity (Roswell and Dushoff 2020), and Hill diversities of equal-sized or equal-coverage samples can be approximately compared using the functions iNEXT and estimateD in the R package iNEXT (Hsieh et al. 2016). Estimates for asymptotic values of Hill diversity are available in SpadeR (Chao and Jost 2015, Chao et al. 2015)."
  },
  {
    "objectID": "posts/2024-06-25-species-diversity/index.html#load-packages",
    "href": "posts/2024-06-25-species-diversity/index.html#load-packages",
    "title": "Species diversity",
    "section": "Load packages",
    "text": "Load packages\n\nCode\n\nlibrary(patchwork) # The Composer of Plots\nlibrary(readxl) # Read Excel Files\nlibrary(sf) # Simple Features for R\nlibrary(elevatr) # Access Elevation Data from Various APIs\nlibrary(mapview) # Interactive Viewing of Spatial Data in R\nlibrary(tmap)\nlibrary(eks) # make countours\nlibrary(grateful) # Facilitate Citation of R Packages\nlibrary(camtrapR) # Camera Trap Data Management and Preparation of Occupancy and Spatial Capture-Recapture Analyses\nlibrary(vegan) # Community Ecology Package \nlibrary(ggvegan)\n# library(BiodiversityR) # cause error!\nlibrary(ggordiplots)\nlibrary(grid)\nlibrary(gridExtra)\nlibrary(DT)\nlibrary(MeanRarity)\nlibrary(SpadeR)\nlibrary(iNEXT) # Interpolation and Extrapolation for Species Diversity\nlibrary(knitr) # A General-Purpose Package for Dynamic Report Generation in R\nlibrary(kableExtra) # Construct Complex Table with 'kable' and Pipe Syntax\nlibrary(tidyverse) # Easily Install and Load the 'Tidyverse'\nlibrary(ggforce) # Accelerating 'ggplot2'\nlibrary(plotly)"
  },
  {
    "objectID": "posts/2024-06-25-species-diversity/index.html#load-data",
    "href": "posts/2024-06-25-species-diversity/index.html#load-data",
    "title": "Species diversity",
    "section": "Load data",
    "text": "Load data\n\nCode\ndatos &lt;- read_excel(\"C:/CodigoR/CameraTrapCesar/data/CT_Cesar.xlsx\")\n\n# habitat types extracted from Copernicus\nhabs &lt;- read.csv(\"C:/CodigoR/CameraTrapCesar/data/habitats.csv\")"
  },
  {
    "objectID": "posts/2024-06-25-species-diversity/index.html#pooling-together-several-sites",
    "href": "posts/2024-06-25-species-diversity/index.html#pooling-together-several-sites",
    "title": "Species diversity",
    "section": "Pooling together several sites",
    "text": "Pooling together several sites\nFor this example I used data gathered by fundación Galictis in Perija, Colombia. I selected one year for the sites: Becerril 2021, LaPaz_Manaure 2019, MLJ, CL1, CL2 and PCF. Sometimes we need to make unique codes per camera and cameraOperation table. This was not the case.\nFor this example we are using the habitat type were the camera was installed as a way to see the sampling effort (number of cameras) per habitat type. The habitat type was extracted overlaying the camera points on top of the Land Cover 100m global dataset from COPERNICUS using Google Earth engine connected to R. How to do this will be in another post.\n\nCode# make a new column Station\n# datos_PCF &lt;- datos |&gt; dplyr::filter(Proyecto==\"CT_LaPaz_Manaure\") |&gt; unite (\"Station\", ProyectoEtapa:Salida:CT, sep = \"-\")\n\n# fix dates\ndatos$Start &lt;- as.Date(datos$Start, \"%d/%m/%Y\")\ndatos$End &lt;- as.Date(datos$End, \"%d/%m/%Y\")\ndatos$eventDate &lt;- as.Date(datos$eventDate, \"%d/%m/%Y\")\ndatos$eventDateTime &lt;- ymd_hms(paste(datos$eventDate, \" \",\n                              datos$eventTime, \":00\", sep=\"\"))\n\n# filter Becerril\ndatos_Becerril &lt;- datos |&gt; dplyr::filter(ProyectoEtapa==\"CT_Becerril\") |&gt; mutate (Station=IdGeo) |&gt; filter(Year==2021)\n\n# filter LaPaz_Manaure\ndatos_LaPaz_Manaure&lt;- datos |&gt; dplyr::filter(ProyectoEtapa==\"CT_LaPaz_Manaure\") |&gt; mutate (Station=IdGeo) |&gt; filter(Year==2019)\n\n# filter MLJ\ndatos_MLJ &lt;- datos |&gt; dplyr::filter(ProyectoEtapa==\"MLJ_TH_TS_2021\") |&gt; mutate (Station=IdGeo)\n\n# filter CL\ndatos_CL1 &lt;- datos |&gt; dplyr::filter(ProyectoEtapa==\"CL-TH2022\") |&gt; mutate (Station=IdGeo)\n# filter CL\ndatos_CL2 &lt;- datos |&gt; dplyr::filter(ProyectoEtapa==\"CL-TS2022\") |&gt; mutate (Station=IdGeo)\n\n# filter PCF\ndatos_PCF &lt;- datos |&gt; dplyr::filter(Proyecto==\"PCF\") |&gt; mutate (Station=IdGeo)\n\ndata_south &lt;- rbind(datos_LaPaz_Manaure, datos_Becerril, datos_MLJ,datos_CL1, datos_CL2,datos_PCF)\n\n# filter 2021 and make uniques\nCToperation  &lt;- data_south |&gt; \n              # filter(Year==2021) |&gt; \n              group_by(Station) |&gt; \n              mutate(minStart=min(Start), maxEnd=max(End)) |&gt;  distinct(Longitude, Latitude, minStart, maxEnd, Year) |&gt; \n  ungroup()"
  },
  {
    "objectID": "posts/2024-06-25-species-diversity/index.html#generating-the-cameraoperation-table-and-making-detection-histories-for-all-the-species.",
    "href": "posts/2024-06-25-species-diversity/index.html#generating-the-cameraoperation-table-and-making-detection-histories-for-all-the-species.",
    "title": "Species diversity",
    "section": "Generating the cameraOperation table and making detection histories for all the species.",
    "text": "Generating the cameraOperation table and making detection histories for all the species.\nThe package CamtrapR has the function ‘cameraOperation’ which makes a table of cameras (stations) and dates (setup, puck-up), this table is key to generate the detection histories using the function ‘detectionHistory’ in the next step.\n\nCode# Generamos la matríz de operación de las cámaras\n\ncamop &lt;- cameraOperation(CTtable= CToperation, # Tabla de operación\n                         stationCol= \"Station\", # Columna que define la estación\n                         setupCol= \"minStart\", #Columna fecha de colocación\n                         retrievalCol= \"maxEnd\", #Columna fecha de retiro\n                         #hasProblems= T, # Hubo fallos de cámaras\n                         dateFormat= \"%Y-%m-%d\") #, # Formato de las fechas\n                         #cameraCol=\"CT\")\n                         # sessionCol= \"Year\")\n\n# Generar las historias de detección ---------------------------------------\n## remove plroblem species\n# ind &lt;- which(datos_PCF$Species==\"Marmosa sp.\")\n# datos_PCF &lt;- datos_PCF[-ind,]\n\nDetHist_list &lt;- lapply(unique(data_south$Species), FUN = function(x) {\n  detectionHistory(\n    recordTable         = data_south, # Tabla de registros\n    camOp                = camop, # Matriz de operación de cámaras\n    stationCol           = \"Station\",\n    speciesCol           = \"Species\",\n    recordDateTimeCol    = \"eventDateTime\",\n    recordDateTimeFormat  = \"%Y-%m-%d\",\n    species              = x,     # la función reemplaza x por cada una de las especies\n    occasionLength       = 7, # Colapso de las historias a 10 días\n    day1                 = \"station\", # (\"survey\"),or #inicia en la fecha de cada station\n    datesAsOccasionNames = FALSE,\n    includeEffort        = TRUE,\n    scaleEffort          = FALSE,\n    output               = (\"binary\"), # (\"binary\") or (\"count\")\n    #unmarkedMultFrameInput=TRUE\n    timeZone             = \"America/Bogota\" \n    )\n  }\n)\n\n# put names to the species \nnames(DetHist_list) &lt;- unique(data_south$Species)\n\n# Finally we make a new list to put all the detection histories.\nylist &lt;- lapply(DetHist_list, FUN = function(x) x$detection_history)"
  },
  {
    "objectID": "posts/2024-06-25-species-diversity/index.html#use-the-detection-histories-to-make-the-a-matrix-for-vegan-and-the-incidence-for-inext.",
    "href": "posts/2024-06-25-species-diversity/index.html#use-the-detection-histories-to-make-the-a-matrix-for-vegan-and-the-incidence-for-inext.",
    "title": "Species diversity",
    "section": "Use the detection histories to make the a matrix for vegan and the incidence for iNEXT.",
    "text": "Use the detection histories to make the a matrix for vegan and the incidence for iNEXT.\nSpecies accumulation curves made using the package vegan, plot the increase in species richness as we add survey units. If the curve plateaus (flattens), then that suggests you have sampled the majority of the species in your survey site (camera or habitat type).\n\nCode# loop to make vegan matrix\nmat_vegan &lt;- matrix(NA, dim(ylist[[1]])[1], length(unique(data_south$Species)))\nfor(i in 1:length(unique(data_south$Species))){\n  mat_vegan[,i] &lt;- apply(ylist[[i]], 1, sum, na.rm=TRUE)\n  mat_vegan[,i] &lt;- tidyr::replace_na(mat_vegan[,i], 0) # replace na with 0\n}\n\ncolnames(mat_vegan)  &lt;- unique(data_south$Species)\nrownames(mat_vegan) &lt;- rownames(ylist[[1]])\n\nmat_vegan2 &lt;- as.data.frame(mat_vegan)\nmat_vegan2$hab &lt;- habs$hab_code\n# mat_vegan3 &lt;-  mat_vegan2 |&gt; \n  \n# Select specific rows by row numbers\nclosed_forest_rows &lt;- which(mat_vegan2$hab==\"closed_forest_evergreen_broad\")\nherbaceous_rows &lt;- which(mat_vegan2$hab==\"herbaceous_wetland\")\nherbs_rows &lt;- which(mat_vegan2$hab==\"herbs\")\nopen_forest_rows &lt;- which(mat_vegan2$hab==\"open_forest_evergreen_broad\")\nopen_forest2_rows &lt;- which(mat_vegan2$hab==\"open_forest_other\")\n\n\nclosed_forest &lt;- apply(mat_vegan2[closed_forest_rows,1:22], MARGIN = 2, sum)\nherbaceous_wetland &lt;- apply(mat_vegan2[herbaceous_rows,1:22], MARGIN = 2, sum)\nherbs  &lt;- apply(mat_vegan2[herbs_rows,1:22], MARGIN = 2, sum)\nopen_forest_evergreen &lt;- apply(mat_vegan2[open_forest_rows,1:22], MARGIN = 2, sum)\nopen_forest_other &lt;- apply(mat_vegan2[open_forest2_rows,1:22], MARGIN = 2, sum)\n\n# tb_sp &lt;- mat_vegan2 |&gt; group_by(hab)\n# hab_list &lt;- group_split(tb_sp)\n\n# make list of dataframe per habitat\nsp_by_hab &lt;- mat_vegan2 |&gt; dplyr::group_by(hab) %&gt;% split (.$hab)\n# arrange abundance (detection frecuency) mat for INEXT \ncesar_sp &lt;- t(rbind(\nt(colSums(sp_by_hab[[1]][,1:33])),\nt(colSums(sp_by_hab[[2]][,1:33])),\nt(colSums(sp_by_hab[[3]][,1:33])),\nt(colSums(sp_by_hab[[4]][,1:33])),\nt(colSums(sp_by_hab[[5]][,1:33]))\n))\n \ncolnames(cesar_sp) &lt;- names(sp_by_hab)\n\n\n\n# function to Format data to incidence and use iNext\nf_incidences &lt;- function(habitat_rows=closed_forest_rows){ylist %&gt;%  # historias de detection\n  map(~rowSums(.,na.rm = T)) %&gt;% # sumo las detecciones en cada sitio\n  reduce(cbind) %&gt;% # unimos las listas\n  as_data_frame() %&gt;% #formato dataframe\n  filter(row_number() %in% habitat_rows) |&gt; \n  t() %&gt;% # trasponer la tabla\n  as_tibble() %&gt;% #formato tibble\n  mutate_if(is.numeric,~(.&gt;=1)*1) %&gt;%  #como es incidencia, formateo a 1 y 0\n  rowSums() %&gt;%  # ahora si la suma de las incidencias en cada sitio\n  sort(decreasing=T) |&gt; \n  as_tibble() %&gt;% \n  add_row(value= length(habitat_rows), .before = 1) %&gt;%  # requiere que el primer valor sea el número de sitios\n  filter(!if_any()==0) |&gt;  # filter ceros\n  as.matrix() # Requiere formato de matriz\n}\n\n# Make incidence frequency table (is a list whit 5 habitats)\n# Make an empty list to store our data\nincidence_cesar &lt;- list() \nincidence_cesar[[1]] &lt;- f_incidences(closed_forest_rows)\nincidence_cesar[[2]] &lt;- f_incidences(herbaceous_rows)\nincidence_cesar[[3]] &lt;- f_incidences(herbs_rows)\nincidence_cesar[[4]] &lt;- f_incidences(open_forest_rows)\nincidence_cesar[[5]] &lt;- f_incidences(open_forest_other)\n\n# put names\nnames(incidence_cesar) &lt;- names(sp_by_hab)\n\n# we deleted this habitat type for making error\nincidence_cesar &lt;- within(incidence_cesar, rm(\"herbaceous_wetland\"))"
  },
  {
    "objectID": "posts/2024-06-25-species-diversity/index.html#to-start-lets-plot-the-species-vs-sites",
    "href": "posts/2024-06-25-species-diversity/index.html#to-start-lets-plot-the-species-vs-sites",
    "title": "Species diversity",
    "section": "To start lets plot the species vs sites",
    "text": "To start lets plot the species vs sites\n\nCode# Transpose if needed to have sample site names on rows\nabund_table&lt;-mat_vegan\n# Convert to relative frequencies\nabund_table &lt;- abund_table/rowSums(abund_table)\nlibrary(reshape2)\ndf&lt;-melt(abund_table)\ncolnames(df)&lt;-c(\"Sampled_site\",\"Species\",\"Value\")\nlibrary(plyr)\nlibrary(scales)\n \n# We are going to apply transformation to our data to make it\n# easier on eyes \n \n#df&lt;-ddply(df,.(Samples),transform,rescale=scale(Value))\ndf&lt;-ddply(df,.(Sampled_site),transform,rescale=sqrt(Value))\n \n# Plot heatmap\np &lt;- ggplot(df, aes(Species, Sampled_site)) + \n  geom_tile(aes(fill = rescale),colour = \"white\") + \n  scale_fill_gradient(low = \"white\",high = \"#1E5A8C\")+\n  scale_x_discrete(expand = c(0, 0)) +\n  scale_y_discrete(expand = c(0, 0)) + theme(legend.position = \"none\",axis.ticks = element_blank(),axis.text.x = element_text(angle = 90, hjust = 1,size=6),axis.text.y = element_text(size=4))\n\n# ggplotly(p) # see interactive\n# View the plot\np\n\n\n\n\n\n\n\n\nNotice how some cameras didn’t record any species. Here showed as the gay horizontal line. Perhaps we need to delete those cameras."
  },
  {
    "objectID": "posts/2024-06-25-species-diversity/index.html#rarefaction-using-vegan",
    "href": "posts/2024-06-25-species-diversity/index.html#rarefaction-using-vegan",
    "title": "Species diversity",
    "section": "Rarefaction using vegan\n",
    "text": "Rarefaction using vegan\n\n\nNotice that sites are cameras and the accumulation is species per camera not time\n\nRarefaction is a technique to assess expected species richness. Rarefaction allows the calculation of species richness for a given number of individual samples, based on the construction of rarefaction curves.\nThe issue that occurs when sampling various species in a community is that the larger the number of individuals sampled, the more species that will be found. Rarefaction curves are created by randomly re-sampling the pool of N samples multiple times and then plotting the average number of species found in each sample (1,2, … N). “Thus rarefaction generates the expected number of species in a small collection of n individuals (or n samples) drawn at random from the large pool of N samples.”. Rarefaction curves generally grow rapidly at first, as the most common species are found, but the curves plateau as only the rarest species remain to be sampled.\n\nCode\nrarecurve(mat_vegan, col = \"blue\") \n\n\n\n\n\n\nCoderarecurve(t(cesar_sp), col = \"blue\") \n\n\n\n\n\n\nCode\nsp1 &lt;- specaccum(mat_vegan)\nsp2 &lt;- specaccum(mat_vegan, \"random\")\n# sp2\n# summary(sp2)\nplot(sp1, ci.type=\"poly\", col=\"blue\", lwd=2, ci.lty=0, ci.col=\"lightblue\")\n\n\n\n\n\n\nCode# boxplot(sp2, col=\"yellow\", add=TRUE, pch=\"+\")\n\n\nmods &lt;- fitspecaccum(sp1, \"gleason\")\nplot(mods, col=\"hotpink\")\nboxplot(sp2, col = \"yellow\", border = \"blue\", lty=1, cex=0.3, add= TRUE)\n\n\n\n\n\n\nCode\n\n## Accumulation model\npool &lt;- poolaccum(mat_vegan)\n# summary(pool, display = \"chao\")\nplot(pool)\n\n\n\n\n\n\n\nRanked abundance distribution\nAn alternative approach to species abundance distribution is to plot logarithmic abundances in decreasing order, or against ranks of species.\n\nCodek &lt;- sample(nrow(mat_vegan), 1)\nrad &lt;- radfit(mat_vegan[22,]) # species 22\n# plot(rad)\nradlattice(rad)\n\n\n\n\n\n\n\nHill Diversities using vegan\n\nCode# data(BCI)\ni &lt;- sample(nrow(mat_vegan), 20)\nmod &lt;- renyi(mat_vegan) #selecting sites with more than one record\nplot(mod)\n\n\n\n\n\n\nCodemod &lt;- renyiaccum(mat_vegan[55:89,])\nplot(mod, as.table=TRUE, col = c(1, 2, 2))\n\n\n\n\n\n\nCodepersp(mod)\n\n\n\n\n\n\n\nTotal number of species\n\nCodeDT::datatable(round(specpool(mat_vegan),3))\n\n\n\n\n\nNumber of unseen species per camera\nLook at S.chao1\n\nCodeDT::datatable(\nt(round(as.data.frame(estimateR(mat_vegan[,])),3))\n)\n\n\n\n\nCode\n# save as dataframe\nS_per_site &lt;- as.data.frame(t(round(as.data.frame(estimateR(mat_vegan[,])),3)))\n# add sites\nS_per_site$Station &lt;- rownames(S_per_site)\n\n\nIt is weird to have .5 species in some sites."
  },
  {
    "objectID": "posts/2024-06-25-species-diversity/index.html#map-it-converting-cameratrap-operation-to-sf",
    "href": "posts/2024-06-25-species-diversity/index.html#map-it-converting-cameratrap-operation-to-sf",
    "title": "Species diversity",
    "section": "Map it converting Cameratrap-operation to sf",
    "text": "Map it converting Cameratrap-operation to sf\nIn this step we convert the Cameratrap-operation table to sf, we add elevation from Amazon web Services (AWS), habitat type and species per site (S.chao1) to finally visualize the map showing the number of species as the size of the dot.\n\nCode\n# datos_distinct &lt;- datos |&gt; distinct(Longitude, Latitude, CT, Proyecto)\n\nprojlatlon &lt;- \"+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0\"\n\nCToperation_sf &lt;-  st_as_sf(x = CToperation,\n                         coords = c(\"Longitude\", \n                                    \"Latitude\"),\n                         crs = projlatlon)\n\n# write.csv(habs, \"C:/CodigoR/CameraTrapCesar/data/habitats.csv\")\nhabs &lt;- read.csv(\"C:/CodigoR/CameraTrapCesar/data/habitats.csv\")\n\nCToperation_elev_sf &lt;- get_elev_point(CToperation_sf, src = \"aws\") # get elevation from AWS\n\nCToperation_elev_sf &lt;- CToperation_elev_sf |&gt; left_join(habs, by='Station') |&gt; left_join(S_per_site, by='Station') |&gt; select(\"Station\", \"elevation\", \"minStart.x\",\"maxEnd.x\", \"Year.x\", \"hab_code\" , \"S.obs\", \"S.chao1\")\n\n# add habitat \n# CToperation_elev_sf$habs &lt;- habs$hab_code\n# see the map\nmapview(CToperation_elev_sf, zcol=\"hab_code\", cex = \"S.chao1\", alpha = 0)"
  },
  {
    "objectID": "posts/2024-06-25-species-diversity/index.html#perhaps-it-is-easyer-to-plot-the-species-number-as-a-countour-map",
    "href": "posts/2024-06-25-species-diversity/index.html#perhaps-it-is-easyer-to-plot-the-species-number-as-a-countour-map",
    "title": "Species diversity",
    "section": "Perhaps it is easyer to plot the species number as a countour map",
    "text": "Perhaps it is easyer to plot the species number as a countour map\nOne advantage of using the eks density estimate, is that it is clearer what the output means. The 20% contour means “20% of the measurements lie inside this contour”. The documentation for eks takes issue with how stat_density_2d from ggplot2 does its calculation, I don’t know who is right because the estimated value is species and both graphs are similar.\n\nCode# select chao\nspecies &lt;- dplyr::select(CToperation_elev_sf, \"S.chao1\")\n# hakeoides_coord &lt;- data.frame(sf::st_coordinates(hakeoides))\nSta_den &lt;- eks::st_kde(species) # calculate density\n\n# VERY conveniently, eks can generate an sf file of contour lines\ncontours &lt;- eks::st_get_contour(Sta_den, cont=c( 10,20,30,40,50,60,70,80, 90)) %&gt;% \n  mutate(value=as.numeric(levels(contlabel)))\n\n\n# pal_fun &lt;- leaflet::colorQuantile(\"YlOrRd\", NULL, n = 5)\n\np_popup &lt;- paste(\"Species\", as.numeric(levels(contours$estimate)), \"number\")\n\n\ntmap::tmap_mode(\"view\") # set mode to interactive plots\n\ntmap::tm_shape(species) + \n    tmap::tm_sf(col=\"black\", size=0.2) +\n  #   contours from eks\n  tmap::tm_shape(contours) +\n    tmap::tm_polygons(\"estimate\",\n                      palette=\"Reds\",\n                      alpha=0.5 )\n\n\n\n\n\nCode\n\n## geom_sf plot\n# ## suitable smoothing matrix gives optimally smoothed contours\n# gs1 &lt;- ggplot(Sta_den) + geom_sf(data=CToperation_elev_sf, fill=NA) + ggthemes::theme_map() +\n#     colorspace::scale_fill_discrete_sequential(palette=\"Heat2\") \n# gs1 + geom_sf(data=st_get_contour(Sta_den), aes(fill=label_percent(contlabel))) +\n#     coord_sf(xlim=xlim, ylim=ylim) \n\n\n\nIn general terms the species estimate per site seems to be larger near the coal mine and decrease with the distance to the mine. Also notice kernel density estimates are larger than s.chao1."
  },
  {
    "objectID": "posts/2024-06-25-species-diversity/index.html#nonmetric-multidimensional-scaling-nmds",
    "href": "posts/2024-06-25-species-diversity/index.html#nonmetric-multidimensional-scaling-nmds",
    "title": "Species diversity",
    "section": "Nonmetric Multidimensional Scaling (NMDS)",
    "text": "Nonmetric Multidimensional Scaling (NMDS)\nOften in ecological research, we are interested not only in comparing univariate descriptors of communities, like diversity, but also in how the constituent species — or the species composition — changes from one community to the next. One common tool to do this is non-metric multidimensional scaling, or NMDS. The goal of NMDS is to collapse information from multiple dimensions (e.g, from multiple communities, sites were the cameratrap was installed, etc.) into just a few, so that they can be visualized and interpreted. Unlike other ordination techniques that rely on (primarily Euclidean) distances, such as Principal Coordinates Analysis, NMDS uses rank orders, and thus is an extremely flexible technique that can accommodate a variety of different kinds of data.\nIf the treatment is continuous, such as an environmental gradient, then it might be useful to plot contour lines rather than convex hulls. We can get some, elevation data for our original community matrix and overlay them onto the NMDS plot using ordisurf.\n\nCode\nexample_NMDS=metaMDS(as.data.frame(mat_vegan), \n                     distance=\"euclidean\",\n                     zerodist = \"ignore\",\n                     trymax=300,\n                     k=5) # T\n#&gt; Wisconsin double standardization\n#&gt; Run 0 stress 0.1177774 \n#&gt; Run 1 stress 0.1206288 \n#&gt; Run 2 stress 0.1186686 \n#&gt; Run 3 stress 0.1191797 \n#&gt; Run 4 stress 0.1179719 \n#&gt; ... Procrustes: rmse 0.05919246  max resid 0.2038165 \n#&gt; Run 5 stress 0.1183849 \n#&gt; Run 6 stress 0.1196809 \n#&gt; Run 7 stress 0.1186472 \n#&gt; Run 8 stress 0.1184403 \n#&gt; Run 9 stress 0.1196989 \n#&gt; Run 10 stress 0.1194615 \n#&gt; Run 11 stress 0.1214856 \n#&gt; Run 12 stress 0.1188458 \n#&gt; Run 13 stress 0.1204449 \n#&gt; Run 14 stress 0.1193109 \n#&gt; Run 15 stress 0.118481 \n#&gt; Run 16 stress 0.1195796 \n#&gt; Run 17 stress 0.1186381 \n#&gt; Run 18 stress 0.1191817 \n#&gt; Run 19 stress 0.1176268 \n#&gt; ... New best solution\n#&gt; ... Procrustes: rmse 0.06730393  max resid 0.1981391 \n#&gt; Run 20 stress 0.1188219 \n#&gt; Run 21 stress 0.1185899 \n#&gt; Run 22 stress 0.1203331 \n#&gt; Run 23 stress 0.1194288 \n#&gt; Run 24 stress 0.1201856 \n#&gt; Run 25 stress 0.1202617 \n#&gt; Run 26 stress 0.1181575 \n#&gt; Run 27 stress 0.1202947 \n#&gt; Run 28 stress 0.118683 \n#&gt; Run 29 stress 0.119821 \n#&gt; Run 30 stress 0.1194675 \n#&gt; Run 31 stress 0.1210007 \n#&gt; Run 32 stress 0.1184738 \n#&gt; Run 33 stress 0.1195521 \n#&gt; Run 34 stress 0.1187497 \n#&gt; Run 35 stress 0.1191322 \n#&gt; Run 36 stress 0.1179864 \n#&gt; ... Procrustes: rmse 0.06264792  max resid 0.2506916 \n#&gt; Run 37 stress 0.1185073 \n#&gt; Run 38 stress 0.1192425 \n#&gt; Run 39 stress 0.1187494 \n#&gt; Run 40 stress 0.1178776 \n#&gt; ... Procrustes: rmse 0.06673682  max resid 0.3230683 \n#&gt; Run 41 stress 0.1191402 \n#&gt; Run 42 stress 0.1183157 \n#&gt; Run 43 stress 0.118886 \n#&gt; Run 44 stress 0.118375 \n#&gt; Run 45 stress 0.1210902 \n#&gt; Run 46 stress 0.1183168 \n#&gt; Run 47 stress 0.1200819 \n#&gt; Run 48 stress 0.1188811 \n#&gt; Run 49 stress 0.1190618 \n#&gt; Run 50 stress 0.1190239 \n#&gt; Run 51 stress 0.1192832 \n#&gt; Run 52 stress 0.1171768 \n#&gt; ... New best solution\n#&gt; ... Procrustes: rmse 0.06292082  max resid 0.295684 \n#&gt; Run 53 stress 0.1187272 \n#&gt; Run 54 stress 0.1191086 \n#&gt; Run 55 stress 0.1192896 \n#&gt; Run 56 stress 0.1205005 \n#&gt; Run 57 stress 0.1187612 \n#&gt; Run 58 stress 0.119228 \n#&gt; Run 59 stress 0.1190356 \n#&gt; Run 60 stress 0.1179332 \n#&gt; Run 61 stress 0.1197881 \n#&gt; Run 62 stress 0.1181237 \n#&gt; Run 63 stress 0.1193814 \n#&gt; Run 64 stress 0.118903 \n#&gt; Run 65 stress 0.1191659 \n#&gt; Run 66 stress 0.1189552 \n#&gt; Run 67 stress 0.118381 \n#&gt; Run 68 stress 0.1182353 \n#&gt; Run 69 stress 0.1185069 \n#&gt; Run 70 stress 0.119889 \n#&gt; Run 71 stress 0.1189324 \n#&gt; Run 72 stress 0.1202498 \n#&gt; Run 73 stress 0.1198287 \n#&gt; Run 74 stress 0.1173791 \n#&gt; ... Procrustes: rmse 0.03459135  max resid 0.1320568 \n#&gt; Run 75 stress 0.118462 \n#&gt; Run 76 stress 0.1208487 \n#&gt; Run 77 stress 0.1184617 \n#&gt; Run 78 stress 0.11866 \n#&gt; Run 79 stress 0.1205182 \n#&gt; Run 80 stress 0.1196904 \n#&gt; Run 81 stress 0.1190856 \n#&gt; Run 82 stress 0.1181391 \n#&gt; Run 83 stress 0.1194442 \n#&gt; Run 84 stress 0.1185924 \n#&gt; Run 85 stress 0.1193937 \n#&gt; Run 86 stress 0.121223 \n#&gt; Run 87 stress 0.1180475 \n#&gt; Run 88 stress 0.1172267 \n#&gt; ... Procrustes: rmse 0.03409711  max resid 0.1753628 \n#&gt; Run 89 stress 0.1192943 \n#&gt; Run 90 stress 0.1196633 \n#&gt; Run 91 stress 0.1188599 \n#&gt; Run 92 stress 0.1183631 \n#&gt; Run 93 stress 0.1187598 \n#&gt; Run 94 stress 0.1185968 \n#&gt; Run 95 stress 0.11951 \n#&gt; Run 96 stress 0.1213391 \n#&gt; Run 97 stress 0.1197127 \n#&gt; Run 98 stress 0.119473 \n#&gt; Run 99 stress 0.1196205 \n#&gt; Run 100 stress 0.1192707 \n#&gt; Run 101 stress 0.1187672 \n#&gt; Run 102 stress 0.1193891 \n#&gt; Run 103 stress 0.1180284 \n#&gt; Run 104 stress 0.1203894 \n#&gt; Run 105 stress 0.1194927 \n#&gt; Run 106 stress 0.1212493 \n#&gt; Run 107 stress 0.1182965 \n#&gt; Run 108 stress 0.1202082 \n#&gt; Run 109 stress 0.1196737 \n#&gt; Run 110 stress 0.1184745 \n#&gt; Run 111 stress 0.1196734 \n#&gt; Run 112 stress 0.1210192 \n#&gt; Run 113 stress 0.1204562 \n#&gt; Run 114 stress 0.1183794 \n#&gt; Run 115 stress 0.1196312 \n#&gt; Run 116 stress 0.1195102 \n#&gt; Run 117 stress 0.1186427 \n#&gt; Run 118 stress 0.1177037 \n#&gt; Run 119 stress 0.1196211 \n#&gt; Run 120 stress 0.1184335 \n#&gt; Run 121 stress 0.1187205 \n#&gt; Run 122 stress 0.1193329 \n#&gt; Run 123 stress 0.1183935 \n#&gt; Run 124 stress 0.1180111 \n#&gt; Run 125 stress 0.1190067 \n#&gt; Run 126 stress 0.1199412 \n#&gt; Run 127 stress 0.1203917 \n#&gt; Run 128 stress 0.1193066 \n#&gt; Run 129 stress 0.1190813 \n#&gt; Run 130 stress 0.1210336 \n#&gt; Run 131 stress 0.1183395 \n#&gt; Run 132 stress 0.1185109 \n#&gt; Run 133 stress 0.1186184 \n#&gt; Run 134 stress 0.1182459 \n#&gt; Run 135 stress 0.1190389 \n#&gt; Run 136 stress 0.1204167 \n#&gt; Run 137 stress 0.1186198 \n#&gt; Run 138 stress 0.118966 \n#&gt; Run 139 stress 0.1201539 \n#&gt; Run 140 stress 0.1192333 \n#&gt; Run 141 stress 0.1191073 \n#&gt; Run 142 stress 0.1181058 \n#&gt; Run 143 stress 0.1180379 \n#&gt; Run 144 stress 0.1194509 \n#&gt; Run 145 stress 0.1190307 \n#&gt; Run 146 stress 0.1227532 \n#&gt; Run 147 stress 0.1197243 \n#&gt; Run 148 stress 0.1194925 \n#&gt; Run 149 stress 0.1176478 \n#&gt; ... Procrustes: rmse 0.03324642  max resid 0.1376792 \n#&gt; Run 150 stress 0.1197673 \n#&gt; Run 151 stress 0.118505 \n#&gt; Run 152 stress 0.1195788 \n#&gt; Run 153 stress 0.1183746 \n#&gt; Run 154 stress 0.1207917 \n#&gt; Run 155 stress 0.1195209 \n#&gt; Run 156 stress 0.1186476 \n#&gt; Run 157 stress 0.1205683 \n#&gt; Run 158 stress 0.1203957 \n#&gt; Run 159 stress 0.1194334 \n#&gt; Run 160 stress 0.1187067 \n#&gt; Run 161 stress 0.1191248 \n#&gt; Run 162 stress 0.1194916 \n#&gt; Run 163 stress 0.1187049 \n#&gt; Run 164 stress 0.1188084 \n#&gt; Run 165 stress 0.1195733 \n#&gt; Run 166 stress 0.1189146 \n#&gt; Run 167 stress 0.1189353 \n#&gt; Run 168 stress 0.1190702 \n#&gt; Run 169 stress 0.1188005 \n#&gt; Run 170 stress 0.1188069 \n#&gt; Run 171 stress 0.1199909 \n#&gt; Run 172 stress 0.1198793 \n#&gt; Run 173 stress 0.1193492 \n#&gt; Run 174 stress 0.1183103 \n#&gt; Run 175 stress 0.1188022 \n#&gt; Run 176 stress 0.119465 \n#&gt; Run 177 stress 0.1201642 \n#&gt; Run 178 stress 0.1203076 \n#&gt; Run 179 stress 0.1184545 \n#&gt; Run 180 stress 0.1191182 \n#&gt; Run 181 stress 0.1184663 \n#&gt; Run 182 stress 0.1197293 \n#&gt; Run 183 stress 0.1196431 \n#&gt; Run 184 stress 0.1200847 \n#&gt; Run 185 stress 0.1218445 \n#&gt; Run 186 stress 0.1205694 \n#&gt; Run 187 stress 0.1193901 \n#&gt; Run 188 stress 0.1202695 \n#&gt; Run 189 stress 0.1186335 \n#&gt; Run 190 stress 0.1189535 \n#&gt; Run 191 stress 0.1184268 \n#&gt; Run 192 stress 0.1203722 \n#&gt; Run 193 stress 0.11953 \n#&gt; Run 194 stress 0.1181967 \n#&gt; Run 195 stress 0.1210427 \n#&gt; Run 196 stress 0.1193239 \n#&gt; Run 197 stress 0.1189304 \n#&gt; Run 198 stress 0.1188824 \n#&gt; Run 199 stress 0.1179775 \n#&gt; Run 200 stress 0.1200429 \n#&gt; Run 201 stress 0.1186354 \n#&gt; Run 202 stress 0.1175204 \n#&gt; ... Procrustes: rmse 0.05732237  max resid 0.2698293 \n#&gt; Run 203 stress 0.1190253 \n#&gt; Run 204 stress 0.119378 \n#&gt; Run 205 stress 0.1187723 \n#&gt; Run 206 stress 0.1193228 \n#&gt; Run 207 stress 0.1190969 \n#&gt; Run 208 stress 0.1190627 \n#&gt; Run 209 stress 0.1184325 \n#&gt; Run 210 stress 0.1194397 \n#&gt; Run 211 stress 0.1194828 \n#&gt; Run 212 stress 0.1185745 \n#&gt; Run 213 stress 0.1186796 \n#&gt; Run 214 stress 0.1192906 \n#&gt; Run 215 stress 0.1200002 \n#&gt; Run 216 stress 0.1186742 \n#&gt; Run 217 stress 0.119254 \n#&gt; Run 218 stress 0.1191419 \n#&gt; Run 219 stress 0.120306 \n#&gt; Run 220 stress 0.119665 \n#&gt; Run 221 stress 0.1212614 \n#&gt; Run 222 stress 0.118446 \n#&gt; Run 223 stress 0.1191734 \n#&gt; Run 224 stress 0.1186459 \n#&gt; Run 225 stress 0.1186136 \n#&gt; Run 226 stress 0.1198339 \n#&gt; Run 227 stress 0.1189743 \n#&gt; Run 228 stress 0.1191247 \n#&gt; Run 229 stress 0.1186571 \n#&gt; Run 230 stress 0.1183342 \n#&gt; Run 231 stress 0.120657 \n#&gt; Run 232 stress 0.1200303 \n#&gt; Run 233 stress 0.1194832 \n#&gt; Run 234 stress 0.1183993 \n#&gt; Run 235 stress 0.1192708 \n#&gt; Run 236 stress 0.1195927 \n#&gt; Run 237 stress 0.1192793 \n#&gt; Run 238 stress 0.1203671 \n#&gt; Run 239 stress 0.1187571 \n#&gt; Run 240 stress 0.1206314 \n#&gt; Run 241 stress 0.1172878 \n#&gt; ... Procrustes: rmse 0.03546175  max resid 0.1313024 \n#&gt; Run 242 stress 0.1180823 \n#&gt; Run 243 stress 0.1204901 \n#&gt; Run 244 stress 0.1190983 \n#&gt; Run 245 stress 0.1199391 \n#&gt; Run 246 stress 0.1182834 \n#&gt; Run 247 stress 0.1184138 \n#&gt; Run 248 stress 0.1205916 \n#&gt; Run 249 stress 0.1173884 \n#&gt; ... Procrustes: rmse 0.06476341  max resid 0.2793467 \n#&gt; Run 250 stress 0.1184572 \n#&gt; Run 251 stress 0.1179883 \n#&gt; Run 252 stress 0.119103 \n#&gt; Run 253 stress 0.1208135 \n#&gt; Run 254 stress 0.1192279 \n#&gt; Run 255 stress 0.1194243 \n#&gt; Run 256 stress 0.1203805 \n#&gt; Run 257 stress 0.1196346 \n#&gt; Run 258 stress 0.1187809 \n#&gt; Run 259 stress 0.1220039 \n#&gt; Run 260 stress 0.1202155 \n#&gt; Run 261 stress 0.119038 \n#&gt; Run 262 stress 0.1185969 \n#&gt; Run 263 stress 0.1185206 \n#&gt; Run 264 stress 0.1191264 \n#&gt; Run 265 stress 0.1203919 \n#&gt; Run 266 stress 0.1193328 \n#&gt; Run 267 stress 0.119689 \n#&gt; Run 268 stress 0.1185788 \n#&gt; Run 269 stress 0.1190655 \n#&gt; Run 270 stress 0.1193243 \n#&gt; Run 271 stress 0.1204081 \n#&gt; Run 272 stress 0.1193853 \n#&gt; Run 273 stress 0.1191507 \n#&gt; Run 274 stress 0.1191006 \n#&gt; Run 275 stress 0.1194524 \n#&gt; Run 276 stress 0.1196515 \n#&gt; Run 277 stress 0.1191174 \n#&gt; Run 278 stress 0.1197212 \n#&gt; Run 279 stress 0.1195057 \n#&gt; Run 280 stress 0.1190863 \n#&gt; Run 281 stress 0.1173829 \n#&gt; ... Procrustes: rmse 0.04228723  max resid 0.2906148 \n#&gt; Run 282 stress 0.1183771 \n#&gt; Run 283 stress 0.118756 \n#&gt; Run 284 stress 0.1184836 \n#&gt; Run 285 stress 0.1193089 \n#&gt; Run 286 stress 0.1187367 \n#&gt; Run 287 stress 0.1211166 \n#&gt; Run 288 stress 0.118612 \n#&gt; Run 289 stress 0.1182366 \n#&gt; Run 290 stress 0.1190942 \n#&gt; Run 291 stress 0.118254 \n#&gt; Run 292 stress 0.1182043 \n#&gt; Run 293 stress 0.1210657 \n#&gt; Run 294 stress 0.1176667 \n#&gt; ... Procrustes: rmse 0.0316457  max resid 0.1553559 \n#&gt; Run 295 stress 0.1180872 \n#&gt; Run 296 stress 0.1173496 \n#&gt; ... Procrustes: rmse 0.05887519  max resid 0.229526 \n#&gt; Run 297 stress 0.1178518 \n#&gt; Run 298 stress 0.1220267 \n#&gt; Run 299 stress 0.1186454 \n#&gt; Run 300 stress 0.1205719 \n#&gt; *** Best solution was not repeated -- monoMDS stopping criteria:\n#&gt;    300: no. of iterations &gt;= maxit\n\n# plot the graph\nvegan::ordisurf((example_NMDS),CToperation_elev_sf$elevation,main=\"\",col=\"forestgreen\", trymax=100) # bubble = 2\n#&gt; \n#&gt; Family: gaussian \n#&gt; Link function: identity \n#&gt; \n#&gt; Formula:\n#&gt; y ~ s(x1, x2, k = 10, bs = \"tp\", fx = FALSE)\n#&gt; \n#&gt; Estimated degrees of freedom:\n#&gt; 5.1  total = 6.1 \n#&gt; \n#&gt; REML score: 732.1451\nvegan::orditorp(example_NMDS,display=\"species\",col=\"blue\",air=0.1,\n   cex=0.5)\n\n\n\n\n\n\n\nWe can make a similar plot using gg_ordisurf from the package ggordiplots but also incorporating habitat type.\n\nCode# ggordiplots::gg_ordisurf()\n# To fit a surface with ggordiplots:\n\n \nordiplot &lt;- gg_ordisurf(ord = example_NMDS, \n                        env.var = CToperation_elev_sf$elevation,\n                        var.label = \"Elevation\",\n                        pt.size = 2,\n                        groups = CToperation_elev_sf$hab_code,\n                        binwidth = 50)\n\n\n\n\n\n\nCode\n# ggplotly(ordiplot$plot) # see interactive\n\n# # alternative using biodiversityR\n# \n# A1.surface &lt;- ordisurf( y=example_NMDS)\n# A1.grid &lt;- ordisurfgrid.long(A1.surface)\n# # Preparing the plot\n# \n# plotgg4 &lt;- ggplot() + \n#     geom_contour_filled(data=A1.grid, \n#                         aes(x=x, y=y, z=z)) +\n#     geom_vline(xintercept = c(0), color = \"grey70\", linetype = 2) +\n#     geom_hline(yintercept = c(0), color = \"grey70\", linetype = 2) +  \n#     xlab(axis.long2[1, \"label\"]) +\n#     ylab(axis.long2[2, \"label\"]) +  \n#     scale_x_continuous(sec.axis = dup_axis(labels=NULL, name=NULL)) +\n#     scale_y_continuous(sec.axis = dup_axis(labels=NULL, name=NULL)) +\n#     geom_point(data=sites.long2, \n#                aes(x=axis1, y=axis2, shape=Management), \n#                colour=\"red\", size=4) +\n#     BioR.theme +\n#     scale_fill_viridis_d() +\n#     labs(fill=\"A1\") +\n#     coord_fixed(ratio=1)\n# # and seeing the plot.\n# \n# plotgg4\n\n\nThe contours connect species in the ordination space that are predicted to have the same elevation. Notice this is not a geographic map, it is a multivariate space."
  },
  {
    "objectID": "posts/2024-06-25-species-diversity/index.html#rarefaction-using-inext",
    "href": "posts/2024-06-25-species-diversity/index.html#rarefaction-using-inext",
    "title": "Species diversity",
    "section": "Rarefaction using iNEXT\n",
    "text": "Rarefaction using iNEXT\n\n\nCode\n\n\nout &lt;- iNEXT(incidence_cesar, # The data frame\n             q=0,# The type of diversity estimator \n             datatype=\"incidence_freq\",   # The type of analysis\n             knots=40,                    # The number of data points \n             se=TRUE,                     # confidence intervals\n             conf=0.95,                   # The level of confidence intervals\n             nboot=100)                    # The number of bootstraps \n\nggiNEXT(out, type=1)\n\n\n\n\n\n\nCodeggiNEXT(out, type=2)\n\n\n\n\n\n\nCodeggiNEXT(out, type=3)\n\n\n\n\n\n\nCode\np1 &lt;- ggiNEXT(out, type=1)+ theme_classic() +   #  type 1 = the diversity estimator\n        labs(x = \"Survey sites\", y = \"Richness\")\n  \np2 &lt;- ggiNEXT(out, type=2)+ theme_classic() +    #  type 2 = the survey coverage\n        labs(x = \"Survey sites\")\n    \ngrid.arrange(p1, p2, nrow = 2)\n\n\n\n\n\n\nCode##############\nout2 &lt;- iNEXT(incidence_cesar, q=c(0,1,2) ,datatype=\"incidence_freq\" )\n\nggiNEXT(out2, type=1, facet.var=\"Order.q\", color.var=\"Assemblage\") + theme_classic() \n\n\n\n\n\n\n\nThe iNEXT package is well suited for comparisons of diversity indices through the use of hill numbers - of which the q value = 1 represents the traditional diversity indices: The species richness is q = 0. The Shannon index is (q=1), and Simpson is (q=2). Note Increasing values of q reduces the influence of rare species on our estimate of community diversity."
  },
  {
    "objectID": "posts/2024-06-25-species-diversity/index.html#package-citation",
    "href": "posts/2024-06-25-species-diversity/index.html#package-citation",
    "title": "Species diversity",
    "section": "Package Citation",
    "text": "Package Citation\n\nCodepkgs &lt;- cite_packages(output = \"paragraph\", out.dir = \".\") #knitr::kable(pkgs)\npkgs\n\nWe used R v. 4.4.2 (R Core Team 2024) and the following R packages: camtrapR v. 3.0.0 (Niedballa et al. 2016), devtools v. 2.4.6 (Wickham et al. 2025), DT v. 0.34.0 (Xie et al. 2025), eks v. 1.1.1 (Duong 2025), elevatr v. 0.99.0 (Hollister et al. 2023), ggforce v. 0.4.2 (Pedersen 2024), ggordiplots v. 0.4.3 (Quensen, Simpson, and Oksanen 2024), ggvegan v. 0.1.999 (Simpson and Oksanen 2023), gridExtra v. 2.3 (Auguie 2017), iNEXT v. 3.0.1 (Chao et al. 2014; Hsieh, Ma, and Chao 2024), kableExtra v. 1.4.0 (Zhu 2024), knitr v. 1.50 (Xie 2014, 2015, 2025), mapview v. 2.11.4 (Appelhans et al. 2025), MeanRarity v. 0.0.1.5 (Roswell and Dushoff 2023), patchwork v. 1.3.2 (Pedersen 2025), plotly v. 4.10.4 (Sievert 2020), plyr v. 1.8.9 (Wickham 2011), reshape2 v. 1.4.4 (Wickham 2007), rmarkdown v. 2.30 (Xie, Allaire, and Grolemund 2018; Xie, Dervieux, and Riederer 2020; Allaire et al. 2025), scales v. 1.4.0 (Wickham, Pedersen, and Seidel 2025), sf v. 1.0.21 (Pebesma 2018; Pebesma and Bivand 2023), SpadeR v. 0.1.1 (Chao et al. 2016), tidyverse v. 2.0.0 (Wickham et al. 2019), tmap v. 4.2 (Tennekes 2018), vegan v. 2.7.2 (Oksanen et al. 2025)."
  },
  {
    "objectID": "posts/2024-06-25-species-diversity/index.html#sesion-info",
    "href": "posts/2024-06-25-species-diversity/index.html#sesion-info",
    "title": "Species diversity",
    "section": "Sesion info",
    "text": "Sesion info\n\nSession info\n\n#&gt; ─ Session info ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n#&gt;  setting  value\n#&gt;  version  R version 4.4.2 (2024-10-31 ucrt)\n#&gt;  os       Windows 10 x64 (build 19045)\n#&gt;  system   x86_64, mingw32\n#&gt;  ui       RTerm\n#&gt;  language (EN)\n#&gt;  collate  Spanish_Colombia.utf8\n#&gt;  ctype    Spanish_Colombia.utf8\n#&gt;  tz       America/Bogota\n#&gt;  date     2025-11-05\n#&gt;  pandoc   3.6.3 @ C:/Program Files/RStudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n#&gt;  quarto   NA @ C:\\\\Users\\\\usuario\\\\AppData\\\\Local\\\\Programs\\\\Quarto\\\\bin\\\\quarto.exe\n#&gt; \n#&gt; ─ Packages ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n#&gt;  ! package           * version    date (UTC) lib source\n#&gt;    abind               1.4-8      2024-09-12 [1] CRAN (R 4.4.1)\n#&gt;    base64enc           0.1-3      2015-07-28 [1] CRAN (R 4.4.0)\n#&gt;    brew                1.0-10     2023-12-16 [1] CRAN (R 4.4.2)\n#&gt;    bslib               0.9.0      2025-01-30 [1] CRAN (R 4.4.3)\n#&gt;    cachem              1.1.0      2024-05-16 [1] CRAN (R 4.4.2)\n#&gt;    camtrapR          * 3.0.0      2025-09-28 [1] CRAN (R 4.4.3)\n#&gt;    cellranger          1.1.0      2016-07-27 [1] CRAN (R 4.4.2)\n#&gt;    class               7.3-22     2023-05-03 [2] CRAN (R 4.4.2)\n#&gt;    classInt            0.4-11     2025-01-08 [1] CRAN (R 4.4.3)\n#&gt;    cli                 3.6.5      2025-04-23 [1] CRAN (R 4.4.3)\n#&gt;    cluster             2.1.6      2023-12-01 [2] CRAN (R 4.4.2)\n#&gt;    codetools           0.2-20     2024-03-31 [2] CRAN (R 4.4.2)\n#&gt;    colorspace          2.1-1      2024-07-26 [1] CRAN (R 4.4.2)\n#&gt;    cols4all            0.8-1      2025-08-17 [1] Github (cols4all/cols4all-R@d39bcbd)\n#&gt;    crayon              1.5.3      2024-06-20 [1] CRAN (R 4.4.2)\n#&gt;    crosstalk           1.2.1      2023-11-23 [1] CRAN (R 4.4.2)\n#&gt;    curl                7.0.0      2025-08-19 [1] CRAN (R 4.4.3)\n#&gt;    data.table          1.17.8     2025-07-10 [1] CRAN (R 4.4.3)\n#&gt;    DBI                 1.2.3      2024-06-02 [1] CRAN (R 4.4.2)\n#&gt;    devtools            2.4.6      2025-10-03 [1] CRAN (R 4.4.3)\n#&gt;    dichromat           2.0-0.1    2022-05-02 [1] CRAN (R 4.4.0)\n#&gt;    digest              0.6.37     2024-08-19 [1] CRAN (R 4.4.2)\n#&gt;    dplyr             * 1.1.4      2023-11-17 [1] CRAN (R 4.4.2)\n#&gt;    DT                * 0.34.0     2025-09-02 [1] CRAN (R 4.4.3)\n#&gt;    e1071               1.7-16     2024-09-16 [1] CRAN (R 4.4.2)\n#&gt;    eks               * 1.1.1      2025-07-08 [1] CRAN (R 4.4.3)\n#&gt;    elevatr           * 0.99.0     2023-09-12 [1] CRAN (R 4.4.2)\n#&gt;    ellipsis            0.3.2      2021-04-29 [1] CRAN (R 4.4.2)\n#&gt;    evaluate            1.0.4      2025-06-18 [1] CRAN (R 4.4.3)\n#&gt;    farver              2.1.2      2024-05-13 [1] CRAN (R 4.4.2)\n#&gt;    fastmap             1.2.0      2024-05-15 [1] CRAN (R 4.4.2)\n#&gt;    forcats           * 1.0.0      2023-01-29 [1] CRAN (R 4.4.2)\n#&gt;    fs                  1.6.6      2025-04-12 [1] CRAN (R 4.4.3)\n#&gt;    generics            0.1.3      2022-07-05 [1] CRAN (R 4.4.2)\n#&gt;    geos                0.2.4      2023-11-30 [1] CRAN (R 4.4.3)\n#&gt;    ggforce           * 0.4.2      2024-02-19 [1] CRAN (R 4.4.2)\n#&gt;    ggordiplots       * 0.4.3      2024-01-14 [1] CRAN (R 4.4.2)\n#&gt;    ggplot2           * 4.0.0      2025-09-11 [1] CRAN (R 4.4.3)\n#&gt;    ggrepel             0.9.6      2024-09-07 [1] CRAN (R 4.4.2)\n#&gt;    ggvegan           * 0.1.999    2024-12-15 [1] Github (gavinsimpson/ggvegan@058c08c)\n#&gt;    glue              * 1.8.0      2024-09-30 [1] CRAN (R 4.4.2)\n#&gt;    grateful          * 0.3.0      2025-09-04 [1] CRAN (R 4.4.3)\n#&gt;    gridExtra         * 2.3        2017-09-09 [1] CRAN (R 4.4.2)\n#&gt;    gtable              0.3.6      2024-10-25 [1] CRAN (R 4.4.2)\n#&gt;    hms                 1.1.3      2023-03-21 [1] CRAN (R 4.4.2)\n#&gt;    htmltools           0.5.8.1    2024-04-04 [1] CRAN (R 4.4.2)\n#&gt;    htmlwidgets         1.6.4      2023-12-06 [1] CRAN (R 4.4.2)\n#&gt;    httpuv              1.6.16     2025-04-16 [1] CRAN (R 4.4.3)\n#&gt;    httr                1.4.7      2023-08-15 [1] CRAN (R 4.4.2)\n#&gt;    iNEXT             * 3.0.1      2024-03-24 [1] CRAN (R 4.4.2)\n#&gt;    isoband             0.2.7      2022-12-20 [1] CRAN (R 4.4.2)\n#&gt;    jquerylib           0.1.4      2021-04-26 [1] CRAN (R 4.4.2)\n#&gt;    jsonlite            2.0.0      2025-03-27 [1] CRAN (R 4.4.3)\n#&gt;    kableExtra        * 1.4.0      2024-01-24 [1] CRAN (R 4.4.2)\n#&gt;    KernSmooth          2.23-24    2024-05-17 [2] CRAN (R 4.4.2)\n#&gt;    knitr             * 1.50       2025-03-16 [1] CRAN (R 4.4.3)\n#&gt;    ks                  1.15.1     2025-05-04 [1] CRAN (R 4.4.3)\n#&gt;    labeling            0.4.3      2023-08-29 [1] CRAN (R 4.4.0)\n#&gt;    later               1.4.2      2025-04-08 [1] CRAN (R 4.4.3)\n#&gt;    lattice             0.22-6     2024-03-20 [2] CRAN (R 4.4.2)\n#&gt;    lazyeval            0.2.2      2019-03-15 [1] CRAN (R 4.4.2)\n#&gt;    leafem              0.2.4      2025-05-01 [1] CRAN (R 4.4.3)\n#&gt;    leaflegend          1.2.1      2024-05-09 [1] CRAN (R 4.4.2)\n#&gt;    leaflet             2.2.3      2025-09-04 [1] CRAN (R 4.4.3)\n#&gt;    leaflet.providers   2.0.0      2023-10-17 [1] CRAN (R 4.4.2)\n#&gt;    leafpop             0.1.0      2021-05-22 [1] CRAN (R 4.4.2)\n#&gt;    leafsync            0.1.0      2019-03-05 [1] CRAN (R 4.4.2)\n#&gt;    libgeos             3.11.1-3   2025-03-19 [1] CRAN (R 4.4.3)\n#&gt;    lifecycle           1.0.4      2023-11-07 [1] CRAN (R 4.4.2)\n#&gt;    logger              0.4.0      2024-10-22 [1] CRAN (R 4.4.3)\n#&gt;    lubridate         * 1.9.4      2024-12-08 [1] CRAN (R 4.4.2)\n#&gt;    lwgeom              0.2-14     2024-02-21 [1] CRAN (R 4.4.2)\n#&gt;    magrittr            2.0.3      2022-03-30 [1] CRAN (R 4.4.2)\n#&gt;    maplegend           0.2.0      2024-11-12 [1] CRAN (R 4.4.2)\n#&gt;    mapsf               1.0.0      2025-07-01 [1] CRAN (R 4.4.3)\n#&gt;    maptiles            0.10.0     2025-05-07 [1] CRAN (R 4.4.3)\n#&gt;    mapview           * 2.11.4     2025-09-08 [1] CRAN (R 4.4.3)\n#&gt;    MASS                7.3-61     2024-06-13 [2] CRAN (R 4.4.2)\n#&gt;    Matrix              1.7-1      2024-10-18 [2] CRAN (R 4.4.2)\n#&gt;    mclust              6.1.1      2024-04-29 [1] CRAN (R 4.4.2)\n#&gt;    MeanRarity        * 0.0.1.0005 2024-12-15 [1] Github (mikeroswell/MeanRarity@a8b518d)\n#&gt;    memoise             2.0.1      2021-11-26 [1] CRAN (R 4.4.2)\n#&gt;    mgcv                1.9-1      2023-12-21 [2] CRAN (R 4.4.2)\n#&gt;    microbenchmark      1.5.0      2024-09-04 [1] CRAN (R 4.4.2)\n#&gt;    mime                0.13       2025-03-17 [1] CRAN (R 4.4.3)\n#&gt;    mvtnorm             1.3-2      2024-11-04 [1] CRAN (R 4.4.2)\n#&gt;    nlme                3.1-166    2024-08-14 [2] CRAN (R 4.4.2)\n#&gt;    patchwork         * 1.3.2      2025-08-25 [1] CRAN (R 4.4.3)\n#&gt;    permute           * 0.9-7      2022-01-27 [1] CRAN (R 4.4.2)\n#&gt;    pillar              1.11.1     2025-09-17 [1] CRAN (R 4.4.2)\n#&gt;    pkgbuild            1.4.8      2025-05-26 [1] CRAN (R 4.4.3)\n#&gt;    pkgconfig           2.0.3      2019-09-22 [1] CRAN (R 4.4.2)\n#&gt;    pkgload             1.4.1      2025-09-23 [1] CRAN (R 4.4.3)\n#&gt;    plotly            * 4.10.4     2024-01-13 [1] CRAN (R 4.4.2)\n#&gt;    plyr              * 1.8.9      2023-10-02 [1] CRAN (R 4.4.2)\n#&gt;    png                 0.1-8      2022-11-29 [1] CRAN (R 4.4.0)\n#&gt;    polyclip            1.10-7     2024-07-23 [1] CRAN (R 4.4.1)\n#&gt;    pracma              2.4.4      2023-11-10 [1] CRAN (R 4.4.2)\n#&gt;    prettyunits         1.2.0      2023-09-24 [1] CRAN (R 4.4.2)\n#&gt;    progress            1.2.3      2023-12-06 [1] CRAN (R 4.4.2)\n#&gt;    progressr           0.15.0     2024-10-29 [1] CRAN (R 4.4.2)\n#&gt;    promises            1.3.3      2025-05-29 [1] CRAN (R 4.4.3)\n#&gt;    proxy               0.4-27     2022-06-09 [1] CRAN (R 4.4.2)\n#&gt;    purrr             * 1.1.0      2025-07-10 [1] CRAN (R 4.4.3)\n#&gt;    R6                  2.6.1      2025-02-15 [1] CRAN (R 4.4.2)\n#&gt;    raster              3.6-32     2025-03-28 [1] CRAN (R 4.4.3)\n#&gt;    rbibutils           2.3        2024-10-04 [1] CRAN (R 4.4.2)\n#&gt;    RColorBrewer        1.1-3      2022-04-03 [1] CRAN (R 4.4.0)\n#&gt;    Rcpp                1.1.0      2025-07-02 [1] CRAN (R 4.4.3)\n#&gt;    RcppNumerical       0.6-0      2023-09-06 [1] CRAN (R 4.4.2)\n#&gt;  D RcppParallel        5.1.9      2024-08-19 [1] CRAN (R 4.4.2)\n#&gt;    Rdpack              2.6.2      2024-11-15 [1] CRAN (R 4.4.2)\n#&gt;    readr             * 2.1.5      2024-01-10 [1] CRAN (R 4.4.2)\n#&gt;    readxl            * 1.4.3      2023-07-06 [1] CRAN (R 4.4.2)\n#&gt;    remotes             2.5.0      2024-03-17 [1] CRAN (R 4.4.3)\n#&gt;    renv                1.0.11     2024-10-12 [1] CRAN (R 4.4.2)\n#&gt;    reshape2          * 1.4.4      2020-04-09 [1] CRAN (R 4.4.2)\n#&gt;    rlang               1.1.6      2025-04-11 [1] CRAN (R 4.4.3)\n#&gt;    rmarkdown           2.30       2025-09-28 [1] CRAN (R 4.4.3)\n#&gt;    rstudioapi          0.17.1     2024-10-22 [1] CRAN (R 4.4.2)\n#&gt;    s2                  1.1.9      2025-05-23 [1] CRAN (R 4.4.3)\n#&gt;    S7                  0.2.0      2024-11-07 [1] CRAN (R 4.4.3)\n#&gt;    sass                0.4.10     2025-04-11 [1] CRAN (R 4.4.3)\n#&gt;    satellite           1.0.5      2024-02-10 [1] CRAN (R 4.4.2)\n#&gt;    scales            * 1.4.0      2025-04-24 [1] CRAN (R 4.4.3)\n#&gt;    secr                5.1.0      2024-11-04 [1] CRAN (R 4.4.2)\n#&gt;    sessioninfo         1.2.3      2025-02-05 [1] CRAN (R 4.4.3)\n#&gt;    sf                * 1.0-21     2025-05-15 [1] CRAN (R 4.4.3)\n#&gt;    shiny               1.9.1      2024-08-01 [1] CRAN (R 4.4.2)\n#&gt;    shinyBS             0.61.1     2022-04-17 [1] CRAN (R 4.4.3)\n#&gt;    shinydashboard      0.7.3      2025-04-21 [1] CRAN (R 4.4.3)\n#&gt;    slippymath          0.3.1      2019-06-28 [1] CRAN (R 4.4.2)\n#&gt;    sp                  2.2-0      2025-02-01 [1] CRAN (R 4.4.3)\n#&gt;    spacesXYZ           1.6-0      2025-06-06 [1] CRAN (R 4.4.3)\n#&gt;    SpadeR            * 0.1.1      2016-09-06 [1] CRAN (R 4.4.0)\n#&gt;    stars               0.6-8      2025-02-01 [1] CRAN (R 4.4.2)\n#&gt;    stringi             1.8.4      2024-05-06 [1] CRAN (R 4.4.0)\n#&gt;    stringr           * 1.5.2      2025-09-08 [1] CRAN (R 4.4.3)\n#&gt;    svglite             2.1.3      2023-12-08 [1] CRAN (R 4.4.2)\n#&gt;    systemfonts         1.1.0      2024-05-15 [1] CRAN (R 4.4.2)\n#&gt;    terra               1.8-70     2025-09-27 [1] CRAN (R 4.4.3)\n#&gt;    tibble            * 3.2.1      2023-03-20 [1] CRAN (R 4.4.2)\n#&gt;    tidyr             * 1.3.1      2024-01-24 [1] CRAN (R 4.4.2)\n#&gt;    tidyselect          1.2.1      2024-03-11 [1] CRAN (R 4.4.2)\n#&gt;    tidyverse         * 2.0.0      2023-02-22 [1] CRAN (R 4.4.2)\n#&gt;    timechange          0.3.0      2024-01-18 [1] CRAN (R 4.4.2)\n#&gt;    tmap              * 4.2        2025-09-10 [1] CRAN (R 4.4.3)\n#&gt;    tmaptools           3.3        2025-07-24 [1] CRAN (R 4.4.3)\n#&gt;    tweenr              2.0.3      2024-02-26 [1] CRAN (R 4.4.2)\n#&gt;    tzdb                0.4.0      2023-05-12 [1] CRAN (R 4.4.2)\n#&gt;    units               0.8-7      2025-03-11 [1] CRAN (R 4.4.3)\n#&gt;    usethis             3.2.1      2025-09-06 [1] CRAN (R 4.4.3)\n#&gt;    uuid                1.2-1      2024-07-29 [1] CRAN (R 4.4.1)\n#&gt;    vctrs               0.6.5      2023-12-01 [1] CRAN (R 4.4.2)\n#&gt;    vegan             * 2.7-2      2025-10-08 [1] CRAN (R 4.4.3)\n#&gt;    viridisLite         0.4.2      2023-05-02 [1] CRAN (R 4.4.2)\n#&gt;    withr               3.0.2      2024-10-28 [1] CRAN (R 4.4.2)\n#&gt;    wk                  0.9.4      2024-10-11 [1] CRAN (R 4.4.2)\n#&gt;    xfun                0.52       2025-04-02 [1] CRAN (R 4.4.3)\n#&gt;    XML                 3.99-0.18  2025-01-01 [1] CRAN (R 4.4.3)\n#&gt;    xml2                1.4.0      2025-08-20 [1] CRAN (R 4.4.3)\n#&gt;    xtable              1.8-4      2019-04-21 [1] CRAN (R 4.4.2)\n#&gt;    yaml                2.3.10     2024-07-26 [1] CRAN (R 4.4.1)\n#&gt; \n#&gt;  [1] C:/Users/usuario/AppData/Local/R/win-library/4.4\n#&gt;  [2] C:/Program Files/R/R-4.4.2/library\n#&gt; \n#&gt;  * ── Packages attached to the search path.\n#&gt;  D ── DLL MD5 mismatch, broken installation.\n#&gt; \n#&gt; ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/2024-06-15-visualizing-the-data/index.html",
    "href": "posts/2024-06-15-visualizing-the-data/index.html",
    "title": "Visualizing Cesar Cameratrap Data",
    "section": "",
    "text": "As a simple map and calendar"
  },
  {
    "objectID": "posts/2024-06-15-visualizing-the-data/index.html#load-packages",
    "href": "posts/2024-06-15-visualizing-the-data/index.html#load-packages",
    "title": "Visualizing Cesar Cameratrap Data",
    "section": "Load packages",
    "text": "Load packages\n\nCode\n# library(ggpmthemes)\nlibrary(glue) # Interpreted String Literals\nlibrary(curl) # A Modern and Flexible Web Client for R\nlibrary(patchwork) # The Composer of Plots\nlibrary(readxl) # Read Excel Files\nlibrary(sf) # Simple Features for R\nlibrary(mapview) # Interactive Viewing of Spatial Data in R\nlibrary(ggTimeSeries) # calendar\nlibrary(grateful) # Facilitate Citation of R Packages\n\nlibrary(knitr) # A General-Purpose Package for Dynamic Report Generation in R\n# options(kableExtra.auto_format = FALSE)\nlibrary(kableExtra) # Construct Complex Table with 'kable' and Pipe Syntax\nlibrary(tidyverse) # Easily Install and Load the 'Tidyverse'\nlibrary(ggforce) # Accelerating 'ggplot2'\n\nsource(\"C:/CodigoR/CameraTrapCesar/R/organiza_datos.R\")"
  },
  {
    "objectID": "posts/2024-06-15-visualizing-the-data/index.html#load-data",
    "href": "posts/2024-06-15-visualizing-the-data/index.html#load-data",
    "title": "Visualizing Cesar Cameratrap Data",
    "section": "Load data",
    "text": "Load data\n\nCode\ndatos &lt;- read_excel(\"C:/CodigoR/CameraTrapCesar/data/CT_Cesar.xlsx\")"
  },
  {
    "objectID": "posts/2024-06-15-visualizing-the-data/index.html#convert-to-sf",
    "href": "posts/2024-06-15-visualizing-the-data/index.html#convert-to-sf",
    "title": "Visualizing Cesar Cameratrap Data",
    "section": "Convert to sf",
    "text": "Convert to sf\n\nCode\ndatos_distinct &lt;- datos |&gt; distinct(Longitude, Latitude, CT, Proyecto)\n\nprojlatlon &lt;- \"+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0\"\n\ndatos_sf &lt;-  st_as_sf(x = datos_distinct,\n                         coords = c(\"Longitude\", \n                                    \"Latitude\"),\n                         crs = projlatlon)"
  },
  {
    "objectID": "posts/2024-06-15-visualizing-the-data/index.html#plot-all",
    "href": "posts/2024-06-15-visualizing-the-data/index.html#plot-all",
    "title": "Visualizing Cesar Cameratrap Data",
    "section": "Plot all",
    "text": "Plot all\n\nCodemapview(datos_sf, zcol=\"Proyecto\")\n\n\n\n\nCode\n\ncalendario &lt;- function(data=datos, Proyect=Proyecto){\n  dtData&lt;- datos |&gt; filter(Proyecto==Proyect) |&gt; #|&gt; filter(Year==\"2022\")\n  # becerril$Date_Time &lt;- as_date(as.character(data$eventDate))\n      mutate(Date_Time=as.Date(eventDate, \"%d/%m/%Y\")) |&gt; \n      count(Date_Time) |&gt; na.omit()\n  \n  # base plot\n  p1 = ggplot_calendar_heatmap(\n     dtData,\n     'Date_Time',\n     'n',\n     dayBorderSize = 0.1,\n     monthBorderSize = 0.7\n  )\n  \n  # adding some formatting\n  p1 +\n     xlab(NULL) +\n     ylab(NULL) +\n     scale_fill_continuous(low = 'cyan', high = 'red') +\n     facet_wrap(~Year, ncol = 1) # number of columns\n} # end function"
  },
  {
    "objectID": "posts/2024-06-15-visualizing-the-data/index.html#see-camera-calendar-per-proyecto",
    "href": "posts/2024-06-15-visualizing-the-data/index.html#see-camera-calendar-per-proyecto",
    "title": "Visualizing Cesar Cameratrap Data",
    "section": "See camera calendar per Proyecto",
    "text": "See camera calendar per Proyecto\nBecerril\n\nCode\ncalendario(data=datos, Proyect = \"Becerril\")\n\n\n\n\n\n\nCode\n# species &lt;- f.det_history.creator(data=becerril_2022)\n# \n# \n# min(dmy(becerril_2022$Start))\n# max(dmy(becerril_2022$Start))\n# \n# min(dmy(becerril_2022$eventDate))\n\n\nLas camaras en Becerril estuvieron activas año y medio.\nLaPaz_Manaure\n\nCode\ncalendario(data=datos, Proyect = \"LaPaz_Manaure\")\n\n\n\n\n\n\n\nPCF\n\nCodecalendario(data=datos, Proyect = \"PCF\")\n\n\n\n\n\n\n\nCL\n\nCodecalendario(data=datos, Proyect = \"CL\")\n\n\n\n\n\n\n\nEDN\n\nCodecalendario(data=datos, Proyect = \"EDN\")\n\n\n\n\n\n\n\nPB\n\nCodecalendario(data=datos, Proyect = \"PB\" )\n\n\n\n\n\n\n\nEDS\n\nCodecalendario(data=datos, Proyect = \"EDS\" )\n\n\n\n\n\n\n\nCCI\n\nCodecalendario(data=datos, Proyect = \"CCI\" )\n\n\n\n\n\n\n\nMLJ\n\nCodecalendario(data=datos, Proyect = \"MLJ\" )\n\n\n\n\n\n\n\nMCAL\n\nCodecalendario(data=datos, Proyect = \"MCAL\" )"
  },
  {
    "objectID": "posts/2024-06-15-visualizing-the-data/index.html#package-citation",
    "href": "posts/2024-06-15-visualizing-the-data/index.html#package-citation",
    "title": "Visualizing Cesar Cameratrap Data",
    "section": "Package Citation",
    "text": "Package Citation\n\nCodepkgs &lt;- cite_packages(output = \"paragraph\", out.dir = \".\") #knitr::kable(pkgs)\npkgs\n\nWe used R version 4.3.2 (R Core Team 2023) and the following R packages: curl v. 5.2.0 (Ooms 2023), devtools v. 2.4.5 (Wickham et al. 2022), ggforce v. 0.4.2 (Pedersen 2024a), ggTimeSeries v. 1.0.2 (Kothari 2022), glue v. 1.7.0 (Hester and Bryan 2024), kableExtra v. 1.4.0 (Zhu 2024), knitr v. 1.46 (Xie 2014, 2015, 2024), mapview v. 2.11.2 (Appelhans et al. 2023), patchwork v. 1.2.0 (Pedersen 2024b), quarto v. 1.4 (Allaire and Dervieux 2024), rmarkdown v. 2.27 (Xie, Allaire, and Grolemund 2018; Xie, Dervieux, and Riederer 2020; Allaire et al. 2024), sf v. 1.0.15 (Pebesma 2018; Pebesma and Bivand 2023), styler v. 1.10.3 (Müller and Walthert 2024), tidyverse v. 2.0.0 (Wickham et al. 2019)."
  },
  {
    "objectID": "posts/2024-06-15-visualizing-the-data/index.html#sesion-info",
    "href": "posts/2024-06-15-visualizing-the-data/index.html#sesion-info",
    "title": "Visualizing Cesar Cameratrap Data",
    "section": "Sesion info",
    "text": "Sesion info\n\nSession info\n\n#&gt; ─ Session info ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n#&gt;  setting  value\n#&gt;  version  R version 4.3.2 (2023-10-31 ucrt)\n#&gt;  os       Windows 10 x64 (build 19042)\n#&gt;  system   x86_64, mingw32\n#&gt;  ui       RTerm\n#&gt;  language (EN)\n#&gt;  collate  Spanish_Colombia.utf8\n#&gt;  ctype    Spanish_Colombia.utf8\n#&gt;  tz       America/Bogota\n#&gt;  date     2024-06-23\n#&gt;  pandoc   3.1.11 @ C:/Program Files/RStudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n#&gt; \n#&gt; ─ Packages ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n#&gt;  package           * version date (UTC) lib source\n#&gt;  base64enc           0.1-3   2015-07-28 [1] CRAN (R 4.3.1)\n#&gt;  brew                1.0-10  2023-12-16 [1] CRAN (R 4.3.2)\n#&gt;  cachem              1.0.8   2023-05-01 [1] CRAN (R 4.3.2)\n#&gt;  cellranger          1.1.0   2016-07-27 [1] CRAN (R 4.3.2)\n#&gt;  class               7.3-22  2023-05-03 [2] CRAN (R 4.3.2)\n#&gt;  classInt            0.4-10  2023-09-05 [1] CRAN (R 4.3.2)\n#&gt;  cli                 3.6.2   2023-12-11 [1] CRAN (R 4.3.2)\n#&gt;  codetools           0.2-19  2023-02-01 [2] CRAN (R 4.3.2)\n#&gt;  colorspace          2.1-0   2023-01-23 [1] CRAN (R 4.3.2)\n#&gt;  crosstalk           1.2.1   2023-11-23 [1] CRAN (R 4.3.2)\n#&gt;  curl              * 5.2.0   2023-12-08 [1] CRAN (R 4.3.2)\n#&gt;  data.table          1.15.0  2024-01-30 [1] CRAN (R 4.3.2)\n#&gt;  DBI                 1.2.2   2024-02-16 [1] CRAN (R 4.3.2)\n#&gt;  devtools            2.4.5   2022-10-11 [1] CRAN (R 4.3.2)\n#&gt;  digest              0.6.34  2024-01-11 [1] CRAN (R 4.3.2)\n#&gt;  dplyr             * 1.1.4   2023-11-17 [1] CRAN (R 4.3.2)\n#&gt;  e1071               1.7-14  2023-12-06 [1] CRAN (R 4.3.2)\n#&gt;  ellipsis            0.3.2   2021-04-29 [1] CRAN (R 4.3.2)\n#&gt;  evaluate            0.23    2023-11-01 [1] CRAN (R 4.3.2)\n#&gt;  fansi               1.0.6   2023-12-08 [1] CRAN (R 4.3.2)\n#&gt;  farver              2.1.1   2022-07-06 [1] CRAN (R 4.3.2)\n#&gt;  fastmap             1.1.1   2023-02-24 [1] CRAN (R 4.3.2)\n#&gt;  forcats           * 1.0.0   2023-01-29 [1] CRAN (R 4.3.2)\n#&gt;  fs                  1.6.3   2023-07-20 [1] CRAN (R 4.3.2)\n#&gt;  generics            0.1.3   2022-07-05 [1] CRAN (R 4.3.2)\n#&gt;  ggforce           * 0.4.2   2024-02-19 [1] CRAN (R 4.3.3)\n#&gt;  ggplot2           * 3.5.1   2024-04-23 [1] CRAN (R 4.3.3)\n#&gt;  ggTimeSeries      * 1.0.2   2022-01-23 [1] CRAN (R 4.3.3)\n#&gt;  glue              * 1.7.0   2024-01-09 [1] CRAN (R 4.3.2)\n#&gt;  grateful          * 0.2.4   2023-10-22 [1] CRAN (R 4.3.3)\n#&gt;  gtable              0.3.4   2023-08-21 [1] CRAN (R 4.3.2)\n#&gt;  hms                 1.1.3   2023-03-21 [1] CRAN (R 4.3.2)\n#&gt;  htmltools           0.5.7   2023-11-03 [1] CRAN (R 4.3.2)\n#&gt;  htmlwidgets         1.6.4   2023-12-06 [1] CRAN (R 4.3.2)\n#&gt;  httpuv              1.6.14  2024-01-26 [1] CRAN (R 4.3.2)\n#&gt;  jquerylib           0.1.4   2021-04-26 [1] CRAN (R 4.3.2)\n#&gt;  jsonlite            1.8.8   2023-12-04 [1] CRAN (R 4.3.2)\n#&gt;  kableExtra        * 1.4.0   2024-01-24 [1] CRAN (R 4.3.3)\n#&gt;  KernSmooth          2.23-22 2023-07-10 [2] CRAN (R 4.3.2)\n#&gt;  knitr             * 1.46    2024-04-06 [1] CRAN (R 4.3.3)\n#&gt;  labeling            0.4.3   2023-08-29 [1] CRAN (R 4.3.1)\n#&gt;  later               1.3.2   2023-12-06 [1] CRAN (R 4.3.2)\n#&gt;  lattice             0.22-5  2023-10-24 [1] CRAN (R 4.3.2)\n#&gt;  leafem              0.2.3   2023-09-17 [1] CRAN (R 4.3.2)\n#&gt;  leaflet             2.2.1   2023-11-13 [1] CRAN (R 4.3.2)\n#&gt;  leaflet.providers   2.0.0   2023-10-17 [1] CRAN (R 4.3.2)\n#&gt;  leafpop             0.1.0   2021-05-22 [1] CRAN (R 4.3.2)\n#&gt;  lifecycle           1.0.4   2023-11-07 [1] CRAN (R 4.3.2)\n#&gt;  lubridate         * 1.9.3   2023-09-27 [1] CRAN (R 4.3.2)\n#&gt;  magrittr            2.0.3   2022-03-30 [1] CRAN (R 4.3.2)\n#&gt;  mapview           * 2.11.2  2023-10-13 [1] CRAN (R 4.3.2)\n#&gt;  MASS                7.3-60  2023-05-04 [2] CRAN (R 4.3.2)\n#&gt;  memoise             2.0.1   2021-11-26 [1] CRAN (R 4.3.2)\n#&gt;  mime                0.12    2021-09-28 [1] CRAN (R 4.3.1)\n#&gt;  miniUI              0.1.1.1 2018-05-18 [1] CRAN (R 4.3.2)\n#&gt;  munsell             0.5.0   2018-06-12 [1] CRAN (R 4.3.2)\n#&gt;  patchwork         * 1.2.0   2024-01-08 [1] CRAN (R 4.3.3)\n#&gt;  pillar              1.9.0   2023-03-22 [1] CRAN (R 4.3.2)\n#&gt;  pkgbuild            1.4.4   2024-03-17 [1] CRAN (R 4.3.3)\n#&gt;  pkgconfig           2.0.3   2019-09-22 [1] CRAN (R 4.3.2)\n#&gt;  pkgload             1.3.4   2024-01-16 [1] CRAN (R 4.3.2)\n#&gt;  png                 0.1-8   2022-11-29 [1] CRAN (R 4.3.1)\n#&gt;  polyclip            1.10-6  2023-09-27 [1] CRAN (R 4.3.1)\n#&gt;  processx            3.8.3   2023-12-10 [1] CRAN (R 4.3.2)\n#&gt;  profvis             0.3.8   2023-05-02 [1] CRAN (R 4.3.2)\n#&gt;  promises            1.2.1   2023-08-10 [1] CRAN (R 4.3.2)\n#&gt;  proxy               0.4-27  2022-06-09 [1] CRAN (R 4.3.2)\n#&gt;  ps                  1.7.6   2024-01-18 [1] CRAN (R 4.3.2)\n#&gt;  purrr             * 1.0.2   2023-08-10 [1] CRAN (R 4.3.2)\n#&gt;  quarto            * 1.4     2024-03-06 [1] CRAN (R 4.3.3)\n#&gt;  R.cache             0.16.0  2022-07-21 [1] CRAN (R 4.3.3)\n#&gt;  R.methodsS3         1.8.2   2022-06-13 [1] CRAN (R 4.3.3)\n#&gt;  R.oo                1.26.0  2024-01-24 [1] CRAN (R 4.3.3)\n#&gt;  R.utils             2.12.3  2023-11-18 [1] CRAN (R 4.3.3)\n#&gt;  R6                  2.5.1   2021-08-19 [1] CRAN (R 4.3.2)\n#&gt;  raster              3.6-26  2023-10-14 [1] CRAN (R 4.3.2)\n#&gt;  Rcpp                1.0.12  2024-01-09 [1] CRAN (R 4.3.2)\n#&gt;  readr             * 2.1.5   2024-01-10 [1] CRAN (R 4.3.2)\n#&gt;  readxl            * 1.4.3   2023-07-06 [1] CRAN (R 4.3.2)\n#&gt;  remotes             2.5.0   2024-03-17 [1] CRAN (R 4.3.3)\n#&gt;  renv                1.0.3   2023-09-19 [1] CRAN (R 4.3.2)\n#&gt;  rlang               1.1.3   2024-01-10 [1] CRAN (R 4.3.2)\n#&gt;  rmarkdown           2.27    2024-05-17 [1] CRAN (R 4.3.3)\n#&gt;  rstudioapi          0.16.0  2024-03-24 [1] CRAN (R 4.3.3)\n#&gt;  satellite           1.0.5   2024-02-10 [1] CRAN (R 4.3.2)\n#&gt;  scales              1.3.0   2023-11-28 [1] CRAN (R 4.3.3)\n#&gt;  sessioninfo         1.2.2   2021-12-06 [1] CRAN (R 4.3.2)\n#&gt;  sf                * 1.0-15  2023-12-18 [1] CRAN (R 4.3.2)\n#&gt;  shiny               1.8.0   2023-11-17 [1] CRAN (R 4.3.2)\n#&gt;  sp                  2.1-3   2024-01-30 [1] CRAN (R 4.3.2)\n#&gt;  stringi             1.8.3   2023-12-11 [1] CRAN (R 4.3.2)\n#&gt;  stringr           * 1.5.1   2023-11-14 [1] CRAN (R 4.3.2)\n#&gt;  styler            * 1.10.3  2024-04-07 [1] CRAN (R 4.3.3)\n#&gt;  svglite             2.1.3   2023-12-08 [1] CRAN (R 4.3.2)\n#&gt;  systemfonts         1.0.5   2023-10-09 [1] CRAN (R 4.3.2)\n#&gt;  terra               1.7-71  2024-01-31 [1] CRAN (R 4.3.2)\n#&gt;  tibble            * 3.2.1   2023-03-20 [1] CRAN (R 4.3.2)\n#&gt;  tidyr             * 1.3.1   2024-01-24 [1] CRAN (R 4.3.2)\n#&gt;  tidyselect          1.2.1   2024-03-11 [1] CRAN (R 4.3.3)\n#&gt;  tidyverse         * 2.0.0   2023-02-22 [1] CRAN (R 4.3.2)\n#&gt;  timechange          0.3.0   2024-01-18 [1] CRAN (R 4.3.2)\n#&gt;  tweenr              2.0.3   2024-02-26 [1] CRAN (R 4.3.3)\n#&gt;  tzdb                0.4.0   2023-05-12 [1] CRAN (R 4.3.2)\n#&gt;  units               0.8-5   2023-11-28 [1] CRAN (R 4.3.2)\n#&gt;  urlchecker          1.0.1   2021-11-30 [1] CRAN (R 4.3.2)\n#&gt;  usethis             2.2.3   2024-02-19 [1] CRAN (R 4.3.2)\n#&gt;  utf8                1.2.4   2023-10-22 [1] CRAN (R 4.3.2)\n#&gt;  uuid                1.2-0   2024-01-14 [1] CRAN (R 4.3.2)\n#&gt;  vctrs               0.6.5   2023-12-01 [1] CRAN (R 4.3.2)\n#&gt;  viridisLite         0.4.2   2023-05-02 [1] CRAN (R 4.3.2)\n#&gt;  withr               3.0.0   2024-01-16 [1] CRAN (R 4.3.2)\n#&gt;  xfun                0.44    2024-05-15 [1] CRAN (R 4.3.3)\n#&gt;  xml2                1.3.6   2023-12-04 [1] CRAN (R 4.3.2)\n#&gt;  xtable              1.8-4   2019-04-21 [1] CRAN (R 4.3.2)\n#&gt;  yaml                2.3.8   2023-12-11 [1] CRAN (R 4.3.2)\n#&gt; \n#&gt;  [1] C:/Users/usuario/AppData/Local/R/win-library/4.3\n#&gt;  [2] C:/Program Files/R/R-4.3.2/library\n#&gt; \n#&gt; ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "dataexploration.html",
    "href": "dataexploration.html",
    "title": "Data exploration",
    "section": "",
    "text": "The natural world is complex full of intricate interactions. Understanding this complexity is vital for conservation efforts. Technology is providing us with powerful tools to gather data. Among the most popular and effective are camera traps – silent sentinels capturing candid moments of wildlife, day and night.\nBut collecting data is only the first step. Imagine a vast library filled with millions of books, uncatalogued and unread. That’s what raw camera trap data can be without proper exploration. Data exploration is the process of sifting through, visualizing, and understanding your data before diving into complex analyses. And when it comes to biodiversity and camera trap projects, it’s not just important – it’s absolutely critical.\nHere’s why:\n\n\nThink of data exploration as shining a spotlight into the dark corners of your dataset. Before you even formulate a hypothesis, exploring your data can reveal surprising patterns, trends, and anomalies you might otherwise miss.\n\nSpecies Activity Patterns: When are certain animals most active? Are they nocturnal, diurnal, or crepuscular? Exploring temporal data can show peaks and troughs in activity, informing our understanding of their ecology and potential human-wildlife conflict.\nSpatial Distribution: Where are different species congregating? Are there areas they avoid? Visualizing spatial data can highlight critical habitats, movement corridors, or barriers.\nInter-species Relationships: Do certain species appear together or avoid each other? Preliminary exploration can hint at predator-prey dynamics or competitive exclusion.\n\n\n\n\nNo dataset is perfect. Misidentifications, incorrect timestamps, camera malfunctions or excel dates formats can all introduce errors. Data exploration acts as your first line of defense against these inaccuracies.\n\nSpotting Outliers: An unusually high number of detections for a particular species in one location, or a sudden drop-off, could indicate a data entry error or a camera malfunction.\nChecking Data Integrity: Visualizing distributions of variables can quickly highlight impossible values (e.g., a camera trap recording an animal at a negative temperature) or inconsistencies. Catching these early saves immense time and ensures the validity of your subsequent analyses.\n\n\n\n\nEffective research begins with well-formed questions. Data exploration helps you refine existing hypotheses and generate new, more targeted ones.\n\nIf your exploration shows a strong correlation between a specific habitat type and a rare species, you might formulate a hypothesis about habitat preference.\nDiscovering an unexpected species in an area could lead to new questions about range expansion or previously unrecorded populations.\n\n\n\n\nUnderstanding the nuances of your current data can significantly improve future data collection efforts.\n\nOptimizing Camera Placement: If exploration reveals certain areas consistently yield more valuable data, you can adjust your camera trap placement in subsequent deployments.\nRefining Survey Timings: If your data shows that a target species is primarily active during a specific short window, you might focus your efforts during those times.\nIdentifying Data Gaps: Exploration can highlight areas or time periods where you have insufficient data, prompting you to adjust your sampling strategy.\n\n\n\n\nVisualizations born from data exploration and are a powerful tool for communicating your findings to a wider audience – stakeholders, policymakers, or the general public.\n\nEngaging Infographics: Simple bar charts showing species richness or heat maps illustrating animal density can be far more impactful than raw numbers.\nHighlighting Key Insights: Visualizing your data allows you to tell a compelling story about the wildlife you’re studying and the conservation challenges they face."
  },
  {
    "objectID": "dataexploration.html#why-data-exploration-is-crucial-for-biodiversity-and-camera-trap-projects",
    "href": "dataexploration.html#why-data-exploration-is-crucial-for-biodiversity-and-camera-trap-projects",
    "title": "Data exploration",
    "section": "",
    "text": "The natural world is complex full of intricate interactions. Understanding this complexity is vital for conservation efforts. Technology is providing us with powerful tools to gather data. Among the most popular and effective are camera traps – silent sentinels capturing candid moments of wildlife, day and night.\nBut collecting data is only the first step. Imagine a vast library filled with millions of books, uncatalogued and unread. That’s what raw camera trap data can be without proper exploration. Data exploration is the process of sifting through, visualizing, and understanding your data before diving into complex analyses. And when it comes to biodiversity and camera trap projects, it’s not just important – it’s absolutely critical.\nHere’s why:\n\n\nThink of data exploration as shining a spotlight into the dark corners of your dataset. Before you even formulate a hypothesis, exploring your data can reveal surprising patterns, trends, and anomalies you might otherwise miss.\n\nSpecies Activity Patterns: When are certain animals most active? Are they nocturnal, diurnal, or crepuscular? Exploring temporal data can show peaks and troughs in activity, informing our understanding of their ecology and potential human-wildlife conflict.\nSpatial Distribution: Where are different species congregating? Are there areas they avoid? Visualizing spatial data can highlight critical habitats, movement corridors, or barriers.\nInter-species Relationships: Do certain species appear together or avoid each other? Preliminary exploration can hint at predator-prey dynamics or competitive exclusion.\n\n\n\n\nNo dataset is perfect. Misidentifications, incorrect timestamps, camera malfunctions or excel dates formats can all introduce errors. Data exploration acts as your first line of defense against these inaccuracies.\n\nSpotting Outliers: An unusually high number of detections for a particular species in one location, or a sudden drop-off, could indicate a data entry error or a camera malfunction.\nChecking Data Integrity: Visualizing distributions of variables can quickly highlight impossible values (e.g., a camera trap recording an animal at a negative temperature) or inconsistencies. Catching these early saves immense time and ensures the validity of your subsequent analyses.\n\n\n\n\nEffective research begins with well-formed questions. Data exploration helps you refine existing hypotheses and generate new, more targeted ones.\n\nIf your exploration shows a strong correlation between a specific habitat type and a rare species, you might formulate a hypothesis about habitat preference.\nDiscovering an unexpected species in an area could lead to new questions about range expansion or previously unrecorded populations.\n\n\n\n\nUnderstanding the nuances of your current data can significantly improve future data collection efforts.\n\nOptimizing Camera Placement: If exploration reveals certain areas consistently yield more valuable data, you can adjust your camera trap placement in subsequent deployments.\nRefining Survey Timings: If your data shows that a target species is primarily active during a specific short window, you might focus your efforts during those times.\nIdentifying Data Gaps: Exploration can highlight areas or time periods where you have insufficient data, prompting you to adjust your sampling strategy.\n\n\n\n\nVisualizations born from data exploration and are a powerful tool for communicating your findings to a wider audience – stakeholders, policymakers, or the general public.\n\nEngaging Infographics: Simple bar charts showing species richness or heat maps illustrating animal density can be far more impactful than raw numbers.\nHighlighting Key Insights: Visualizing your data allows you to tell a compelling story about the wildlife you’re studying and the conservation challenges they face."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi, my name is Diego Lizcano. As a wildlife ecologist, the R statistical computing language is an important part of my daily workflow. I mainly use R for data analysis, modelling, data manipulation and reporting."
  },
  {
    "objectID": "about.html#current-research",
    "href": "about.html#current-research",
    "title": "About",
    "section": "Current research",
    "text": "Current research\nI am currently working as a data annalist for WCS Andes-Amazon-Orinoco Region\nSome research I am currently working on:\n\nJaguar detection and occupancy modeling\nWCS Strongholds analysis\n\nI am always looking for new collaborations. Do not hesitate to contact me!"
  },
  {
    "objectID": "about.html#scientific-interests-no-specific-order",
    "href": "about.html#scientific-interests-no-specific-order",
    "title": "About",
    "section": "Scientific interests (no specific order)",
    "text": "Scientific interests (no specific order)\n\nMammal ecology\nCamera trap data analysis\nAcoustics\nEcological modeling"
  },
  {
    "objectID": "biodiversity.html",
    "href": "biodiversity.html",
    "title": "Biodiversity",
    "section": "",
    "text": "In the vast, wild places of our planet, a quiet revolution is happening. From the dense rainforests of the Amazon to the remote mountain ranges of Asia, biologist are deploying a simple and powerful tool that is changing the way we see and protect wildlife: the camera trap.\nThese are not average cameras. They are activated by motion and heat, and are designed to be left in the field for weeks or even months, capturing candid, undisturbed moments of animal life. Without a human in sight, these silent witnesses provide a priceless window into the secret world of biodiversity.\nHere’s why camera traps have become such a critical tool for conservation:\n\n\nMany of the world’s most vulnerable species are also the most elusive. Nocturnal hunters, shy forest dwellers, and rare, solitary animals often go undetected by traditional survey methods. Camera traps excel at capturing these “ghosts” of the animal kingdom, providing irrefutable evidence of their presence. This has led to remarkable discoveries, including the first-ever photographs of species thought to be extinct.\n\n\n\nBeyond just finding a single animal, a network of camera traps can paint a comprehensive picture of an entire ecosystem. By analyzing the data: how many different species are present, their activity patterns, and their interactions, scientists can assess the health of a habitat. A high diversity of species, including top predators and preys, is a strong indicator of a thriving Ecosystem.\n\n\n\nCamera trap data is a goldmine of information. It helps conservationists answer key questions such as:\n\nWhere are animals moving? This helps identify crucial wildlife corridors that need to be protected.\nWhat is a species’ population size? This is essential for monitoring endangered populations and evaluating the success of conservation efforts.\nHow are animals interacting with their environment and each other? This provides insight into predator-prey dynamics and competition for resources.\n\nThis information is not just interesting—it’s the foundation for effective, science and data-driven conservation strategies.\n\n\n\nFinally, camera traps serve as a powerful tool for public outreach. The captivating images and videos of a mother Jaguar with her cubs, a majestic tiger, a tapir and baby can be shared on social media, presented in documentaries, and in educational programs. They help people feel a personal connection to wildlife, inspiring a sense of wonder and urgency to protect these magnificent creatures.\nIn a world facing a global biodiversity crisis, camera traps offer hope. They provide us with the evidence, insights, and inspiration we need to make informed decisions and ensure that the planet’s incredible wildlife will thrive for generations to come."
  },
  {
    "objectID": "biodiversity.html#how-camera-traps-are-revolutionizing-biodiversity-conservation",
    "href": "biodiversity.html#how-camera-traps-are-revolutionizing-biodiversity-conservation",
    "title": "Biodiversity",
    "section": "",
    "text": "In the vast, wild places of our planet, a quiet revolution is happening. From the dense rainforests of the Amazon to the remote mountain ranges of Asia, biologist are deploying a simple and powerful tool that is changing the way we see and protect wildlife: the camera trap.\nThese are not average cameras. They are activated by motion and heat, and are designed to be left in the field for weeks or even months, capturing candid, undisturbed moments of animal life. Without a human in sight, these silent witnesses provide a priceless window into the secret world of biodiversity.\nHere’s why camera traps have become such a critical tool for conservation:\n\n\nMany of the world’s most vulnerable species are also the most elusive. Nocturnal hunters, shy forest dwellers, and rare, solitary animals often go undetected by traditional survey methods. Camera traps excel at capturing these “ghosts” of the animal kingdom, providing irrefutable evidence of their presence. This has led to remarkable discoveries, including the first-ever photographs of species thought to be extinct.\n\n\n\nBeyond just finding a single animal, a network of camera traps can paint a comprehensive picture of an entire ecosystem. By analyzing the data: how many different species are present, their activity patterns, and their interactions, scientists can assess the health of a habitat. A high diversity of species, including top predators and preys, is a strong indicator of a thriving Ecosystem.\n\n\n\nCamera trap data is a goldmine of information. It helps conservationists answer key questions such as:\n\nWhere are animals moving? This helps identify crucial wildlife corridors that need to be protected.\nWhat is a species’ population size? This is essential for monitoring endangered populations and evaluating the success of conservation efforts.\nHow are animals interacting with their environment and each other? This provides insight into predator-prey dynamics and competition for resources.\n\nThis information is not just interesting—it’s the foundation for effective, science and data-driven conservation strategies.\n\n\n\nFinally, camera traps serve as a powerful tool for public outreach. The captivating images and videos of a mother Jaguar with her cubs, a majestic tiger, a tapir and baby can be shared on social media, presented in documentaries, and in educational programs. They help people feel a personal connection to wildlife, inspiring a sense of wonder and urgency to protect these magnificent creatures.\nIn a world facing a global biodiversity crisis, camera traps offer hope. They provide us with the evidence, insights, and inspiration we need to make informed decisions and ensure that the planet’s incredible wildlife will thrive for generations to come."
  },
  {
    "objectID": "biodiversity.html#my-contribution",
    "href": "biodiversity.html#my-contribution",
    "title": "Biodiversity",
    "section": "My Contribution",
    "text": "My Contribution\n\nEarly Works\n\n\n\n\n\n\n\n\n\n\n\nMy experience with camera traps dates back to the very first models—those that still relied on film and offered only 36 exposures. We’ve come a long way since then!\nDespite the technological limitations, those early cameras were crucial. They allowed us to capture the first photographic records of the elusive mountain tapir (Tapirus pinchaque) and, using those images, we were able to describe their activity patterns. This pioneering work was published in the following article:\n\n\n\nMountain Tapir picture\n\n\nLizcano DJ, and Cavelier J. 2000. Daily and seasonal activity of the mountain tapir (Tapirus pinchaque) in the Central Andes of Colombia. Journal of Zoology. 252(4):429-435. doi:10.1111/j.1469-7998.2000.tb01225.x\n\n\n\n.\nA decade later, I had the opportunity to collaborate with the Tropical Ecology and Assessment Network (TEAM), utilizing data collected by Johana Hurtado in Costa Rica. This partnership resulted in the publication of an amazing work:\n\n\n\nOccupancy map\n\n\nAhumada JA, Hurtado J, Lizcano D. 2013. Monitoring the Status and Trends of Tropical Forest Terrestrial Vertebrate Communities from Camera Trap Data: A Tool for Conservation. PLoS ONE 8(9): e73707. doi:10.1371/journal.pone.0073707\n\n\n\n\n\nMore Recently\nMore recently, I have focused my efforts on promoting the use of camera traps and their analytical methods within the Spanish-speaking community.\nAndrade-Ponce G, Cepeda-Duque JC, Mandujano S, Velásquez-C KL, Gómez-Valencia B, y Lizcano DJ. 2021. Modelos De ocupación Para Datos De cámaras Trampa. Mammalogy Notes 7 (1), 200. doi:10.47603/mano.v7n1.200\n\n\n\n.\nLizcano DJ. 2018. Trampas cámara Como Herramienta Para Estudiar Mamíferos Silvestres. Mammalogy Notes 5 (1-2), 31-35. doi:10.47603/manovol5n1.31-35\n\n\n\n."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Camera Trap Blog",
    "section": "",
    "text": "Spatial, single-species occupancy model\n\n\n\nR\n\noccupancy\n\nspOccupancy\n\nspatial\n\n\n\nThe package spOccupancy accommodate spatial autocorrelation efficiently in a workflow completely in R (no Bayesian programming languages necessary)\n\n\n\nDiego J. Lizcano, José F. González-Maya\n\n\nJun 1, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nEsfuerzo de muestreo y RAI en Fototrampeo\n\n\n\nR\n\nfototrampeo\n\ncurso\n\nIAR\n\n\n\nParte del Curso Introducción al Fototrampeo\n\n\n\nDiego J. Lizcano, Lain E. Pardo, Angélica Diaz-Pulido\n\n\nDec 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nSingle Season Occupancy Model\n\n\n\nR\n\noccupancy\n\nubms\n\nunmarked\n\n\n\nFits the single season occupancy model of MacKenzie et al (2002) using camera trap data, unmarked and ubms\n\n\n\nDiego J. Lizcano\n\n\nJul 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n“Stacked” Models\n\n\n\nR\n\noccupancy\n\nubms\n\nunmarked\n\n\n\nSuppose you have a dataset of repeated detections/non detections or counts that are collected over several years, but do not want to fit a dynamic model.\n\n\n\nDiego J. Lizcano, José F. González-Maya\n\n\nJul 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nA multi-species (species interactions) occupancy model\n\n\n\nR\n\noccupancy\n\ntapir\n\n\n\nA mountain tapir, puma and andean bear interacting model\n\n\n\nDiego J. Lizcano\n\n\nJul 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpecies diversity\n\n\n\nR\n\ndiversity\n\naccumulation\n\neffort\n\n\n\nusing packages vegan and iNext to analyze diversity on camera trap data\n\n\n\nDiego J. Lizcano\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nRiqueza de especies\n\n\n\nR\n\ndiversity\n\naccumulation\n\neffort\n\n\n\nUso de los paquetes vegan y iNext para analizar la diversidad con datos de fototrampeo\n\n\n\nDiego J. Lizcano, Camilo Fernández-Rodríguez, Katherine Pérez-Gómez\n\n\nJun 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nMultispecies occupancy model\n\n\n\nR\n\noccupancy\n\nJAGS\n\ncamtrapR\n\n\n\nMultispecies occupancy models combines information from multiple species to estimate both individual and community-level responses to environmental variables\n\n\n\nDiego J. Lizcano\n\n\nJun 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nA calendar to visualize camera trap data\n\n\n\nR\n\ncalendar\n\nmap\n\n\n\nUsing several camera trap data campaingns from Galictis Biodiversidad\n\n\n\nDiego J. Lizcano\n\n\nJun 15, 2024\n\n\n\n\n\n\nNo matching items\n Back to top"
  },
  {
    "objectID": "posts/2024-06-20-multispecies-occupancy/index.html",
    "href": "posts/2024-06-20-multispecies-occupancy/index.html",
    "title": "Multispecies occupancy model",
    "section": "",
    "text": "CamtrapR is making very easy to make Multispecies occupancy models from camera trap data. Here one example."
  },
  {
    "objectID": "posts/2024-06-20-multispecies-occupancy/index.html#using-camtrapr",
    "href": "posts/2024-06-20-multispecies-occupancy/index.html#using-camtrapr",
    "title": "Multispecies occupancy model",
    "section": "",
    "text": "CamtrapR is making very easy to make Multispecies occupancy models from camera trap data. Here one example."
  },
  {
    "objectID": "posts/2024-06-20-multispecies-occupancy/index.html#load-packages",
    "href": "posts/2024-06-20-multispecies-occupancy/index.html#load-packages",
    "title": "Multispecies occupancy model",
    "section": "Load packages",
    "text": "Load packages\nFirst we load some packages\n\nCode\nlibrary(grateful) # Facilitate Citation of R Packages\nlibrary(patchwork) # The Composer of Plots\nlibrary(readxl) # Read Excel Files\nlibrary(sf) # Simple Features for R\nlibrary(mapview) # Interactive Viewing of Spatial Data in R\nlibrary(terra) # Spatial Data Analysis\nlibrary(elevatr) # Access Elevation Data from Various APIs\n\nlibrary(camtrapR) # Camera Trap Data Management and Preparation of Occupancy and Spatial Capture-Recapture Analyses \nlibrary(rjags) # Bayesian Graphical Models using MCMC \nlibrary(nimble) # MCMC, Particle Filtering, and Programmable Hierarchical Modeling \n\nlibrary(bayesplot) # Plotting for Bayesian Models # Plotting for Bayesian Models \nlibrary(SpadeR) # Species-Richness Prediction and Diversity Estimation with R \nlibrary(tictoc) # Functions for Timing R Scripts, as Well as Implementations of \"Stack\" and \"StackList\" Structures \nlibrary(beepr) # Easily Play Notification Sounds on any Platform \nlibrary(snowfall) # Easier Cluster Computing (Based on 'snow')\nlibrary(bayesplot) # Plotting for Bayesian Models # Plotting for Bayesian Models \n\nlibrary(kableExtra) # Construct Complex Table with 'kable' and Pipe Syntax\nlibrary(tidyverse) # Easily Install and Load the 'Tidyverse'"
  },
  {
    "objectID": "posts/2024-06-20-multispecies-occupancy/index.html#load-data",
    "href": "posts/2024-06-20-multispecies-occupancy/index.html#load-data",
    "title": "Multispecies occupancy model",
    "section": "Load data",
    "text": "Load data\nThe data set is i a excel file so we use read_excel function to load it.\n\nCode\ndatos &lt;- read_excel(\"C:/CodigoR/CameraTrapCesar/data/CT_Cesar.xlsx\")"
  },
  {
    "objectID": "posts/2024-06-20-multispecies-occupancy/index.html#selecting-just-ct_becerril-2021",
    "href": "posts/2024-06-20-multispecies-occupancy/index.html#selecting-just-ct_becerril-2021",
    "title": "Multispecies occupancy model",
    "section": "Selecting Just CT_Becerril 2021",
    "text": "Selecting Just CT_Becerril 2021\nTo this example I selected just one place one year, Becerril 2021. Sometimes we need to make unique codes per camera and cameraOperation table.\n\nCode# make a new column Station\n# datos_PCF &lt;- datos |&gt; dplyr::filter(Proyecto==\"CT_LaPaz_Manaure\") |&gt; unite (\"Station\", ProyectoEtapa:Salida:CT, sep = \"-\")\n\n# fix dates\ndatos$Start &lt;- as.Date(datos$Start, \"%d/%m/%Y\")\ndatos$End &lt;- as.Date(datos$End, \"%d/%m/%Y\")\ndatos$eventDate &lt;- as.Date(datos$eventDate, \"%d/%m/%Y\")\ndatos$eventDateTime &lt;- ymd_hms(paste(datos$eventDate, \" \",\n                              datos$eventTime, \":00\", sep=\"\"))\n\n# filter Becerril\ndatos_PCF &lt;- datos |&gt; dplyr::filter(ProyectoEtapa==\"CT_Becerril\") |&gt; mutate (Station=IdGeo)\n\n# filter 2021 and make uniques\nCToperation  &lt;- datos_PCF |&gt; filter(Year==2021) |&gt; group_by(Station) |&gt; \n                           mutate(minStart=min(Start), maxEnd=max(End)) |&gt; distinct(Longitude, Latitude, minStart, maxEnd, Year) |&gt; ungroup()"
  },
  {
    "objectID": "posts/2024-06-20-multispecies-occupancy/index.html#generating-cameraoperation-and-making-detection-histories-for-all-the-species.",
    "href": "posts/2024-06-20-multispecies-occupancy/index.html#generating-cameraoperation-and-making-detection-histories-for-all-the-species.",
    "title": "Multispecies occupancy model",
    "section": "Generating cameraOperation and making detection histories for all the species.",
    "text": "Generating cameraOperation and making detection histories for all the species.\nThe package CamtrapR has the function ‘cameraOperation’ which makes a table of cameras (stations) and dates (setup, puck-up), this table is key to generate the detection histories using the function ‘detectionHistory’ in the next step.\n\nCode# Generamos la matríz de operación de las cámaras\n\ncamop &lt;- cameraOperation(CTtable= CToperation, # Tabla de operación\n                         stationCol= \"Station\", # Columna que define la estación\n                         setupCol= \"minStart\", #Columna fecha de colocación\n                         retrievalCol= \"maxEnd\", #Columna fecha de retiro\n                         #hasProblems= T, # Hubo fallos de cámaras\n                         dateFormat= \"%Y-%m-%d\") #, # Formato de las fechas\n                         #cameraCol=\"CT\")\n                         # sessionCol= \"Year\")\n\n# Generar las historias de detección ---------------------------------------\n## remove plroblem species\nind &lt;- which(datos_PCF$Species==\"Marmosa sp.\")\ndatos_PCF &lt;- datos_PCF[-ind,]\n\nDetHist_list &lt;- lapply(unique(datos_PCF$Species), FUN = function(x) {\n  detectionHistory(\n    recordTable         = datos_PCF, # Tabla de registros\n    camOp                = camop, # Matriz de operación de cámaras\n    stationCol           = \"Station\",\n    speciesCol           = \"Species\",\n    recordDateTimeCol    = \"eventDateTime\",\n    recordDateTimeFormat  = \"%Y-%m-%d\",\n    species              = x,     # la función reemplaza x por cada una de las especies\n    occasionLength       = 10, # Colapso de las historias a 10 ías\n    day1                 = \"station\", #inicie en la fecha de cada survey\n    datesAsOccasionNames = FALSE,\n    includeEffort        = TRUE,\n    scaleEffort          = TRUE,\n    #unmarkedMultFrameInput=TRUE\n    timeZone             = \"America/Bogota\" \n    )\n  }\n)\n\n# names\nnames(DetHist_list) &lt;- unique(datos_PCF$Species)\n\n# Finalmente creamos una lista nueva donde estén solo las historias de detección\nylist &lt;- lapply(DetHist_list, FUN = function(x) x$detection_history)"
  },
  {
    "objectID": "posts/2024-06-20-multispecies-occupancy/index.html#preparing-spatial-covariates",
    "href": "posts/2024-06-20-multispecies-occupancy/index.html#preparing-spatial-covariates",
    "title": "Multispecies occupancy model",
    "section": "Preparing spatial covariates",
    "text": "Preparing spatial covariates\nmake sf object, get elevation and derive terrain (slope and roughness).\nWe use the lat and long to make a sf object with the camera locations.\n\nCode\n# make sf object\nprojlatlon &lt;- \"+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0\"\n\ndatos_PCF_sf &lt;-  st_as_sf(x = CToperation,\n                         coords = c(\"Longitude\", \n                                    \"Latitude\"),\n                         crs = projlatlon)\n\n# covariates\nelev &lt;- rast(get_elev_raster(datos_PCF_sf, z=14)) # get raster map\nslope &lt;- terrain(elev, v=\"slope\", neighbors=8, unit=\"degrees\")  \n# also slope, aspect, TPI, TRI, TRIriley, TRIrmsd, roughness, flowdir \nrough &lt;- terrain(elev, v=\"roughness\", neighbors=8, unit=\"degrees\")  \n# landcover &lt;- rast(\"C:/CodigoR/WCS-CameraTrap/raster/latlon/LandCover_Type_Yearly_500m_v61/LC1/MCD12Q1_LC1_2021_001.tif\") \n\ncos_rast &lt;- c(elev,slope, rough) # make a stack\n# rename stack\nnames(cos_rast) &lt;- c(\"elev\", \"slope\", \"rough\")\n\nplot(cos_rast)\n\n\n\n\n\n\nCode\nmapview(elev) + mapview(datos_PCF_sf)\n\n\n\n\n\nExtract values from the rasters\nWe use the camera locations to extract the raster (elevations, slope and roughness) information.\n\nCode\n\n# extract\ncovs &lt;- terra::extract(cos_rast, datos_PCF_sf)\n# landcov &lt;- terra::extract(landcover, datos_PCF_sf)"
  },
  {
    "objectID": "posts/2024-06-20-multispecies-occupancy/index.html#multispecies-occupancy-model",
    "href": "posts/2024-06-20-multispecies-occupancy/index.html#multispecies-occupancy-model",
    "title": "Multispecies occupancy model",
    "section": "Multispecies occupancy model",
    "text": "Multispecies occupancy model\nPreparing the model\nNow we have all ready to make our model. We put the data of the species, and the covariates in a list.\n\nCode\n# check consistancy equal mumner of spatial covariates and rows in data\n# identical(nrow(ylist[[1]]), nrow(covars)) \n\n# Base de datos para los análisis -----------------------------------------\n\ndata_list &lt;- list(ylist    = ylist, # Historias de detección\n                  siteCovs = covs[,2:4], #covars, # Covariables de sitio\n                  obsCovs  = list(effort = DetHist_list[[1]]$effort))  # agregamos el esfuerzo de muestreo como covariable de observación\n\n# 3. 1 Modelo multi-especie  -----------------------------------------\n\n# Se creará un txt temporal donde estarán las especificaciones del modelo en enfoque Bayesiano\nmodelfile &lt;- (fileext = \"modoccu.txt\")\n\n# Usaremos la función ` communityModel`\n\n\nGenerating the model\nWe use the function ‘communityModel’ to setup our model, selecting which covariates is for detection or occupancy and if it is fixed or random effect.\n\nCode\n\n# Generemos el modelo\ncomu_model &lt;- communityModel(data_list, # la lista de datos\n                             occuCovs = list(ranef=c(\"rough\", \"elev\")), # ranef La covariables de sitio\n                             detCovsObservation = list(fixed = \"effort\"), #Covariables de observación\n                             intercepts = list(det = \"ranef\", occu = \"ranef\"),\n                             augmentation = c(full = 30),# Número aumentado de especies\n                             modelFile = \"modelfile\")\n\nsummary(comu_model)\n#&gt; commOccu object for community occupancy model (in JAGS)\n#&gt; \n#&gt; 30 species,  23 stations,  39 occasions\n#&gt; 530 occasions with effort\n#&gt; Number of detections (by species): 0 - 164 \n#&gt; \n#&gt; Available site covariates:\n#&gt;  elev, slope, rough \n#&gt; \n#&gt; Used site covariates:\n#&gt;  elev, rough \n#&gt; \n#&gt; Available site-occasion covariates:\n#&gt;  effort\n\n\nRunning the model\n\nGo for a coffe and enjoy while you wait for the signal beep.\n\n\nCode# Running the model\n\nfit.commu &lt;- fit(comu_model,\n                 n.iter = 1200,\n                 n.burnin = 200,\n                 thin = 2,\n                 chains = 3,\n                 cores = 3,\n                 quiet = T\n);beep(sound = 4)\n\n# save the results to not run again\nsave(fit.commu, file=\"C:/CodigoR/CameraTrapCesar/posts/2024-06-20-multispecies-occupancy/result/DR_result.R\") # guardamos los resultados para no correr de nuevo\n\n\nSee the results\nAs a table\n\nCode\n# Resultados --------------------------------------------------------------\n\n# Extraemos lo tabla de valores estimados\nmodresult &lt;- as.data.frame(summary(fit.commu)[[\"statistics\"]])\n# View(modresult)\nDT::datatable(round(summary(fit.commu)$statistics, 3))\n\n\n\n\n\nAs graphs\n\nCode# Gráficos de predicción y de coeficientes\n\n# Otra gran ventaja de CamtrapR es que permite gráficar de manera muy sencilla la predicción posterior del modelo. Veamos que pasa con la ocupación de cada especie\n\nplot_effects(comu_model,\n              fit.commu,\n              submodel = \"det\")\n#&gt; $effort\n\n\n\n\n\n\nCode\nplot_coef(comu_model,\n           fit.commu,\n           submodel = \"state\",\n           combine = T)\n\n\n\n\n\n\nCode\nplot_effects(comu_model, # El modelo\n             fit.commu, # El objeto ajustado\n             submodel = \"state\",\n             response = \"occupancy\") # el parámetro de interés\n#&gt; $rough\n\n\n\n\n\n\n#&gt; \n#&gt; $elev\n\n\n\n\n\n\nCode\n# Ahora con los coeficientes estimados\n\n# plot_coef(comu_model,\n#           fit.commu,\n#           submodel = \"state\")\n\n\nSee the species richness\nNotice the estimated species richness, Mean, SD, and SE is: 29.0866667, 1.1764686, 0.0303763, 0.0529884\n\nCode\n# Valor de Ntotal, es decir del número de especies estimado\n(riqueza_est &lt;- modresult[\"Ntotal\",])\n#&gt;            Mean       SD   Naive SE Time-series SE\n#&gt; Ntotal 29.08667 1.176469 0.03037629     0.05298842\n\n# Veamos el gráfico de la distribución posterior\nmcmc_areas(fit.commu, # objeto jags\n           pars= \"Ntotal\", # parámetro de interés\n           point_est = \"mean\",\n           prob = 0.95) # intervalos de credibilidad\n\n\n\n\n\n\nCode\n\n# La estimación no se ve muy bien, hay que verificar los trace plots\n\nmcmc_trace(fit.commu, pars = \"Ntotal\")\n\n\n\n\n\n\nCode\n# Debería verse como un cesped, muy probablemente necesitamos muchas mas iteraciones para este modelo\n\ngd &lt;- as.data.frame(gelman.diag(fit.commu,  multivariate = FALSE)[[1]])\nDT::datatable(gd[\"Ntotal\",])\n\n\n\n\nCode\n#La prueba de Gelman-Rubin debe ser ~1 para considerar que hay buena convergencia. Aunque tenemos un valor bueno para Ntotal, hay varios valores de omega con NA, eso puede estar causando los problemas.\n\n\nComparing species richness with Chao\n\nCode\n# Comparando con métodos clásicos -----------------------------------------\n\n\n# Formatear los datos a un vector de frecuencia\ninci_Chao &lt;- ylist %&gt;%  # historias de captura\n  map(~rowSums(.,na.rm = T)) %&gt;% # sumo las detecciones en cada sitio\n  reduce(cbind) %&gt;% # unimos las listas\n  t() %&gt;% # trasponer la tabla\n  as_tibble() %&gt;% #formato tibble\n  mutate_if(is.numeric,~(.&gt;=1)*1) %&gt;%  #como es incidencia, formateo a 1 y 0\n  rowSums() %&gt;%  # ahora si la suma de las incidencias en cada sitio\n  as_tibble() %&gt;% \n add_row(value= dim(CToperation)[1], .before = 1) %&gt;%  # el formato requiere que el primer valor sea el número de sitios\n  as.matrix() # Requiere formato de matriz\n\n\n\n# Calcular la riqueza con estimadores no paramétricos\nchao_sp &lt;- ChaoSpecies(inci_Chao, datatype = \"incidence_freq\")\n\nNIChao &lt;- chao_sp$Species_table[4,c(1,3,4)] # Extraer valores de IChao\n\nNocu&lt;- mcmc_intervals(fit.commu, pars = \"Ntotal\", prob = 0.95,prob_outer = 0.99, point_est = \"mean\")[[1]] %&gt;%  # Extraer valores del bayes plot\n  select(m,l,h) %&gt;% # Seleccionar columnas\n  rename(\"Estimate\"= m, # Renombrarlas\n         \"95%Lower\"= l,\n         \"95%Upper\"= h)\n\n\n# Unir en un solo dataframe\nNplotdata &lt;- rbind(IChao=NIChao, BayesModel=Nocu) %&gt;% \n  as.data.frame() %&gt;% \n  rownames_to_column(.)\n\n# Gráfico para comparar la riqueza estimada\nplotN &lt;- ggplot(Nplotdata, aes(x=rowname, y= Estimate, col=rowname))+\n  geom_point(aes(shape=rowname),size=3)+\n  geom_errorbar(aes(ymin= `95%Lower`, ymax= `95%Upper`), width=.3, size=1)+\n  labs(x=\"Estimador de riqueza\",y=\"Estimated species number\", title = \"Richness estimation by Bayesian model vs Chao\")+\n  theme_classic()+\n  theme(text=element_text(size = 13), plot.title = element_text(hjust= 0.5), legend.position = \"none\")\n\nplotN\n\n\n\n\n\n\n\nSpatial prediction\nOccupancy\nJust like magic camtrapR allow us to make predictions using a raster object, obtaining maps of richness and occupancy per species.\n\nBe aware if you used a large number in interations for better fit in the Running model part, you can get the Error: cannot locate a vector size 467.8 Gb\n\nHere we are plotting only the first 9 species for space reasons.\n\nCode# species occupancy estimates\npredictions_psi &lt;- camtrapR::predict(object    = comu_model, \n                             mcmc.list = fit.commu,\n                             x         = cos_rast,\n                             type      = \"psi\",\n                             draws     = 1000)\n\n# save the results to not run again\nwriteRaster(predictions_psi[[1]], file=\"C:/CodigoR/CameraTrapCesar/posts/2024-06-20-multispecies-occupancy/result/predictions_psi.tif\", overwrite=TRUE) # guardamos los resultados para no correr de nuevo\n\n\n\n# Plot occupancy\nplot(predictions_psi$mean, zlim = c(0,1), \n       col = hcl.colors(100), \n       maxnl = 9,   # plotting only the first 9 species for space reasons\n       asp = 1)  \n  \n\n\n\n\n\n\n\n\n\n\nSpecies Richness\nNotice this prediction can be also very RAM consuming…\n\nCode# species richness estimates\npredictions_rich &lt;- predict(object   = comu_model, \n                             mcmc.list = fit.commu,\n                             x         = cos_rast,\n                             type      = \"richness\",\n                            draws     = 1000)\n\n# save the results to not run again\nwriteRaster(predictions_rich, file=\"C:/CodigoR/CameraTrapCesar/posts/2024-06-20-multispecies-occupancy/result/predictions_rich.tif\") # guardamos los resultados para no correr de nuevo\n\n\n# plot richness\nplot(predictions_rich, col = hcl.colors(100), asp = 1)\n  \n\n\n\n\n\n\n\n\n\n\nAn additional option to avoid the out of memory issue is to aggregate the pixel size in the raster object before making the prediction.\n\nCodeagregated_raster &lt;- aggregate(old_raster, fact = 10) # aggregate 10 pixels in one"
  },
  {
    "objectID": "posts/2024-06-20-multispecies-occupancy/index.html#package-citation",
    "href": "posts/2024-06-20-multispecies-occupancy/index.html#package-citation",
    "title": "Multispecies occupancy model",
    "section": "Package Citation",
    "text": "Package Citation\n\nCodepkgs &lt;- cite_packages(output = \"paragraph\", out.dir = \".\") #knitr::kable(pkgs)\n#&gt; WARNING: One or more problems were discovered while enumerating dependencies.\n#&gt; \n#&gt; # C:/CodigoR/CameraTrapCesar/posts/2024-06-20-multispecies-occupancy/result/DR_result.R --------\n#&gt; Error: invalid multibyte character in parser (&lt;input&gt;:4:4)\n#&gt; \n#&gt; # C:/CodigoR/CameraTrapCesar/posts/2024-06-20-multispecies-occupancy/result/predictions_psi.R --------\n#&gt; Error: invalid multibyte character in parser (&lt;input&gt;:11:2)\n#&gt; \n#&gt; Please see `?renv::dependencies` for more information.\npkgs\n\nWe used R version 4.3.2 (R Core Team 2023) and the following R packages: bayesplot v. 1.11.1 (Gabry et al. 2019; Gabry and Mahr 2024), beepr v. 1.3 (Bååth 2018), camtrapR v. 2.3.0 (Niedballa et al. 2016), devtools v. 2.4.5 (Wickham et al. 2022), DT v. 0.32 (Xie, Cheng, and Tan 2024), elevatr v. 0.99.0 (Hollister et al. 2023), kableExtra v. 1.4.0 (Zhu 2024), mapview v. 2.11.2 (Appelhans et al. 2023), nimble v. 1.1.0 (de Valpine et al. 2017, 2024b, 2024a), patchwork v. 1.2.0 (Pedersen 2024), quarto v. 1.4 (Allaire and Dervieux 2024), rjags v. 4.15 (Plummer 2023), rmarkdown v. 2.27 (Xie, Allaire, and Grolemund 2018; Xie, Dervieux, and Riederer 2020; Allaire et al. 2024), sf v. 1.0.15 (Pebesma 2018; Pebesma and Bivand 2023), snowfall v. 1.84.6.3 (Knaus 2023), SpadeR v. 0.1.1 (Chao et al. 2016), styler v. 1.10.3 (Müller and Walthert 2024), terra v. 1.7.71 (Hijmans 2024), tictoc v. 1.2.1 (Izrailev 2024), tidyverse v. 2.0.0 (Wickham et al. 2019)."
  },
  {
    "objectID": "posts/2024-06-20-multispecies-occupancy/index.html#sesion-info",
    "href": "posts/2024-06-20-multispecies-occupancy/index.html#sesion-info",
    "title": "Multispecies occupancy model",
    "section": "Sesion info",
    "text": "Sesion info\n\nSession info\n\n#&gt; ─ Session info ───────────────────────────────────────────────────────────────────────────────────────────────────────\n#&gt;  setting  value\n#&gt;  version  R version 4.3.2 (2023-10-31 ucrt)\n#&gt;  os       Windows 10 x64 (build 19042)\n#&gt;  system   x86_64, mingw32\n#&gt;  ui       RTerm\n#&gt;  language (EN)\n#&gt;  collate  Spanish_Colombia.utf8\n#&gt;  ctype    Spanish_Colombia.utf8\n#&gt;  tz       America/Bogota\n#&gt;  date     2024-07-04\n#&gt;  pandoc   3.1.11 @ C:/Program Files/RStudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n#&gt; \n#&gt; ─ Packages ───────────────────────────────────────────────────────────────────────────────────────────────────────────\n#&gt;  ! package           * version    date (UTC) lib source\n#&gt;    abind               1.4-5      2016-07-21 [1] CRAN (R 4.3.1)\n#&gt;    audio               0.1-11     2023-08-18 [1] CRAN (R 4.3.1)\n#&gt;    backports           1.4.1      2021-12-13 [1] CRAN (R 4.3.1)\n#&gt;    base64enc           0.1-3      2015-07-28 [1] CRAN (R 4.3.1)\n#&gt;    bayesplot         * 1.11.1     2024-02-15 [1] CRAN (R 4.3.3)\n#&gt;    beepr             * 1.3        2018-06-04 [1] CRAN (R 4.3.3)\n#&gt;    brew                1.0-10     2023-12-16 [1] CRAN (R 4.3.2)\n#&gt;    bslib               0.6.1      2023-11-28 [1] CRAN (R 4.3.2)\n#&gt;    cachem              1.0.8      2023-05-01 [1] CRAN (R 4.3.2)\n#&gt;    camtrapR          * 2.3.0      2024-02-26 [1] CRAN (R 4.3.3)\n#&gt;    cellranger          1.1.0      2016-07-27 [1] CRAN (R 4.3.2)\n#&gt;    checkmate           2.3.1      2023-12-04 [1] CRAN (R 4.3.2)\n#&gt;    class               7.3-22     2023-05-03 [2] CRAN (R 4.3.2)\n#&gt;    classInt            0.4-10     2023-09-05 [1] CRAN (R 4.3.2)\n#&gt;    cli                 3.6.2      2023-12-11 [1] CRAN (R 4.3.2)\n#&gt;    coda              * 0.19-4.1   2024-01-31 [1] CRAN (R 4.3.2)\n#&gt;    codetools           0.2-19     2023-02-01 [2] CRAN (R 4.3.2)\n#&gt;    colorspace          2.1-0      2023-01-23 [1] CRAN (R 4.3.2)\n#&gt;    crayon              1.5.2      2022-09-29 [1] CRAN (R 4.3.2)\n#&gt;    crosstalk           1.2.1      2023-11-23 [1] CRAN (R 4.3.2)\n#&gt;    curl                5.2.0      2023-12-08 [1] CRAN (R 4.3.2)\n#&gt;    data.table          1.15.0     2024-01-30 [1] CRAN (R 4.3.2)\n#&gt;    DBI                 1.2.2      2024-02-16 [1] CRAN (R 4.3.2)\n#&gt;    devtools            2.4.5      2022-10-11 [1] CRAN (R 4.3.2)\n#&gt;    digest              0.6.34     2024-01-11 [1] CRAN (R 4.3.2)\n#&gt;    distributional      0.4.0      2024-02-07 [1] CRAN (R 4.3.2)\n#&gt;    dplyr             * 1.1.4      2023-11-17 [1] CRAN (R 4.3.2)\n#&gt;    DT                  0.32       2024-02-19 [1] CRAN (R 4.3.3)\n#&gt;    e1071               1.7-14     2023-12-06 [1] CRAN (R 4.3.2)\n#&gt;    elevatr           * 0.99.0     2023-09-12 [1] CRAN (R 4.3.2)\n#&gt;    ellipsis            0.3.2      2021-04-29 [1] CRAN (R 4.3.2)\n#&gt;    evaluate            0.23       2023-11-01 [1] CRAN (R 4.3.2)\n#&gt;    fansi               1.0.6      2023-12-08 [1] CRAN (R 4.3.2)\n#&gt;    farver              2.1.1      2022-07-06 [1] CRAN (R 4.3.2)\n#&gt;    fastmap             1.1.1      2023-02-24 [1] CRAN (R 4.3.2)\n#&gt;    forcats           * 1.0.0      2023-01-29 [1] CRAN (R 4.3.2)\n#&gt;    fs                  1.6.3      2023-07-20 [1] CRAN (R 4.3.2)\n#&gt;    generics            0.1.3      2022-07-05 [1] CRAN (R 4.3.2)\n#&gt;    ggplot2           * 3.5.1      2024-04-23 [1] CRAN (R 4.3.3)\n#&gt;    ggridges            0.5.6      2024-01-23 [1] CRAN (R 4.3.3)\n#&gt;    glue                1.7.0      2024-01-09 [1] CRAN (R 4.3.2)\n#&gt;    grateful          * 0.2.4      2023-10-22 [1] CRAN (R 4.3.3)\n#&gt;    gtable              0.3.4      2023-08-21 [1] CRAN (R 4.3.2)\n#&gt;    hms                 1.1.3      2023-03-21 [1] CRAN (R 4.3.2)\n#&gt;    htmltools           0.5.7      2023-11-03 [1] CRAN (R 4.3.2)\n#&gt;    htmlwidgets         1.6.4      2023-12-06 [1] CRAN (R 4.3.2)\n#&gt;    httpuv              1.6.14     2024-01-26 [1] CRAN (R 4.3.2)\n#&gt;    httr                1.4.7      2023-08-15 [1] CRAN (R 4.3.2)\n#&gt;    igraph              2.0.2      2024-02-17 [1] CRAN (R 4.3.2)\n#&gt;    jquerylib           0.1.4      2021-04-26 [1] CRAN (R 4.3.2)\n#&gt;    jsonlite            1.8.8      2023-12-04 [1] CRAN (R 4.3.2)\n#&gt;    kableExtra        * 1.4.0      2024-01-24 [1] CRAN (R 4.3.3)\n#&gt;    KernSmooth          2.23-22    2023-07-10 [2] CRAN (R 4.3.2)\n#&gt;    knitr               1.46       2024-04-06 [1] CRAN (R 4.3.3)\n#&gt;    labeling            0.4.3      2023-08-29 [1] CRAN (R 4.3.1)\n#&gt;    later               1.3.2      2023-12-06 [1] CRAN (R 4.3.2)\n#&gt;    lattice             0.22-5     2023-10-24 [1] CRAN (R 4.3.2)\n#&gt;    leafem              0.2.3      2023-09-17 [1] CRAN (R 4.3.2)\n#&gt;    leaflet             2.2.1      2023-11-13 [1] CRAN (R 4.3.2)\n#&gt;    leaflet.providers   2.0.0      2023-10-17 [1] CRAN (R 4.3.2)\n#&gt;    leafpop             0.1.0      2021-05-22 [1] CRAN (R 4.3.2)\n#&gt;    lifecycle           1.0.4      2023-11-07 [1] CRAN (R 4.3.2)\n#&gt;    lubridate         * 1.9.3      2023-09-27 [1] CRAN (R 4.3.2)\n#&gt;    lwgeom              0.2-13     2023-05-22 [1] CRAN (R 4.3.2)\n#&gt;    magrittr            2.0.3      2022-03-30 [1] CRAN (R 4.3.2)\n#&gt;    mapview           * 2.11.2     2023-10-13 [1] CRAN (R 4.3.2)\n#&gt;    MASS                7.3-60     2023-05-04 [2] CRAN (R 4.3.2)\n#&gt;    Matrix              1.6-1.1    2023-09-18 [2] CRAN (R 4.3.2)\n#&gt;    memoise             2.0.1      2021-11-26 [1] CRAN (R 4.3.2)\n#&gt;    mgcv                1.9-1      2023-12-21 [1] CRAN (R 4.3.3)\n#&gt;    mime                0.12       2021-09-28 [1] CRAN (R 4.3.1)\n#&gt;    miniUI              0.1.1.1    2018-05-18 [1] CRAN (R 4.3.2)\n#&gt;    munsell             0.5.0      2018-06-12 [1] CRAN (R 4.3.2)\n#&gt;    nimble            * 1.1.0      2024-01-31 [1] CRAN (R 4.3.3)\n#&gt;    nlme                3.1-163    2023-08-09 [2] CRAN (R 4.3.2)\n#&gt;    numDeriv            2016.8-1.1 2019-06-06 [1] CRAN (R 4.3.1)\n#&gt;    patchwork         * 1.2.0      2024-01-08 [1] CRAN (R 4.3.3)\n#&gt;    pillar              1.9.0      2023-03-22 [1] CRAN (R 4.3.2)\n#&gt;    pkgbuild            1.4.4      2024-03-17 [1] CRAN (R 4.3.3)\n#&gt;    pkgconfig           2.0.3      2019-09-22 [1] CRAN (R 4.3.2)\n#&gt;    pkgload             1.3.4      2024-01-16 [1] CRAN (R 4.3.2)\n#&gt;    plyr                1.8.9      2023-10-02 [1] CRAN (R 4.3.2)\n#&gt;    png                 0.1-8      2022-11-29 [1] CRAN (R 4.3.1)\n#&gt;    posterior           1.5.0      2023-10-31 [1] CRAN (R 4.3.2)\n#&gt;    pracma              2.4.4      2023-11-10 [1] CRAN (R 4.3.3)\n#&gt;    prettyunits         1.2.0      2023-09-24 [1] CRAN (R 4.3.2)\n#&gt;    processx            3.8.3      2023-12-10 [1] CRAN (R 4.3.2)\n#&gt;    profvis             0.3.8      2023-05-02 [1] CRAN (R 4.3.2)\n#&gt;    progress            1.2.3      2023-12-06 [1] CRAN (R 4.3.3)\n#&gt;    progressr           0.14.0     2023-08-10 [1] CRAN (R 4.3.2)\n#&gt;    promises            1.2.1      2023-08-10 [1] CRAN (R 4.3.2)\n#&gt;    proxy               0.4-27     2022-06-09 [1] CRAN (R 4.3.2)\n#&gt;    ps                  1.7.6      2024-01-18 [1] CRAN (R 4.3.2)\n#&gt;    purrr             * 1.0.2      2023-08-10 [1] CRAN (R 4.3.2)\n#&gt;    quarto            * 1.4        2024-03-06 [1] CRAN (R 4.3.3)\n#&gt;    R.cache             0.16.0     2022-07-21 [1] CRAN (R 4.3.3)\n#&gt;    R.methodsS3         1.8.2      2022-06-13 [1] CRAN (R 4.3.3)\n#&gt;    R.oo                1.26.0     2024-01-24 [1] CRAN (R 4.3.3)\n#&gt;    R.utils             2.12.3     2023-11-18 [1] CRAN (R 4.3.3)\n#&gt;    R6                  2.5.1      2021-08-19 [1] CRAN (R 4.3.2)\n#&gt;    raster              3.6-26     2023-10-14 [1] CRAN (R 4.3.2)\n#&gt;    RColorBrewer        1.1-3      2022-04-03 [1] CRAN (R 4.3.1)\n#&gt;    Rcpp                1.0.12     2024-01-09 [1] CRAN (R 4.3.2)\n#&gt;    RcppNumerical       0.6-0      2023-09-06 [1] CRAN (R 4.3.3)\n#&gt;  D RcppParallel        5.1.7      2023-02-27 [1] CRAN (R 4.3.2)\n#&gt;    readr             * 2.1.5      2024-01-10 [1] CRAN (R 4.3.2)\n#&gt;    readxl            * 1.4.3      2023-07-06 [1] CRAN (R 4.3.2)\n#&gt;    remotes             2.5.0      2024-03-17 [1] CRAN (R 4.3.3)\n#&gt;    renv                1.0.7      2024-04-11 [1] CRAN (R 4.3.3)\n#&gt;    reshape2            1.4.4      2020-04-09 [1] CRAN (R 4.3.3)\n#&gt;    rjags             * 4-15       2023-11-30 [1] CRAN (R 4.3.3)\n#&gt;    rlang               1.1.3      2024-01-10 [1] CRAN (R 4.3.2)\n#&gt;    rmarkdown           2.27       2024-05-17 [1] CRAN (R 4.3.3)\n#&gt;    rstudioapi          0.16.0     2024-03-24 [1] CRAN (R 4.3.3)\n#&gt;    s2                  1.1.6      2023-12-19 [1] CRAN (R 4.3.2)\n#&gt;    sass                0.4.8      2023-12-06 [1] CRAN (R 4.3.2)\n#&gt;    satellite           1.0.5      2024-02-10 [1] CRAN (R 4.3.2)\n#&gt;    scales              1.3.0      2023-11-28 [1] CRAN (R 4.3.3)\n#&gt;    secr                4.6.6      2024-02-29 [1] CRAN (R 4.3.3)\n#&gt;    sessioninfo         1.2.2      2021-12-06 [1] CRAN (R 4.3.2)\n#&gt;    sf                * 1.0-15     2023-12-18 [1] CRAN (R 4.3.2)\n#&gt;    shiny               1.8.0      2023-11-17 [1] CRAN (R 4.3.2)\n#&gt;    slippymath          0.3.1      2019-06-28 [1] CRAN (R 4.3.2)\n#&gt;    snow              * 0.4-4      2021-10-27 [1] CRAN (R 4.3.2)\n#&gt;    snowfall          * 1.84-6.3   2023-11-26 [1] CRAN (R 4.3.2)\n#&gt;    sp                  2.1-3      2024-01-30 [1] CRAN (R 4.3.2)\n#&gt;    SpadeR            * 0.1.1      2016-09-06 [1] CRAN (R 4.3.1)\n#&gt;    stars               0.6-4      2023-09-11 [1] CRAN (R 4.3.2)\n#&gt;    stringi             1.8.3      2023-12-11 [1] CRAN (R 4.3.2)\n#&gt;    stringr           * 1.5.1      2023-11-14 [1] CRAN (R 4.3.2)\n#&gt;    styler            * 1.10.3     2024-04-07 [1] CRAN (R 4.3.3)\n#&gt;    svglite             2.1.3      2023-12-08 [1] CRAN (R 4.3.2)\n#&gt;    systemfonts         1.0.5      2023-10-09 [1] CRAN (R 4.3.2)\n#&gt;    tensorA             0.36.2.1   2023-12-13 [1] CRAN (R 4.3.2)\n#&gt;    terra             * 1.7-71     2024-01-31 [1] CRAN (R 4.3.2)\n#&gt;    tibble            * 3.2.1      2023-03-20 [1] CRAN (R 4.3.2)\n#&gt;    tictoc            * 1.2.1      2024-03-18 [1] CRAN (R 4.3.3)\n#&gt;    tidyr             * 1.3.1      2024-01-24 [1] CRAN (R 4.3.2)\n#&gt;    tidyselect          1.2.1      2024-03-11 [1] CRAN (R 4.3.3)\n#&gt;    tidyverse         * 2.0.0      2023-02-22 [1] CRAN (R 4.3.2)\n#&gt;    timechange          0.3.0      2024-01-18 [1] CRAN (R 4.3.2)\n#&gt;    tzdb                0.4.0      2023-05-12 [1] CRAN (R 4.3.2)\n#&gt;    units               0.8-5      2023-11-28 [1] CRAN (R 4.3.2)\n#&gt;    urlchecker          1.0.1      2021-11-30 [1] CRAN (R 4.3.2)\n#&gt;    usethis             2.2.3      2024-02-19 [1] CRAN (R 4.3.2)\n#&gt;    utf8                1.2.4      2023-10-22 [1] CRAN (R 4.3.2)\n#&gt;    uuid                1.2-0      2024-01-14 [1] CRAN (R 4.3.2)\n#&gt;    vctrs               0.6.5      2023-12-01 [1] CRAN (R 4.3.2)\n#&gt;    viridisLite         0.4.2      2023-05-02 [1] CRAN (R 4.3.2)\n#&gt;    withr               3.0.0      2024-01-16 [1] CRAN (R 4.3.2)\n#&gt;    wk                  0.9.1      2023-11-29 [1] CRAN (R 4.3.2)\n#&gt;    xfun                0.44       2024-05-15 [1] CRAN (R 4.3.3)\n#&gt;    xml2                1.3.6      2023-12-04 [1] CRAN (R 4.3.2)\n#&gt;    xtable              1.8-4      2019-04-21 [1] CRAN (R 4.3.2)\n#&gt;    yaml                2.3.8      2023-12-11 [1] CRAN (R 4.3.2)\n#&gt; \n#&gt;  [1] C:/Users/usuario/AppData/Local/R/win-library/4.3\n#&gt;  [2] C:/Program Files/R/R-4.3.2/library\n#&gt; \n#&gt;  D ── DLL MD5 mismatch, broken installation.\n#&gt; \n#&gt; ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/2024-07-05-multi-species-interacting-occupancy/index.html",
    "href": "posts/2024-07-05-multi-species-interacting-occupancy/index.html",
    "title": "A multi-species (species interactions) occupancy model",
    "section": "",
    "text": "Direct observations of interactions (e.g. predation events)\nIndirect ways:\n\n\nOver time. We can use Activity pattern analysis (e.g. Ridout and Linkie 2009, overlap R package). Doesn’t necessarily test if species are typically found in the same locations.\nOver space. Multispecies occupancy models. Don’t necessary test if species are active at the same time.\n\n\n\nTwo or more species, no interactions explicitly modeled (e.g. community occupancy models; AHM1 Chap 11).\nTwo species, species interaction factor, sometimes has numerical issues (MacKenzie et al. 2004).\nTwo species, asymmetric interactions (Waddle et al. 2010, Richmond et al. 2010). Available in PRESENCE and MARK software.\nTwo species, symmetric interactions (Rota et al. 2016, AHM2 Chap 8) &lt;- focus of this post."
  },
  {
    "objectID": "posts/2024-07-05-multi-species-interacting-occupancy/index.html#how-can-we-model-species-interactions",
    "href": "posts/2024-07-05-multi-species-interacting-occupancy/index.html#how-can-we-model-species-interactions",
    "title": "A multi-species (species interactions) occupancy model",
    "section": "",
    "text": "Direct observations of interactions (e.g. predation events)\nIndirect ways:\n\n\nOver time. We can use Activity pattern analysis (e.g. Ridout and Linkie 2009, overlap R package). Doesn’t necessarily test if species are typically found in the same locations.\nOver space. Multispecies occupancy models. Don’t necessary test if species are active at the same time.\n\n\n\nTwo or more species, no interactions explicitly modeled (e.g. community occupancy models; AHM1 Chap 11).\nTwo species, species interaction factor, sometimes has numerical issues (MacKenzie et al. 2004).\nTwo species, asymmetric interactions (Waddle et al. 2010, Richmond et al. 2010). Available in PRESENCE and MARK software.\nTwo species, symmetric interactions (Rota et al. 2016, AHM2 Chap 8) &lt;- focus of this post."
  },
  {
    "objectID": "posts/2024-07-05-multi-species-interacting-occupancy/index.html#load-packages",
    "href": "posts/2024-07-05-multi-species-interacting-occupancy/index.html#load-packages",
    "title": "A multi-species (species interactions) occupancy model",
    "section": "Load packages",
    "text": "Load packages\n\nCode\n# library(ggpmthemes)\nlibrary(glue) # Interpreted String Literals\nlibrary(patchwork) # The Composer of Plots\nlibrary(readxl) # Read Excel Files\nlibrary(sf) # Simple Features for R\nlibrary(mapview) # Interactive Viewing of Spatial Data in R\nlibrary(grateful) # Facilitate Citation of R Packages\nlibrary (terra)\nlibrary(unmarked)\nlibrary(stars)\nlibrary(elevatr)\nlibrary(ubms)\nlibrary(camtrapR)\nlibrary(knitr) # A General-Purpose Package for Dynamic Report Generation in R\n# options(kableExtra.auto_format = FALSE)\nlibrary(kableExtra) # Construct Complex Table with 'kable' and Pipe Syntax\nlibrary(DT)\nlibrary(tidyverse) # Easily Install and Load the 'Tidyverse'\nlibrary(ggforce) # Accelerating 'ggplot2'\n\nlibrary(readr)\n\n\n\nsource(\"C:/CodigoR/CameraTrapCesar/R/organiza_datos.R\")"
  },
  {
    "objectID": "posts/2024-07-05-multi-species-interacting-occupancy/index.html#load-data",
    "href": "posts/2024-07-05-multi-species-interacting-occupancy/index.html#load-data",
    "title": "A multi-species (species interactions) occupancy model",
    "section": "Load data",
    "text": "Load data\nSingle campaign in raw format and next arrange to 5 occasions\nLoad full dataset\n\nCode\nodp_ecu_col&lt;- read_csv(\"C:/CodigoR/CameraTrapCesar/data/oso_danta_puma_ucu_pitalito_cocha2_ana_saldania_ecuador_noNA.csv\")"
  },
  {
    "objectID": "posts/2024-07-05-multi-species-interacting-occupancy/index.html#convert-to-sf",
    "href": "posts/2024-07-05-multi-species-interacting-occupancy/index.html#convert-to-sf",
    "title": "A multi-species (species interactions) occupancy model",
    "section": "Convert to sf",
    "text": "Convert to sf\n\nCode\ndatos_distinct &lt;- odp_ecu_col |&gt; distinct(Longitude, Latitude, Deployment_id)\n\nprojlatlon &lt;- \"+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0\"\n\ndatos_sf &lt;-  st_as_sf(x = datos_distinct,\n                         coords = c(\"Longitude\", \n                                    \"Latitude\"),\n                         crs = projlatlon)\n\nmapview(datos_sf, zcol=\"Deployment_id\")"
  },
  {
    "objectID": "posts/2024-07-05-multi-species-interacting-occupancy/index.html#get-rasters",
    "href": "posts/2024-07-05-multi-species-interacting-occupancy/index.html#get-rasters",
    "title": "A multi-species (species interactions) occupancy model",
    "section": "get rasters",
    "text": "get rasters\n\nCode\n#load raster\nper_tree_cov &lt;- rast(\"C:/CodigoR/WCS-CameraTrap/raster/latlon/Veg_Cont_Fields_Yearly_250m_v61/Perc_TreeCov/MOD44B_Perc_TreeCov_2010_065.tif\")\nroad_den &lt;- rast(\"C:/CodigoR/WCS-CameraTrap/raster/latlon/RoadDensity/grip4_total_dens_m_km2.asc\")\n# elev &lt;- rast(\"D:/CORREGIDAS/elevation_z7.tif\")\nlandcov &lt;- rast(\"C:/CodigoR/WCS-CameraTrap/raster/latlon/LandCover_Type_Yearly_500m_v61/LC1/MCD12Q1_LC1_2010_001.tif\") \ncattle &lt;- rast(\"C:/CodigoR/WCS-CameraTrap/raster/latlon/Global cattle distribution/5_Ct_2010_Da.tif\")\n#river &lt;- st_read(\"F:/WCS-CameraTrap/shp/DensidadRios/MCD12Q1_LC1_2001_001_RECLASS_MASK_GRID_3600m_DensDrenSouthAmer.shp\")\n\n# get elevation map\n#elevation_detailed &lt;- rast(get_elev_raster(sites, z = 10, clip=\"bbox\", neg_to_na=TRUE))\nelevation_detailed &lt;- get_elev_point (datos_sf, src=\"aws\", overwrite=TRUE)\n\n\n# extract covs using points and add to sites\n# covs &lt;- cbind(sites, terra::extract(SiteCovsRast, sites))\nper_tre &lt;- terra::extract(per_tree_cov, datos_sf)\nroads &lt;- terra::extract(road_den, datos_sf)\n# eleva &lt;- terra::extract(elevation_detailed, sites)\nland_cov &lt;- terra::extract(landcov, datos_sf)\ncattle_den &lt;-  terra::extract(cattle, datos_sf)\n\nsites &lt;- as.data.frame(datos_sf)\n\n# remove decimals convert to factor\nsites$land_cover &lt;-  factor(land_cov$MCD12Q1_LC1_2010_001)\n# sites$elevation &lt;-  eleva$file3be898018c3\nsites$per_tree_cov &lt;- per_tre$MOD44B_Perc_TreeCov_2010_065 \n#  fix 200 isue\nind &lt;- which(sites$per_tree_cov== 200)\nsites$per_tree_cov[ind] &lt;- 0\n\nsites$elevation &lt;- elevation_detailed$elevation\nsites$roads &lt;- roads$grip4_total_dens_m_km2\nsites$cattle &lt;- cattle_den[,2]\n\n# arrange detections observations\n\neffort &lt;- as.data.frame(odp_ecu_col[,19:23])\n\nylist &lt;- list(oso  =as.matrix(odp_ecu_col[,4:8]),\n              danta=as.matrix(odp_ecu_col[,9:13]),\n              puma =as.matrix(odp_ecu_col[,14:18]))\n\nlapply(ylist, head) # look at first few rows\n#&gt; $oso\n#&gt;      o1 o2 o3 o4 o5\n#&gt; [1,]  0  0  0  0  0\n#&gt; [2,]  0  0  0  0  0\n#&gt; [3,]  0  0  0  0  0\n#&gt; [4,]  0  0  0  0  0\n#&gt; [5,]  0  0  0  0  0\n#&gt; [6,]  0  0  0  0  0\n#&gt; \n#&gt; $danta\n#&gt;      d1 d2 d3 d4 d5\n#&gt; [1,]  1  1  1  1  1\n#&gt; [2,]  1  1  1  1  1\n#&gt; [3,]  1  1  1  0  1\n#&gt; [4,]  1  1  1  1  1\n#&gt; [5,]  0  1  1  1  1\n#&gt; [6,]  1  1  1  1  1\n#&gt; \n#&gt; $puma\n#&gt;      p1 p2 p3 p4 p5\n#&gt; [1,]  0  0  0  0  0\n#&gt; [2,]  0  0  0  0  0\n#&gt; [3,]  0  0  1  0  0\n#&gt; [4,]  0  0  0  0  0\n#&gt; [5,]  0  0  0  0  0\n#&gt; [6,]  0  1  0  0  0\n\nsite_covs &lt;- as.data.frame(sites[,4:7])\n# site_covs$roads &lt;- as.numeric(site_covs$roads)\n# site_covs &lt;- scale(site_covs)\nhead(site_covs)\n#&gt;   per_tree_cov elevation roads   cattle\n#&gt; 1           19      2199   541 2554.303\n#&gt; 2           13      2729   541 2554.303\n#&gt; 3            9      2199   541 2554.303\n#&gt; 4            5      2199   541 2554.303\n#&gt; 5            8      2199   541 2554.303\n#&gt; 6           13      2370   541 2554.303\n\n\nObsCovs_list &lt;- list(effort= odp_ecu_col[,19:23])\n\n\n# Make UMF object\numf &lt;- unmarkedFrameOccuMulti(y=ylist, \n                              siteCovs=site_covs,\n                              obsCovs=ObsCovs_list\n                              )\nhead(umf)\n#&gt; Data frame representation of unmarkedFrame object.\n#&gt; Only showing observation matrix for species 1.\n#&gt;    y.1 y.2 y.3 y.4 y.5 per_tree_cov elevation roads   cattle effort.1 effort.2\n#&gt; 1    0   0   0   0   0           19      2199   541 2554.303      9.5       10\n#&gt; 2    0   0   0   0   0           13      2729   541 2554.303      9.5       10\n#&gt; 3    0   0   0   0   0            9      2199   541 2554.303      9.5       10\n#&gt; 4    0   0   0   0   0            5      2199   541 2554.303      9.5       10\n#&gt; 5    0   0   0   0   0            8      2199   541 2554.303      9.5       10\n#&gt; 6    0   0   0   0   0           13      2370   541 2554.303      9.5       10\n#&gt; 7    0   0   0   0   0            4      2218    57 2545.696      9.5       10\n#&gt; 8    0   0   0   0   0            5      2310    57 2545.696      9.5       10\n#&gt; 9    0   0   0   0   0           10      2310    57 2545.696      9.5       10\n#&gt; 10   0   1   0   0   0            6      2023  1315 2963.785      9.5       10\n#&gt;    effort.3 effort.4 effort.5\n#&gt; 1        10       10      4.5\n#&gt; 2        10       10      2.5\n#&gt; 3        10       10      4.5\n#&gt; 4        10       10      4.5\n#&gt; 5        10       10     10.0\n#&gt; 6        10       10      3.5\n#&gt; 7        10       10     10.0\n#&gt; 8        10       10      2.5\n#&gt; 9        10       10     10.0\n#&gt; 10       10       10      2.5\nsummary(umf)\n#&gt; unmarkedFrame Object\n#&gt; \n#&gt; 287 sites\n#&gt; 3 species: oso danta puma \n#&gt; Maximum number of observations per site: 5 \n#&gt; Mean number of observations per site:\n#&gt; oso: 5  danta: 5  puma: 5  \n#&gt; Sites with at least one detection:\n#&gt; oso: 48  danta: 88  puma: 28  \n#&gt; Tabulation of y observations:\n#&gt; oso:\n#&gt;    0    1 \n#&gt; 1364   71 \n#&gt; danta:\n#&gt;    0    1 \n#&gt; 1238  197 \n#&gt; puma:\n#&gt;    0    1 \n#&gt; 1393   42 \n#&gt; \n#&gt; Site-level covariates:\n#&gt;   per_tree_cov     elevation        roads            cattle      \n#&gt;  Min.   : 2.00   Min.   : 684   Min.   :   0.0   Min.   :   0.0  \n#&gt;  1st Qu.:10.00   1st Qu.:2225   1st Qu.:   0.0   1st Qu.: 371.3  \n#&gt;  Median :19.00   Median :2590   Median :  59.0   Median :1599.6  \n#&gt;  Mean   :28.49   Mean   :2629   Mean   : 216.1   Mean   :1350.4  \n#&gt;  3rd Qu.:44.50   3rd Qu.:3038   3rd Qu.: 448.0   3rd Qu.:2498.4  \n#&gt;  Max.   :82.00   Max.   :4019   Max.   :1315.0   Max.   :5666.5  \n#&gt; \n#&gt; Observation-level covariates:\n#&gt;      effort     \n#&gt;  Min.   : 0.00  \n#&gt;  1st Qu.: 9.50  \n#&gt;  Median :10.00  \n#&gt;  Mean   :11.13  \n#&gt;  3rd Qu.:19.50  \n#&gt;  Max.   :24.00\n\nplot(umf)"
  },
  {
    "objectID": "posts/2024-07-05-multi-species-interacting-occupancy/index.html#set-up-the-formulas",
    "href": "posts/2024-07-05-multi-species-interacting-occupancy/index.html#set-up-the-formulas",
    "title": "A multi-species (species interactions) occupancy model",
    "section": "Set up the formulas",
    "text": "Set up the formulas\nIntercept-only model, assuming independence\nFor now, we assume independence among species. We do this by only allowing 1st order natural parameters (maxOrder = 1).\nThis is equivalent to fitting 3 single-species occupancy models.\n\nCode\numf@fDesign\n#&gt;          f1[oso] f2[danta] f3[puma] f4[oso:danta] f5[oso:puma] f6[danta:puma]\n#&gt; psi[111]       1         1        1             1            1              1\n#&gt; psi[110]       1         1        0             1            0              0\n#&gt; psi[101]       1         0        1             0            1              0\n#&gt; psi[100]       1         0        0             0            0              0\n#&gt; psi[011]       0         1        1             0            0              1\n#&gt; psi[010]       0         1        0             0            0              0\n#&gt; psi[001]       0         0        1             0            0              0\n#&gt; psi[000]       0         0        0             0            0              0\n#&gt;          f7[oso:danta:puma]\n#&gt; psi[111]                  1\n#&gt; psi[110]                  0\n#&gt; psi[101]                  0\n#&gt; psi[100]                  0\n#&gt; psi[011]                  0\n#&gt; psi[010]                  0\n#&gt; psi[001]                  0\n#&gt; psi[000]                  0\n\nfit_1 &lt;- occuMulti(detformulas = c('~1', '~1', '~1'),\n                   stateformulas = c('~1', '~1', '~1'),\n                   maxOrder = 1,\n                   data = umf)\n\n# DT::datatable(round(summary(fit_1), 3))\n\nsummary(fit_1)\n#&gt; \n#&gt; Call:\n#&gt; occuMulti(detformulas = c(\"~1\", \"~1\", \"~1\"), stateformulas = c(\"~1\", \n#&gt;     \"~1\", \"~1\"), data = umf, maxOrder = 1)\n#&gt; \n#&gt; Occupancy (logit-scale):\n#&gt;                     Estimate    SE     z  P(&gt;|z|)\n#&gt; [oso] (Intercept)     -1.094 0.225 -4.86 1.18e-06\n#&gt; [danta] (Intercept)   -0.715 0.134 -5.32 1.06e-07\n#&gt; [puma] (Intercept)    -1.789 0.259 -6.89 5.42e-12\n#&gt; \n#&gt; Detection (logit-scale):\n#&gt;                     Estimate    SE     z  P(&gt;|z|)\n#&gt; [oso] (Intercept)     -1.404 0.213 -6.58 4.64e-11\n#&gt; [danta] (Intercept)   -0.332 0.108 -3.06 2.19e-03\n#&gt; [puma] (Intercept)    -1.360 0.274 -4.96 6.95e-07\n#&gt; \n#&gt; AIC: 1825.561 \n#&gt; Number of sites: 287\n#&gt; optim convergence code: 0\n#&gt; optim iterations: 68 \n#&gt; Bootstrap iterations: 0\n\n\nIntercept-only model, assuming dependence\n\nSet maxOrder = 2 to estimate up to 2nd order natural parameters\nPermits dependence between species\nFixes all natural parameters &gt; maxOrder at 0\n\nIn fit_2 The species are interacting, but no covariates are involved.\n\nCode\nfit_2 &lt;- occuMulti(detformulas = c('~1', '~1', '~1'),\n                   stateformulas = c('~1', '~1', '~1',\n                                     '~1', '~1', '~1'),\n                   maxOrder = 2,\n                   data = umf)\n\nsummary(fit_2)\n#&gt; \n#&gt; Call:\n#&gt; occuMulti(detformulas = c(\"~1\", \"~1\", \"~1\"), stateformulas = c(\"~1\", \n#&gt;     \"~1\", \"~1\", \"~1\", \"~1\", \"~1\"), data = umf, maxOrder = 2)\n#&gt; \n#&gt; Occupancy (logit-scale):\n#&gt;                          Estimate    SE      z  P(&gt;|z|)\n#&gt; [oso] (Intercept)          -0.797 0.264 -3.014 2.58e-03\n#&gt; [danta] (Intercept)        -0.720 0.190 -3.795 1.47e-04\n#&gt; [puma] (Intercept)         -2.567 0.458 -5.603 2.10e-08\n#&gt; [oso:danta] (Intercept)    -1.250 0.495 -2.524 1.16e-02\n#&gt; [oso:puma] (Intercept)      0.197 0.716  0.275 7.83e-01\n#&gt; [danta:puma] (Intercept)    1.611 0.519  3.104 1.91e-03\n#&gt; \n#&gt; Detection (logit-scale):\n#&gt;                     Estimate    SE     z  P(&gt;|z|)\n#&gt; [oso] (Intercept)     -1.402 0.213 -6.58 4.58e-11\n#&gt; [danta] (Intercept)   -0.329 0.108 -3.05 2.31e-03\n#&gt; [puma] (Intercept)    -1.362 0.275 -4.95 7.30e-07\n#&gt; \n#&gt; AIC: 1811.834 \n#&gt; Number of sites: 287\n#&gt; optim convergence code: 0\n#&gt; optim iterations: 39 \n#&gt; Bootstrap iterations: 0\n\n\noso y danta occur together more frequently than expected by chance (p&lt;0.01) danta y puma occur together more frequently than expected by chance (p&lt;0.01)\nIncorporating covariates\nAny parameter can be modeled as a function of covariates. The Covariate for each parameter can be unique names of detection covariates corresponding to names provided in named list of the umf object. Names of occupancy covariates correspond to names in the data.frame part of umf. The model below is driven by biology and have the interest in demonstrating that each parameter can be modeled uniquely.\nSo number of days (sampling effort) is the covariate for the detection part. Bear occupancy depends on cattle, tapir occupancy depends on elevation, and puma occupancy depends on elevation as well. The interaction oso:danta depends on cattle, oso:puma depends on per_tree_cov and danta:puma on per_tree_cov as well.\n\nCodefit_3 &lt;- occuMulti(detformulas = c('~effort', '~effort', '~effort'),\n                   stateformulas = c('~cattle', #oso\n                                     '~elevation', #danta\n                                     '~elevation', #puma\n                                     '~cattle', #oso:danta\n                                     '~per_tree_cov', #oso:puma\n                                     '~per_tree_cov' #danta:puma\n                                     ),\n                   maxOrder = 2,\n                   se=TRUE,\n                   penalty=0.5,\n                   data = umf)\n#&gt; Bootstraping covariance matrix\n\nsummary(fit_3)\n#&gt; \n#&gt; Call:\n#&gt; occuMulti(detformulas = c(\"~effort\", \"~effort\", \"~effort\"), stateformulas = c(\"~cattle\", \n#&gt;     \"~elevation\", \"~elevation\", \"~cattle\", \"~per_tree_cov\", \"~per_tree_cov\"), \n#&gt;     data = umf, maxOrder = 2, penalty = 0.5, se = TRUE)\n#&gt; \n#&gt; Occupancy (logit-scale):\n#&gt;                            Estimate       SE         z  P(&gt;|z|)\n#&gt; [oso] (Intercept)         -5.18e-07 2.06e-01 -2.51e-06 1.00e+00\n#&gt; [oso] cattle              -7.89e-04 1.57e-04 -5.03e+00 5.01e-07\n#&gt; [danta] (Intercept)       -6.12e-08 4.81e-01 -1.27e-07 1.00e+00\n#&gt; [danta] elevation         -3.45e-04 2.47e-04 -1.40e+00 1.62e-01\n#&gt; [puma] (Intercept)        -3.71e-07 1.20e-01 -3.08e-06 1.00e+00\n#&gt; [puma] elevation          -1.00e-03 7.69e-05 -1.30e+01 7.08e-39\n#&gt; [oso:danta] (Intercept)   -2.67e-07 1.24e-01 -2.15e-06 1.00e+00\n#&gt; [oso:danta] cattle        -4.04e-04 6.94e-04 -5.82e-01 5.60e-01\n#&gt; [oso:puma] (Intercept)    -2.57e-07 4.84e-01 -5.31e-07 1.00e+00\n#&gt; [oso:puma] per_tree_cov   -7.89e-06 2.49e-03 -3.17e-03 9.97e-01\n#&gt; [danta:puma] (Intercept)  -1.40e-07 5.60e-01 -2.49e-07 1.00e+00\n#&gt; [danta:puma] per_tree_cov -4.20e-06 1.01e-02 -4.16e-04 1.00e+00\n#&gt; \n#&gt; Detection (logit-scale):\n#&gt;                      Estimate     SE         z P(&gt;|z|)\n#&gt; [oso] (Intercept)   -5.28e-07 0.7627 -6.92e-07       1\n#&gt; [oso] effort        -4.95e-06 0.0323 -1.53e-04       1\n#&gt; [danta] (Intercept) -2.76e-07 0.2390 -1.16e-06       1\n#&gt; [danta] effort      -1.79e-06 0.0191 -9.36e-05       1\n#&gt; [puma] (Intercept)  -3.21e-07 0.6453 -4.98e-07       1\n#&gt; [puma] effort       -3.23e-06 0.0147 -2.19e-04       1\n#&gt; \n#&gt; AIC: 1977.895 \n#&gt; Number of sites: 287\n#&gt; optim convergence code: 0\n#&gt; optim iterations: 101 \n#&gt; Bootstrap iterations: 30\n\n\nConditional occupancy probability\nCalculation of conditional and marginal occupancy probabilities is done with the predict function.\nCreate a data.frame for predictions The procedure is equivalent to creating data frames for all other applications of predict Include complete range of observed cattle; hold all other variables at their mean.\n\nCodend_cond &lt;- data.frame(\n  # cattle is the one changing from min to max\n  cattle = seq(min(site_covs$cattle), max(site_covs$cattle), length.out = 100), \n  elevation = rep(mean(site_covs$elevation), 100),\n  roads = rep(mean(site_covs$roads), 100),\n  per_tree_cov = rep(mean(site_covs$per_tree_cov), 100) # max(site_covs$per_tree_cov),\n                 # length.out = 100)\n)\n\n\nPredicting danta occurrence when oso are present\nspecies indicates which species we assume when predicting occupancy cond indicates which species we are assuming is present or absent\n\nCodedanta_oso_1 &lt;- predict(fit_3, type = 'state', species = 'danta',\n                     cond = 'oso', newdata = nd_cond)\n\n\nPredicting danta occurrence when oso are absent\nputting a - in front of oso tells predict you wish to assume oso are absent\n\nCode\ndanta_oso_0 &lt;- predict(fit_3, type = 'state', species = 'danta',\n                     cond = '-oso', newdata = nd_cond)\n\n\ndanta oso marginal occupancy box plot\n\nCode################################## Marginal\ndanta_marginal &lt;- predict(fit_3, type=\"state\", species=\"danta\")\nhead(danta_marginal)\n#&gt;   Predicted         SE     lower     upper\n#&gt; 1 0.3021211 0.08128417 0.2565159 0.4397345\n#&gt; 2 0.2650259 0.09711105 0.2030555 0.4494998\n#&gt; 3 0.3021219 0.08087223 0.2578118 0.4387217\n#&gt; 4 0.3021222 0.08074926 0.2583218 0.4383562\n#&gt; 5 0.3021220 0.08083894 0.2579374 0.4386284\n#&gt; 6 0.2898338 0.08585125 0.2388948 0.4426687\n\noso_marginal &lt;- predict(fit_3, type='state', species=\"oso\") # get coyote\nmarg_plot_dat &lt;- rbind(danta_marginal[1,], oso_marginal[1,])\nmarg_plot_dat$Species &lt;- c(\"Tapir\", \"Bear\")\nmarg_plot_dat\n#&gt;    Predicted         SE      lower     upper Species\n#&gt; 1 0.30212114 0.08128417 0.25651587 0.4397345   Tapir\n#&gt; 2 0.09583095 0.13700921 0.05208936 0.5353914    Bear\n\n\nplot(1:2, marg_plot_dat$Predicted, ylim=c(0,0.9), \n     xlim=c(0.5,2.5), pch=19, cex=1.5, xaxt='n', \n     xlab=\"\", ylab=\"Marginal occupancy\")\naxis(1, at=1:2, labels=marg_plot_dat$Species)\n\n# CIs\ntop &lt;- 0.1\nfor (i in 1:2){\n  segments(i, marg_plot_dat$lower[i], i, marg_plot_dat$upper[i])\n  segments(i-top, marg_plot_dat$lower[i], i+top)\n  segments(i-top, marg_plot_dat$upper[i], i+top)\n}\n\n\n\n\n\n\n\ndanta puma marginal occupancy box plot\n\nCode################################## Marginal\ndanta_marginal &lt;- predict(fit_3, type=\"state\", species=\"danta\")\nhead(danta_marginal)\n#&gt;   Predicted         SE     lower     upper\n#&gt; 1 0.3021211 0.08395486 0.2565297 0.4859036\n#&gt; 2 0.2650259 0.09928923 0.2090361 0.4913584\n#&gt; 3 0.3021219 0.08334700 0.2584128 0.4845884\n#&gt; 4 0.3021222 0.08312611 0.2589106 0.4841209\n#&gt; 5 0.3021220 0.08329045 0.2585376 0.4844686\n#&gt; 6 0.2898338 0.08844256 0.2428272 0.4873957\n\noso_marginal &lt;- predict(fit_3, type='state', species=\"puma\") # get coyote\nmarg_plot_dat &lt;- rbind(danta_marginal[1,], oso_marginal[1,])\nmarg_plot_dat$Species &lt;- c(\"Tapir\", \"Puma\")\nmarg_plot_dat\n#&gt;    Predicted         SE      lower     upper Species\n#&gt; 1 0.30212114 0.08395486 0.25652967 0.4859036   Tapir\n#&gt; 2 0.09927149 0.03690354 0.04093709 0.1944529    Puma\n\n\nplot(1:2, marg_plot_dat$Predicted, ylim=c(0,0.9), \n     xlim=c(0.5,2.5), pch=19, cex=1.5, xaxt='n', \n     xlab=\"\", ylab=\"Marginal occupancy\")\naxis(1, at=1:2, labels=marg_plot_dat$Species)\n\n# CIs\ntop &lt;- 0.1\nfor (i in 1:2){\n  segments(i, marg_plot_dat$lower[i], i, marg_plot_dat$upper[i])\n  segments(i-top, marg_plot_dat$lower[i], i+top)\n  segments(i-top, marg_plot_dat$upper[i], i+top)\n}\n\n\n\n\n\n\n\ndanta oso conditional box plot\n\nCode\n######################### Conditional\ndanta_oso &lt;- predict(fit_3, type=\"state\", species=\"danta\", cond=\"oso\")\nhead(danta_oso)\n#&gt;   Predicted        SE       lower     upper\n#&gt; 1 0.1429898 0.2461383 0.009344876 0.8173717\n#&gt; 2 0.1220171 0.2488071 0.006604323 0.8196394\n#&gt; 3 0.1429903 0.2456877 0.009881261 0.8168746\n#&gt; 4 0.1429905 0.2455080 0.010123259 0.8166972\n#&gt; 5 0.1429904 0.2456428 0.009940192 0.8168291\n#&gt; 6 0.1359140 0.2469085 0.008530747 0.8179675\n\ndanta_No_oso &lt;- predict(fit_3, type=\"state\", species=\"danta\", cond=\"-oso\")\nhead(danta_oso)\n#&gt;   Predicted        SE       lower     upper\n#&gt; 1 0.1429898 0.2461383 0.009344876 0.8173717\n#&gt; 2 0.1220171 0.2488071 0.006604323 0.8196394\n#&gt; 3 0.1429903 0.2456877 0.009881261 0.8168746\n#&gt; 4 0.1429905 0.2455080 0.010123259 0.8166972\n#&gt; 5 0.1429904 0.2456428 0.009940192 0.8168291\n#&gt; 6 0.1359140 0.2469085 0.008530747 0.8179675\n\n\nplot_data &lt;- rbind(danta_oso[1,], danta_No_oso[1,])\nplot_data$Oso_status &lt;- c(\"Present\",\"Absent\")\nhead(plot_data)\n#&gt;   Predicted         SE       lower     upper Oso_status\n#&gt; 1 0.1429898 0.24613826 0.009344876 0.8173717    Present\n#&gt; 2 0.3189871 0.02345546 0.282291906 0.3704988     Absent\n\nplot(1:2, plot_data$Predicted, ylim=c(0, 0.9), \n     xlim=c(0.5,2.5), pch=19, cex=1.5, xaxt='n', \n     xlab=\"Bear status\", ylab=\"Tapir cond. occupancy\")\naxis(1, at=1:2, labels=plot_data$Oso_status)\n\n# CIs\ntop &lt;- 0.1\nfor (i in 1:2){\n  segments(i, plot_data$lower[i], i, plot_data$upper[i])\n  segments(i-top, plot_data$lower[i], i+top)\n  segments(i-top, plot_data$upper[i], i+top)\n}\n\n\n\n\n\n\n\ndanta puma conditional box plot\n\nCode\n######################### Conditional\ndanta_oso &lt;- predict(fit_3, type=\"state\", species=\"danta\", cond=\"puma\")\nhead(danta_oso)\n#&gt;   Predicted         SE     lower     upper\n#&gt; 1 0.3021080 0.05173259 0.2150523 0.4010237\n#&gt; 2 0.2650173 0.04030880 0.2038915 0.3472187\n#&gt; 3 0.3021157 0.06940203 0.1926251 0.4259667\n#&gt; 4 0.3021187 0.07700312 0.1811854 0.4381635\n#&gt; 5 0.3021164 0.07128587 0.1896902 0.4290078\n#&gt; 6 0.2898249 0.05372997 0.2022631 0.3896648\n\ndanta_No_oso &lt;- predict(fit_3, type=\"state\", species=\"danta\", cond=\"-puma\")\nhead(danta_oso)\n#&gt;   Predicted         SE     lower     upper\n#&gt; 1 0.3021080 0.05173259 0.2150523 0.4010237\n#&gt; 2 0.2650173 0.04030880 0.2038915 0.3472187\n#&gt; 3 0.3021157 0.06940203 0.1926251 0.4259667\n#&gt; 4 0.3021187 0.07700312 0.1811854 0.4381635\n#&gt; 5 0.3021164 0.07128587 0.1896902 0.4290078\n#&gt; 6 0.2898249 0.05372997 0.2022631 0.3896648\n\n\nplot_data &lt;- rbind(danta_oso[1,], danta_No_oso[1,])\nplot_data$Oso_status &lt;- c(\"Present\",\"Absent\")\nhead(plot_data)\n#&gt;   Predicted         SE     lower     upper Oso_status\n#&gt; 1 0.3021080 0.05173259 0.2150523 0.4010237    Present\n#&gt; 2 0.3021226 0.06373796 0.2524167 0.4499569     Absent\n\nplot(1:2, plot_data$Predicted, ylim=c(0, 0.9), \n     xlim=c(0.5,2.5), pch=19, cex=1.5, xaxt='n', \n     xlab=\"Puma status\", ylab=\"Tapir cond. occupancy\")\naxis(1, at=1:2, labels=plot_data$Oso_status)\n\n# CIs\ntop &lt;- 0.1\nfor (i in 1:2){\n  segments(i, plot_data$lower[i], i, plot_data$upper[i])\n  segments(i-top, plot_data$lower[i], i+top)\n  segments(i-top, plot_data$upper[i], i+top)\n}\n\n\n\n\n\n\n\npredicting with covariates\n\nCode\ngg_df_cond1 &lt;- data.frame(\n  cattle = rep(nd_cond$cattle, 2),\n  occupancy = c(danta_oso_1$Predicted,\n                danta_oso_0$Predicted),\n  low = c(danta_oso_1$lower,\n          danta_oso_0$lower),\n  high = c(danta_oso_1$upper,\n           danta_oso_0$upper),\n  conditional = rep(c('Bear present', 'Bear absent'),\n                    each = 100)\n)\n\n\ncond_fig1 &lt;- ggplot(gg_df_cond1, aes(x = cattle, y = occupancy,\n                                   group = conditional)) +\n  geom_ribbon(aes(ymin = low, ymax = high, fill = conditional),  alpha=0.5) +\n  geom_line() +\n  ylab('Conditional Tapir\\noccupancy probability') +\n  xlab('cattle') +\n  labs(fill = 'Bear state') +\n  theme(text = element_text(size = 15),\n        legend.position = c(0.75, 0.85))\n\ncond_fig1\n\n\n\n\n\n\n\ndanta puma\n\nCode\ndanta_puma_1 &lt;- predict(fit_3, type = 'state', species = 'danta',\n                     cond = 'puma', newdata = nd_cond)\n\ndanta_puma_0 &lt;- predict(fit_3, type = 'state', species = 'danta',\n                     cond = '-puma', newdata = nd_cond)\n\n\ngg_df_cond2 &lt;- data.frame(\n  cattle = rep(nd_cond$cattle, 2),\n  occupancy = c(danta_puma_1$Predicted,\n                danta_puma_0$Predicted),\n  low = c(danta_puma_1$lower,\n          danta_puma_0$lower),\n  high = c(danta_puma_1$upper,\n           danta_puma_0$upper),\n  conditional = rep(c('Puma present', 'Puma absent'),\n                    each = 100)\n)\n\n\n\ncond_fig2 &lt;- ggplot(gg_df_cond2, aes(x = cattle, y = occupancy,\n                                   group = conditional)) +\n  geom_ribbon(aes(ymin = low, ymax = high, fill = conditional),  alpha=0.5) +\n  geom_line() +\n  ylab('Conditional Tapir\\noccupancy probability') +\n  xlab('per_tree_cov') +\n  labs(fill = 'Puma state') +\n  theme(text = element_text(size = 15),\n        legend.position = c(0.75, 0.85))\n\ncond_fig2\n\n\n\n\n\n\n\nhttps://eesc.usgs.gov/MBR/workshops/ahm2023/04_Multispecies%20_occupancy/multispecies-occupancy.html"
  },
  {
    "objectID": "posts/2024-07-05-multi-species-interacting-occupancy/index.html#package-citation",
    "href": "posts/2024-07-05-multi-species-interacting-occupancy/index.html#package-citation",
    "title": "A multi-species (species interactions) occupancy model",
    "section": "Package Citation",
    "text": "Package Citation\n\nCodepkgs &lt;- cite_packages(output = \"paragraph\", out.dir = \".\") #knitr::kable(pkgs)\npkgs\n\nWe used R version 4.3.2 (R Core Team 2023) and the following R packages: camtrapR v. 2.3.0 (Niedballa et al. 2016), devtools v. 2.4.5 (Wickham et al. 2022), DT v. 0.32 (Xie, Cheng, and Tan 2024), elevatr v. 0.99.0 (Hollister et al. 2023), ggforce v. 0.4.2 (Pedersen 2024a), glue v. 1.7.0 (Hester and Bryan 2024), kableExtra v. 1.4.0 (Zhu 2024), knitr v. 1.46 (Xie 2014, 2015, 2024), mapview v. 2.11.2 (Appelhans et al. 2023), patchwork v. 1.2.0 (Pedersen 2024b), quarto v. 1.4 (Allaire and Dervieux 2024), rmarkdown v. 2.27 (Xie, Allaire, and Grolemund 2018; Xie, Dervieux, and Riederer 2020; Allaire et al. 2024), sf v. 1.0.15 (Pebesma 2018; Pebesma and Bivand 2023a), stars v. 0.6.4 (Pebesma and Bivand 2023b), styler v. 1.10.3 (Müller and Walthert 2024), terra v. 1.7.71 (Hijmans 2024), tidyverse v. 2.0.0 (Wickham et al. 2019), ubms v. 1.2.6 (Kellner et al. 2021), unmarked v. 1.4.1 (Fiske and Chandler 2011; Kellner et al. 2023)."
  },
  {
    "objectID": "posts/2024-07-05-multi-species-interacting-occupancy/index.html#sesion-info",
    "href": "posts/2024-07-05-multi-species-interacting-occupancy/index.html#sesion-info",
    "title": "A multi-species (species interactions) occupancy model",
    "section": "Sesion info",
    "text": "Sesion info\n\nSession info\n\n#&gt; ─ Session info ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n#&gt;  setting  value\n#&gt;  version  R version 4.3.2 (2023-10-31 ucrt)\n#&gt;  os       Windows 10 x64 (build 19042)\n#&gt;  system   x86_64, mingw32\n#&gt;  ui       RTerm\n#&gt;  language (EN)\n#&gt;  collate  Spanish_Colombia.utf8\n#&gt;  ctype    Spanish_Colombia.utf8\n#&gt;  tz       America/Bogota\n#&gt;  date     2024-07-17\n#&gt;  pandoc   3.1.11 @ C:/Program Files/RStudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n#&gt; \n#&gt; ─ Packages ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n#&gt;  ! package           * version  date (UTC) lib source\n#&gt;    abind             * 1.4-5    2016-07-21 [1] CRAN (R 4.3.1)\n#&gt;    base64enc           0.1-3    2015-07-28 [1] CRAN (R 4.3.1)\n#&gt;    bit                 4.0.5    2022-11-15 [1] CRAN (R 4.3.2)\n#&gt;    bit64               4.0.5    2020-08-30 [1] CRAN (R 4.3.2)\n#&gt;    boot                1.3-28.1 2022-11-22 [2] CRAN (R 4.3.2)\n#&gt;    brew                1.0-10   2023-12-16 [1] CRAN (R 4.3.2)\n#&gt;    cachem              1.0.8    2023-05-01 [1] CRAN (R 4.3.2)\n#&gt;    camtrapR          * 2.3.0    2024-02-26 [1] CRAN (R 4.3.3)\n#&gt;    cellranger          1.1.0    2016-07-27 [1] CRAN (R 4.3.2)\n#&gt;    class               7.3-22   2023-05-03 [2] CRAN (R 4.3.2)\n#&gt;    classInt            0.4-10   2023-09-05 [1] CRAN (R 4.3.2)\n#&gt;    cli                 3.6.2    2023-12-11 [1] CRAN (R 4.3.2)\n#&gt;    codetools           0.2-19   2023-02-01 [2] CRAN (R 4.3.2)\n#&gt;    colorspace          2.1-0    2023-01-23 [1] CRAN (R 4.3.2)\n#&gt;    crayon              1.5.2    2022-09-29 [1] CRAN (R 4.3.2)\n#&gt;    crosstalk           1.2.1    2023-11-23 [1] CRAN (R 4.3.2)\n#&gt;    curl                5.2.0    2023-12-08 [1] CRAN (R 4.3.2)\n#&gt;    data.table          1.15.0   2024-01-30 [1] CRAN (R 4.3.2)\n#&gt;    DBI                 1.2.2    2024-02-16 [1] CRAN (R 4.3.2)\n#&gt;    devtools            2.4.5    2022-10-11 [1] CRAN (R 4.3.2)\n#&gt;    digest              0.6.34   2024-01-11 [1] CRAN (R 4.3.2)\n#&gt;    dplyr             * 1.1.4    2023-11-17 [1] CRAN (R 4.3.2)\n#&gt;    DT                * 0.32     2024-02-19 [1] CRAN (R 4.3.3)\n#&gt;    e1071               1.7-14   2023-12-06 [1] CRAN (R 4.3.2)\n#&gt;    elevatr           * 0.99.0   2023-09-12 [1] CRAN (R 4.3.2)\n#&gt;    ellipsis            0.3.2    2021-04-29 [1] CRAN (R 4.3.2)\n#&gt;    evaluate            0.23     2023-11-01 [1] CRAN (R 4.3.2)\n#&gt;    fansi               1.0.6    2023-12-08 [1] CRAN (R 4.3.2)\n#&gt;    farver              2.1.1    2022-07-06 [1] CRAN (R 4.3.2)\n#&gt;    fastmap             1.1.1    2023-02-24 [1] CRAN (R 4.3.2)\n#&gt;    forcats           * 1.0.0    2023-01-29 [1] CRAN (R 4.3.2)\n#&gt;    fs                  1.6.3    2023-07-20 [1] CRAN (R 4.3.2)\n#&gt;    generics            0.1.3    2022-07-05 [1] CRAN (R 4.3.2)\n#&gt;    ggforce           * 0.4.2    2024-02-19 [1] CRAN (R 4.3.3)\n#&gt;    ggplot2           * 3.5.1    2024-04-23 [1] CRAN (R 4.3.3)\n#&gt;    glue              * 1.7.0    2024-01-09 [1] CRAN (R 4.3.2)\n#&gt;    grateful          * 0.2.4    2023-10-22 [1] CRAN (R 4.3.3)\n#&gt;    gridExtra           2.3      2017-09-09 [1] CRAN (R 4.3.2)\n#&gt;    gtable              0.3.4    2023-08-21 [1] CRAN (R 4.3.2)\n#&gt;    hms                 1.1.3    2023-03-21 [1] CRAN (R 4.3.2)\n#&gt;    htmltools           0.5.7    2023-11-03 [1] CRAN (R 4.3.2)\n#&gt;    htmlwidgets         1.6.4    2023-12-06 [1] CRAN (R 4.3.2)\n#&gt;    httpuv              1.6.14   2024-01-26 [1] CRAN (R 4.3.2)\n#&gt;    httr                1.4.7    2023-08-15 [1] CRAN (R 4.3.2)\n#&gt;    inline              0.3.19   2021-05-31 [1] CRAN (R 4.3.2)\n#&gt;    jquerylib           0.1.4    2021-04-26 [1] CRAN (R 4.3.2)\n#&gt;    jsonlite            1.8.8    2023-12-04 [1] CRAN (R 4.3.2)\n#&gt;    kableExtra        * 1.4.0    2024-01-24 [1] CRAN (R 4.3.3)\n#&gt;    KernSmooth          2.23-22  2023-07-10 [2] CRAN (R 4.3.2)\n#&gt;    knitr             * 1.46     2024-04-06 [1] CRAN (R 4.3.3)\n#&gt;    labeling            0.4.3    2023-08-29 [1] CRAN (R 4.3.1)\n#&gt;    later               1.3.2    2023-12-06 [1] CRAN (R 4.3.2)\n#&gt;    lattice             0.22-5   2023-10-24 [1] CRAN (R 4.3.2)\n#&gt;    leafem              0.2.3    2023-09-17 [1] CRAN (R 4.3.2)\n#&gt;    leaflet             2.2.1    2023-11-13 [1] CRAN (R 4.3.2)\n#&gt;    leaflet.providers   2.0.0    2023-10-17 [1] CRAN (R 4.3.2)\n#&gt;    leafpop             0.1.0    2021-05-22 [1] CRAN (R 4.3.2)\n#&gt;    lifecycle           1.0.4    2023-11-07 [1] CRAN (R 4.3.2)\n#&gt;    lme4                1.1-35.3 2024-04-16 [1] CRAN (R 4.3.2)\n#&gt;    loo                 2.7.0    2024-02-24 [1] CRAN (R 4.3.2)\n#&gt;    lubridate         * 1.9.3    2023-09-27 [1] CRAN (R 4.3.2)\n#&gt;    magrittr            2.0.3    2022-03-30 [1] CRAN (R 4.3.2)\n#&gt;    mapview           * 2.11.2   2023-10-13 [1] CRAN (R 4.3.2)\n#&gt;    MASS                7.3-60   2023-05-04 [2] CRAN (R 4.3.2)\n#&gt;    Matrix              1.6-1.1  2023-09-18 [2] CRAN (R 4.3.2)\n#&gt;    matrixStats         1.2.0    2023-12-11 [1] CRAN (R 4.3.2)\n#&gt;    memoise             2.0.1    2021-11-26 [1] CRAN (R 4.3.2)\n#&gt;    mgcv                1.9-1    2023-12-21 [1] CRAN (R 4.3.3)\n#&gt;    mime                0.12     2021-09-28 [1] CRAN (R 4.3.1)\n#&gt;    miniUI              0.1.1.1  2018-05-18 [1] CRAN (R 4.3.2)\n#&gt;    minqa               1.2.6    2023-09-11 [1] CRAN (R 4.3.2)\n#&gt;    munsell             0.5.0    2018-06-12 [1] CRAN (R 4.3.2)\n#&gt;    nlme                3.1-163  2023-08-09 [2] CRAN (R 4.3.2)\n#&gt;    nloptr              2.0.3    2022-05-26 [1] CRAN (R 4.3.2)\n#&gt;    patchwork         * 1.2.0    2024-01-08 [1] CRAN (R 4.3.3)\n#&gt;    pbapply             1.7-2    2023-06-27 [1] CRAN (R 4.3.2)\n#&gt;    pillar              1.9.0    2023-03-22 [1] CRAN (R 4.3.2)\n#&gt;    pkgbuild            1.4.4    2024-03-17 [1] CRAN (R 4.3.3)\n#&gt;    pkgconfig           2.0.3    2019-09-22 [1] CRAN (R 4.3.2)\n#&gt;    pkgload             1.3.4    2024-01-16 [1] CRAN (R 4.3.2)\n#&gt;    png                 0.1-8    2022-11-29 [1] CRAN (R 4.3.1)\n#&gt;    polyclip            1.10-6   2023-09-27 [1] CRAN (R 4.3.1)\n#&gt;    prettyunits         1.2.0    2023-09-24 [1] CRAN (R 4.3.2)\n#&gt;    processx            3.8.3    2023-12-10 [1] CRAN (R 4.3.2)\n#&gt;    profvis             0.3.8    2023-05-02 [1] CRAN (R 4.3.2)\n#&gt;    progress            1.2.3    2023-12-06 [1] CRAN (R 4.3.3)\n#&gt;    progressr           0.14.0   2023-08-10 [1] CRAN (R 4.3.2)\n#&gt;    promises            1.2.1    2023-08-10 [1] CRAN (R 4.3.2)\n#&gt;    proxy               0.4-27   2022-06-09 [1] CRAN (R 4.3.2)\n#&gt;    ps                  1.7.6    2024-01-18 [1] CRAN (R 4.3.2)\n#&gt;    purrr             * 1.0.2    2023-08-10 [1] CRAN (R 4.3.2)\n#&gt;    quarto            * 1.4      2024-03-06 [1] CRAN (R 4.3.3)\n#&gt;    QuickJSR            1.1.3    2024-01-31 [1] CRAN (R 4.3.2)\n#&gt;    R.cache             0.16.0   2022-07-21 [1] CRAN (R 4.3.3)\n#&gt;    R.methodsS3         1.8.2    2022-06-13 [1] CRAN (R 4.3.3)\n#&gt;    R.oo                1.26.0   2024-01-24 [1] CRAN (R 4.3.3)\n#&gt;    R.utils             2.12.3   2023-11-18 [1] CRAN (R 4.3.3)\n#&gt;    R6                  2.5.1    2021-08-19 [1] CRAN (R 4.3.2)\n#&gt;    raster              3.6-26   2023-10-14 [1] CRAN (R 4.3.2)\n#&gt;    Rcpp                1.0.12   2024-01-09 [1] CRAN (R 4.3.2)\n#&gt;    RcppNumerical       0.6-0    2023-09-06 [1] CRAN (R 4.3.3)\n#&gt;  D RcppParallel        5.1.7    2023-02-27 [1] CRAN (R 4.3.2)\n#&gt;    readr             * 2.1.5    2024-01-10 [1] CRAN (R 4.3.2)\n#&gt;    readxl            * 1.4.3    2023-07-06 [1] CRAN (R 4.3.2)\n#&gt;    remotes             2.5.0    2024-03-17 [1] CRAN (R 4.3.3)\n#&gt;    renv                1.0.7    2024-04-11 [1] CRAN (R 4.3.3)\n#&gt;    rlang               1.1.3    2024-01-10 [1] CRAN (R 4.3.2)\n#&gt;    rmarkdown           2.27     2024-05-17 [1] CRAN (R 4.3.3)\n#&gt;    RSpectra            0.16-1   2022-04-24 [1] CRAN (R 4.3.2)\n#&gt;    rstan               2.32.6   2024-03-05 [1] CRAN (R 4.3.3)\n#&gt;    rstantools          2.4.0    2024-01-31 [1] CRAN (R 4.3.2)\n#&gt;    rstudioapi          0.16.0   2024-03-24 [1] CRAN (R 4.3.3)\n#&gt;    satellite           1.0.5    2024-02-10 [1] CRAN (R 4.3.2)\n#&gt;    scales              1.3.0    2023-11-28 [1] CRAN (R 4.3.3)\n#&gt;    secr                4.6.6    2024-02-29 [1] CRAN (R 4.3.3)\n#&gt;    sessioninfo         1.2.2    2021-12-06 [1] CRAN (R 4.3.2)\n#&gt;    sf                * 1.0-15   2023-12-18 [1] CRAN (R 4.3.2)\n#&gt;    shiny               1.8.0    2023-11-17 [1] CRAN (R 4.3.2)\n#&gt;    slippymath          0.3.1    2019-06-28 [1] CRAN (R 4.3.2)\n#&gt;    sp                  2.1-3    2024-01-30 [1] CRAN (R 4.3.2)\n#&gt;    StanHeaders         2.32.5   2024-01-10 [1] CRAN (R 4.3.2)\n#&gt;    stars             * 0.6-4    2023-09-11 [1] CRAN (R 4.3.2)\n#&gt;    stringi             1.8.3    2023-12-11 [1] CRAN (R 4.3.2)\n#&gt;    stringr           * 1.5.1    2023-11-14 [1] CRAN (R 4.3.2)\n#&gt;    styler            * 1.10.3   2024-04-07 [1] CRAN (R 4.3.3)\n#&gt;    svglite             2.1.3    2023-12-08 [1] CRAN (R 4.3.2)\n#&gt;    systemfonts         1.0.5    2023-10-09 [1] CRAN (R 4.3.2)\n#&gt;    terra             * 1.7-71   2024-01-31 [1] CRAN (R 4.3.2)\n#&gt;    tibble            * 3.2.1    2023-03-20 [1] CRAN (R 4.3.2)\n#&gt;    tidyr             * 1.3.1    2024-01-24 [1] CRAN (R 4.3.2)\n#&gt;    tidyselect          1.2.1    2024-03-11 [1] CRAN (R 4.3.3)\n#&gt;    tidyverse         * 2.0.0    2023-02-22 [1] CRAN (R 4.3.2)\n#&gt;    timechange          0.3.0    2024-01-18 [1] CRAN (R 4.3.2)\n#&gt;    tweenr              2.0.3    2024-02-26 [1] CRAN (R 4.3.3)\n#&gt;    tzdb                0.4.0    2023-05-12 [1] CRAN (R 4.3.2)\n#&gt;    ubms              * 1.2.6    2023-09-11 [1] CRAN (R 4.3.2)\n#&gt;    units               0.8-5    2023-11-28 [1] CRAN (R 4.3.2)\n#&gt;    unmarked          * 1.4.1    2024-01-09 [1] CRAN (R 4.3.2)\n#&gt;    urlchecker          1.0.1    2021-11-30 [1] CRAN (R 4.3.2)\n#&gt;    usethis             2.2.3    2024-02-19 [1] CRAN (R 4.3.2)\n#&gt;    utf8                1.2.4    2023-10-22 [1] CRAN (R 4.3.2)\n#&gt;    uuid                1.2-0    2024-01-14 [1] CRAN (R 4.3.2)\n#&gt;    V8                  4.4.2    2024-02-15 [1] CRAN (R 4.3.3)\n#&gt;    vctrs               0.6.5    2023-12-01 [1] CRAN (R 4.3.2)\n#&gt;    viridisLite         0.4.2    2023-05-02 [1] CRAN (R 4.3.2)\n#&gt;    vroom               1.6.5    2023-12-05 [1] CRAN (R 4.3.2)\n#&gt;    withr               3.0.0    2024-01-16 [1] CRAN (R 4.3.2)\n#&gt;    xfun                0.44     2024-05-15 [1] CRAN (R 4.3.3)\n#&gt;    xml2                1.3.6    2023-12-04 [1] CRAN (R 4.3.2)\n#&gt;    xtable              1.8-4    2019-04-21 [1] CRAN (R 4.3.2)\n#&gt;    yaml                2.3.8    2023-12-11 [1] CRAN (R 4.3.2)\n#&gt; \n#&gt;  [1] C:/Users/usuario/AppData/Local/R/win-library/4.3\n#&gt;  [2] C:/Program Files/R/R-4.3.2/library\n#&gt; \n#&gt;  D ── DLL MD5 mismatch, broken installation.\n#&gt; \n#&gt; ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/2024-07-29-sigle-season-occupancy/index.html",
    "href": "posts/2024-07-29-sigle-season-occupancy/index.html",
    "title": "Single Season Occupancy Model",
    "section": "",
    "text": "First we load some packages\n\nCode\nlibrary(grateful) # Facilitate Citation of R Packages\nlibrary(patchwork) # The Composer of Plots\nlibrary(readxl) # Read Excel Files\nlibrary(sf) # Simple Features for R\nlibrary(mapview) # Interactive Viewing of Spatial Data in R\nlibrary(terra) # Spatial Data Analysis\nlibrary(elevatr) # Access Elevation Data from Various APIs\nlibrary(readr)\n\nlibrary(camtrapR) # Camera Trap Data Management and Preparation of Occupancy and Spatial Capture-Recapture Analyses \nlibrary(unmarked) \nlibrary(ubms) \nlibrary(DT)\n\nlibrary(kableExtra) # Construct Complex Table with 'kable' and Pipe Syntax\nlibrary(tidyverse) # Easily Install and Load the 'Tidyverse'\n\n# source(\"C:/CodigoR/CameraTrapCesar/R/organiza_datos.R\")"
  },
  {
    "objectID": "posts/2024-07-29-sigle-season-occupancy/index.html#load-packages",
    "href": "posts/2024-07-29-sigle-season-occupancy/index.html#load-packages",
    "title": "Single Season Occupancy Model",
    "section": "",
    "text": "First we load some packages\n\nCode\nlibrary(grateful) # Facilitate Citation of R Packages\nlibrary(patchwork) # The Composer of Plots\nlibrary(readxl) # Read Excel Files\nlibrary(sf) # Simple Features for R\nlibrary(mapview) # Interactive Viewing of Spatial Data in R\nlibrary(terra) # Spatial Data Analysis\nlibrary(elevatr) # Access Elevation Data from Various APIs\nlibrary(readr)\n\nlibrary(camtrapR) # Camera Trap Data Management and Preparation of Occupancy and Spatial Capture-Recapture Analyses \nlibrary(unmarked) \nlibrary(ubms) \nlibrary(DT)\n\nlibrary(kableExtra) # Construct Complex Table with 'kable' and Pipe Syntax\nlibrary(tidyverse) # Easily Install and Load the 'Tidyverse'\n\n# source(\"C:/CodigoR/CameraTrapCesar/R/organiza_datos.R\")"
  },
  {
    "objectID": "posts/2024-07-29-sigle-season-occupancy/index.html#organize-the-data",
    "href": "posts/2024-07-29-sigle-season-occupancy/index.html#organize-the-data",
    "title": "Single Season Occupancy Model",
    "section": "Organize the data",
    "text": "Organize the data\nThe workflow starts with package unmarked for organize data and continue with the package ubms for model building, selection and prediction. The first step to perform the analysis is to organize data following the unmarked package. The data should have detection, non-detection records along with the covariates.\nSee the unmarked::unmarkedFrameOccu function for details typing: ?unmarkedFrameOccu in your R console."
  },
  {
    "objectID": "posts/2024-07-29-sigle-season-occupancy/index.html#load-data",
    "href": "posts/2024-07-29-sigle-season-occupancy/index.html#load-data",
    "title": "Single Season Occupancy Model",
    "section": "Load data",
    "text": "Load data\nThe data set was collected by Sebastián Mejía-Correa and is part of the study: Mejia-Correa S, Diaz-Martinez A. 2014. Densidad y hábitos alimentarios de la danta Tapirus bairdii en el Parque Nacional Natural Los Katios, Colombia. Tapir Conservation. 23:16–23..\n\nCode\n\nkatios1 &lt;- read_excel(\"C:/CodigoR/CameraTrapCesar/data/katios/Tbairdii_sebastian.xlsx\", sheet = \"danta\")\n\n\nView the data\n\nCodedatatable(head(katios1))\n\n\n\n\n\nView as map\n\nCode# Load Katios National Park shapefile\nkatios_np &lt;- read_sf(\"C:/CodigoR/CameraTrapCesar/data/katios/shp/WDPA_WDOECM_Nov2024_Public_61610_shp-polygons.shp\")\n\n# make projection\nprojlatlon &lt;- \"+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0\"\n\nkatios_sf &lt;-  st_as_sf(x = katios1 |&gt; distinct(Longitude, Latitude, camera),\n                         coords = c(\"Longitude\", \n                                    \"Latitude\"),\n                         crs = projlatlon)\n\nmapview(katios_np, alpha.regions=0.1) + \nmapview(katios_sf, zcol=\"camera\")\n\n\nCmeras location.\n\n\nFunction to make detection history matrix\n\nCode\n\nf.matrix.creator&lt;-function(data){\n  #results object\n  res&lt;-list()\n  \n  #get the dimensions of the matrix\n  \n  #list if sanpling units\n  cams&lt;-unique(data$camera)\n  cams&lt;-sort(cams)\n  rows&lt;-length(cams)\n  species&lt;-unique(data$species)\n  #start and end dates of sampling periods\n  # data&lt;-data[data$Sampling.Period==year,]\n  min&lt;-min(as.Date(as.character(data$start), \"%Y-%m-%d\"))\n  max&lt;-max(as.Date(as.character(data$end), \"%Y-%m-%d\"))\n  cols&lt;-max-min+1\n  \n  #sampling period\n  date.header&lt;-seq(from=min,to=max, by=\"days\")\n  mat&lt;-matrix(NA,rows,cols,dimnames=list(cams,as.character(date.header)))\n  \n  #for all cameras, determine the open and close date and mark in the matrix\n  start.dates&lt;-tapply(as.character(data$start),data$camera,unique)\n  nms&lt;-names(start.dates)\n  # start.dates&lt;-ymd(start.dates)\n  names(start.dates)&lt;-nms\n  end.dates&lt;-tapply(as.character(data$end),data$camera,unique)\n  # end.dates&lt;-ymd(end.dates)\n  names(end.dates)&lt;-nms\n  \n  #outline the sampling periods for each camera j\n  for(j in 1:length(start.dates)){\n    #for each camera beginning and end of sampling\n    low&lt;-which(date.header==as.Date(as.character(start.dates[j]), format = \"%Y-%m-%d\"))\n    hi&lt;-which(date.header==as.Date(as.character(end.dates[j]), format = \"%Y-%m-%d\"))\n    if(length(low)+length(hi)&gt;0){\n      indx&lt;-seq(from=low,to=hi)\n      mat[names(start.dates)[j],indx]&lt;- 0\n    } else next\n  }\n  mat.template&lt;-mat\n  #get the species\n  #species&lt;-unique(data$bin)\n  #construct the matrix for each species i\n  for(i in 1:length(species)){\n    indx&lt;-which(data$species==species[i])\n    #dates and cameras when/where the species was photographed\n    dates&lt;-data$date[indx]\n    cameras&lt;-data$camera[indx]\n    dates.cameras&lt;-data.frame(dates,cameras)\n    #unique combination of dates and cameras \n    dates.cameras&lt;-unique(dates.cameras)\n    #fill in the matrix\n    for(j in 1:length(dates.cameras[,1])){\n      col&lt;-which(date.header==as.character( dates.cameras[j,1]))\n      row&lt;-which(cams==as.character( dates.cameras[j,2]))\n      mat[row,col]&lt;-1\n    }\n    mat.nas&lt;-is.na(mat)\n    sum.nas&lt;-apply(mat.nas,2,sum)\n    indx.nas&lt;-which(sum.nas==rows)\n    if(length(indx.nas)&gt;0){\n      mat&lt;-mat[,-indx.nas]\n    }\n    \n    res&lt;-c(res,list(mat))\n    #return the matrix to its original form\n    mat&lt;-mat.template\n  }\n  \n  names(res)&lt;-species\n  #res&lt;-lapply(res,f.dum)\n  res #object to return\n}\n\n\nApply the function to get Tapirus bairdii detection matrix\n\nCode\n# filter firs year and make uniques\n\ntbairdi &lt;- f.matrix.creator(katios1)[[1]]\n\n\nLets extract percent tree cover 2012 to be used as site covariate\nThe covariate is coming from MODIS. MOD44B Version 6 Vegetation Continuous Fields (VCF). https://lpdaac.usgs.gov/products/mod44bv006/\nWe plot the cameras as sf object on top the map and extract the values using the function terra::extract\n\nCode# load the raster map\nper_tree_cov &lt;- rast(\"C:/CodigoR/WCS-CameraTrap/raster/latlon/Veg_Cont_Fields_Yearly_250m_v61/Perc_TreeCov/MOD44B_Perc_TreeCov_2012_065.tif\")\n\n# extract values per camera\nper_tre &lt;- terra::extract(per_tree_cov, katios_sf)\n\n# assign values to the sf object\nkatios_sf$per_tree_cov &lt;- per_tre$MOD44B_Perc_TreeCov_2012_065 \n#  fix 200 issue\n# ind &lt;- which(sites$per_tree_cov== 200)\n# sites$per_tree_cov[ind] &lt;- 0"
  },
  {
    "objectID": "posts/2024-07-29-sigle-season-occupancy/index.html#create-unmarked-frame-object",
    "href": "posts/2024-07-29-sigle-season-occupancy/index.html#create-unmarked-frame-object",
    "title": "Single Season Occupancy Model",
    "section": "Create unmarked frame object",
    "text": "Create unmarked frame object\nLets use the unmarked package to make an unmarkedFrameOccu object.\n\nCodeumf &lt;- unmarkedFrameOccu(y=tbairdi, \n                         siteCovs=data.frame(\n                           per_tree_cov=katios_sf$per_tree_cov)\n                           # road_den=sites$roads),\n                         # obsCovs=list(effort=ej)\n                      )\n\nplot(umf)\n\n\n\nSites against days (observation)\n\n\nCode\nunmarked::summary(umf)\n#&gt; unmarkedFrame Object\n#&gt; \n#&gt; 27 sites\n#&gt; Maximum number of observations per site: 93 \n#&gt; Mean number of observations per site: 45.52 \n#&gt; Sites with at least one detection: 10 \n#&gt; \n#&gt; Tabulation of y observations:\n#&gt;    0    1 &lt;NA&gt; \n#&gt; 1206   23 1282 \n#&gt; \n#&gt; Site-level covariates:\n#&gt;   per_tree_cov  \n#&gt;  Min.   :66.00  \n#&gt;  1st Qu.:73.00  \n#&gt;  Median :78.00  \n#&gt;  Mean   :76.07  \n#&gt;  3rd Qu.:78.00  \n#&gt;  Max.   :80.00"
  },
  {
    "objectID": "posts/2024-07-29-sigle-season-occupancy/index.html#fit-models",
    "href": "posts/2024-07-29-sigle-season-occupancy/index.html#fit-models",
    "title": "Single Season Occupancy Model",
    "section": "Fit models",
    "text": "Fit models\nlets use ubms package to fit several models. We contrast the null model (no covariates) against a model with percent tree cover to explain the occupancy. For this example we are not using covariates for the detection part.\n\nCode# fit_0 &lt;- occu(~1~1, data=umf) # unmarked\n\nfit_j0 &lt;- stan_occu(~1~1, data=umf, chains=3, iter=100000, cores=3)\nfit_j2 &lt;- stan_occu(~1~scale(per_tree_cov), data=umf, chains=3, iter=100000, cores=3)\n\n\nModel selection\nCode# compare models\nmodels &lt;- list(\"p(.)psi(.)\" = fit_j0, # put names\n                \"p(.)psi(per_tree_cov)\" = fit_j2) # put names\n\nmods &lt;- fitList(fits = models)\n\n## see model selection as a table\ndatatable( \n  round(modSel(mods), 3)\n  )\n\nThe model p(.)psi(per_tree_cov) is the “better”.\nEstimates for the null model\nEstimated values for the null model p(.)psi(.) are: 0.4410786, 0.0438637 for occupancy, and detection probability respectively.\nDetails of the best model\n\nCodefit_j2\n#&gt; \n#&gt; Call:\n#&gt; stan_occu(formula = ~1 ~ scale(per_tree_cov), data = umf, chains = 3, \n#&gt;     iter = 1e+05, cores = 3)\n#&gt; \n#&gt; Occupancy (logit-scale):\n#&gt;                     Estimate    SD   2.5% 97.5% n_eff Rhat\n#&gt; (Intercept)           -0.403 0.583 -1.492 0.812 88523    1\n#&gt; scale(per_tree_cov)    1.336 0.707  0.154 2.919 89674    1\n#&gt; \n#&gt; Detection (logit-scale):\n#&gt;  Estimate    SD  2.5% 97.5% n_eff Rhat\n#&gt;     -3.09 0.262 -3.64 -2.62 91423    1\n#&gt; \n#&gt; LOOIC: 217.038\n#&gt; Runtime: 81.605 sec\n\n\nwe conclude MCMC chains have converged if all R&gt;1.05\nConvergence here is not that good…\nModel convergence\nLet see the chains.\n\nCodetraceplot(fit_j2, pars=c(\"beta_state\"))\n\n\n\nChains trace plot. The chains should be converging\n\n\n\nnot that good…\nEvaluate model fit\nStatistic (p) should be near 0.5 if the model fits well.\n\nCode\n# eval\nfit_top_gof &lt;- gof(fit_j2, draws=500, quiet=TRUE)\nfit_top_gof\n#&gt; MacKenzie-Bailey Chi-square \n#&gt; Point estimate = 707667614.926\n#&gt; Posterior predictive p = 0.122\n\n# plot(fit_top_gof)\n\n\n0.14 is not that bad.\nModel inference\nNo covariate for detection, and percent of forest tree cover in occupancy.\n\nCode# ubms::plot_effects(fit_j2, \"det\")\nubms::plot_effects(fit_j2, \"state\")\n\n\n\nPrediction of occupancy with percent tree cover\n\n\n\nThe error band is large but there is a clear trend.\nSpatial model\nTaking in to account spatial autocorrelation.\n\nCode# convert to UTM\nkatios_utm = st_transform(katios_sf, 21818)\nkatios_cord &lt;- st_coordinates(katios_utm)\nsite_cov &lt;- as.data.frame(cbind(per_tree_cov=scale(katios_sf$per_tree_cov),\n                  katios_cord))\n\nnames(site_cov) &lt;- c(\"per_tree_cov\", \"X\", \"Y\")\n\nwith(site_cov, RSR(X, Y, threshold=1, plot_site=27))\n\n\n\nSpatial autocorrelation.\n\n\nCode\nform &lt;- ~1 ~per_tree_cov + RSR(X, Y, threshold=1)\numf2 &lt;- unmarkedFrameOccu(y=tbairdi, siteCovs=site_cov)\n# fit_spatial &lt;- stan_occu(form, umf2, chains=3, cores=3, seed=123) # error\n\n\nSpatial model do not run… Error at Building RSR matrices: TridiagEigen: eigen decomposition failed. Probably to few sites."
  },
  {
    "objectID": "posts/2024-07-29-sigle-season-occupancy/index.html#predict-occupancy-in-a-map",
    "href": "posts/2024-07-29-sigle-season-occupancy/index.html#predict-occupancy-in-a-map",
    "title": "Single Season Occupancy Model",
    "section": "Predict occupancy in a map",
    "text": "Predict occupancy in a map\nLets use a raster map with percent tree cover to predict the occupancy and see the resulting occupancy as a map.\n\nCode# cut large raster \nbox &lt;- ext(-77.18,-77.11, 7.800, 7.89) # make a box xmin, xmax, ymin, ymax\nlibrary(raster)\nper_tree_cov_cut &lt;- raster(crop(per_tree_cov, box))# cut raster using the box\n# put correct name\nnames(per_tree_cov_cut) &lt;- \"per_tree_cov\"\n\n# predict in ubms\nmap_occupancy &lt;- ubms::predict(fit_j2,\n                               submodel=\"state\",\n                               newdata=per_tree_cov_cut,\n                               transform=TRUE)\n\nkatios_occu &lt;- map_occupancy[[1]] # assign just prediction\nkatios_occu[katios_occu &gt;= 0.9] &lt;- NA # convert river to NA\n\n# make a palette 9 colors yellow to green\npal &lt;- grDevices::colorRampPalette(RColorBrewer::brewer.pal(9, \"YlGn\"))\n# plot map\nmapview(katios_np, alpha.regions=0.1) +\nmapview(katios_occu, col.regions= pal, alpha = 0.5) + mapview(katios_sf, cex=2) \n\n\nPredicted occupancy map."
  },
  {
    "objectID": "posts/2024-07-29-sigle-season-occupancy/index.html#package-citation",
    "href": "posts/2024-07-29-sigle-season-occupancy/index.html#package-citation",
    "title": "Single Season Occupancy Model",
    "section": "Package Citation",
    "text": "Package Citation\n\nCodepkgs &lt;- cite_packages(output = \"paragraph\", out.dir = \".\") #knitr::kable(pkgs)\npkgs\n\nWe used R version 4.4.2 (R Core Team 2024) and the following R packages: camtrapR v. 2.3.0 (Niedballa et al. 2016), devtools v. 2.4.5 (Wickham et al. 2022), DT v. 0.33 (Xie, Cheng, and Tan 2024), elevatr v. 0.99.0 (Hollister et al. 2023), kableExtra v. 1.4.0 (Zhu 2024), mapview v. 2.11.2 (Appelhans et al. 2023), patchwork v. 1.3.0 (Pedersen 2024), quarto v. 1.4.4 (Allaire and Dervieux 2024), raster v. 3.6.30 (Hijmans 2024a), RColorBrewer v. 1.1.3 (Neuwirth 2022), rmarkdown v. 2.29 (Xie, Allaire, and Grolemund 2018; Xie, Dervieux, and Riederer 2020; Allaire et al. 2024), sf v. 1.0.19 (Pebesma 2018; Pebesma and Bivand 2023), styler v. 1.10.3 (Müller and Walthert 2024), terra v. 1.8.5 (Hijmans 2024b), tidyverse v. 2.0.0 (Wickham et al. 2019), ubms v. 1.2.7 (Kellner et al. 2021), unmarked v. 1.4.3 (Fiske and Chandler 2011; Kellner et al. 2023)."
  },
  {
    "objectID": "posts/2024-07-29-sigle-season-occupancy/index.html#sesion-info",
    "href": "posts/2024-07-29-sigle-season-occupancy/index.html#sesion-info",
    "title": "Single Season Occupancy Model",
    "section": "Sesion info",
    "text": "Sesion info\n\nSession info\n\n#&gt; ─ Session info ───────────────────────────────────────────────────────────────────────────────────────────────────────\n#&gt;  setting  value\n#&gt;  version  R version 4.4.2 (2024-10-31 ucrt)\n#&gt;  os       Windows 10 x64 (build 19045)\n#&gt;  system   x86_64, mingw32\n#&gt;  ui       RTerm\n#&gt;  language (EN)\n#&gt;  collate  Spanish_Colombia.utf8\n#&gt;  ctype    Spanish_Colombia.utf8\n#&gt;  tz       America/Bogota\n#&gt;  date     2024-12-15\n#&gt;  pandoc   3.2 @ C:/Program Files/RStudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n#&gt; \n#&gt; ─ Packages ───────────────────────────────────────────────────────────────────────────────────────────────────────────\n#&gt;  ! package           * version  date (UTC) lib source\n#&gt;    abind               1.4-8    2024-09-12 [1] CRAN (R 4.4.1)\n#&gt;    backports           1.5.0    2024-05-23 [1] CRAN (R 4.4.0)\n#&gt;    base64enc           0.1-3    2015-07-28 [1] CRAN (R 4.4.0)\n#&gt;    brew                1.0-10   2023-12-16 [1] CRAN (R 4.4.2)\n#&gt;    bslib               0.8.0    2024-07-29 [1] CRAN (R 4.4.2)\n#&gt;    cachem              1.1.0    2024-05-16 [1] CRAN (R 4.4.2)\n#&gt;    camtrapR          * 2.3.0    2024-02-26 [1] CRAN (R 4.4.2)\n#&gt;    cellranger          1.1.0    2016-07-27 [1] CRAN (R 4.4.2)\n#&gt;    checkmate           2.3.2    2024-07-29 [1] CRAN (R 4.4.2)\n#&gt;    class               7.3-22   2023-05-03 [2] CRAN (R 4.4.2)\n#&gt;    classInt            0.4-10   2023-09-05 [1] CRAN (R 4.4.2)\n#&gt;    cli                 3.6.3    2024-06-21 [1] CRAN (R 4.4.2)\n#&gt;    codetools           0.2-20   2024-03-31 [2] CRAN (R 4.4.2)\n#&gt;    colorspace          2.1-1    2024-07-26 [1] CRAN (R 4.4.2)\n#&gt;    crosstalk           1.2.1    2023-11-23 [1] CRAN (R 4.4.2)\n#&gt;    curl                6.0.0    2024-11-05 [1] CRAN (R 4.4.2)\n#&gt;    data.table          1.16.4   2024-12-06 [1] CRAN (R 4.4.2)\n#&gt;    DBI                 1.2.3    2024-06-02 [1] CRAN (R 4.4.2)\n#&gt;    devtools            2.4.5    2022-10-11 [1] CRAN (R 4.4.2)\n#&gt;    digest              0.6.37   2024-08-19 [1] CRAN (R 4.4.2)\n#&gt;    distributional      0.5.0    2024-09-17 [1] CRAN (R 4.4.2)\n#&gt;    dplyr             * 1.1.4    2023-11-17 [1] CRAN (R 4.4.2)\n#&gt;    DT                * 0.33     2024-04-04 [1] CRAN (R 4.4.2)\n#&gt;    e1071               1.7-16   2024-09-16 [1] CRAN (R 4.4.2)\n#&gt;    elevatr           * 0.99.0   2023-09-12 [1] CRAN (R 4.4.2)\n#&gt;    ellipsis            0.3.2    2021-04-29 [1] CRAN (R 4.4.2)\n#&gt;    evaluate            1.0.1    2024-10-10 [1] CRAN (R 4.4.2)\n#&gt;    fansi               1.0.6    2023-12-08 [1] CRAN (R 4.4.2)\n#&gt;    farver              2.1.2    2024-05-13 [1] CRAN (R 4.4.2)\n#&gt;    fastmap             1.2.0    2024-05-15 [1] CRAN (R 4.4.2)\n#&gt;    forcats           * 1.0.0    2023-01-29 [1] CRAN (R 4.4.2)\n#&gt;    fs                  1.6.5    2024-10-30 [1] CRAN (R 4.4.2)\n#&gt;    generics            0.1.3    2022-07-05 [1] CRAN (R 4.4.2)\n#&gt;    ggplot2           * 3.5.1    2024-04-23 [1] CRAN (R 4.4.2)\n#&gt;    glue                1.8.0    2024-09-30 [1] CRAN (R 4.4.2)\n#&gt;    grateful          * 0.2.10   2024-09-04 [1] CRAN (R 4.4.2)\n#&gt;    gridExtra           2.3      2017-09-09 [1] CRAN (R 4.4.2)\n#&gt;    gtable              0.3.6    2024-10-25 [1] CRAN (R 4.4.2)\n#&gt;    hms                 1.1.3    2023-03-21 [1] CRAN (R 4.4.2)\n#&gt;    htmltools           0.5.8.1  2024-04-04 [1] CRAN (R 4.4.2)\n#&gt;    htmlwidgets         1.6.4    2023-12-06 [1] CRAN (R 4.4.2)\n#&gt;    httpuv              1.6.15   2024-03-26 [1] CRAN (R 4.4.2)\n#&gt;    inline              0.3.20   2024-11-10 [1] CRAN (R 4.4.2)\n#&gt;    jquerylib           0.1.4    2021-04-26 [1] CRAN (R 4.4.2)\n#&gt;    jsonlite            1.8.9    2024-09-20 [1] CRAN (R 4.4.2)\n#&gt;    kableExtra        * 1.4.0    2024-01-24 [1] CRAN (R 4.4.2)\n#&gt;    KernSmooth          2.23-24  2024-05-17 [2] CRAN (R 4.4.2)\n#&gt;    knitr               1.49     2024-11-08 [1] CRAN (R 4.4.2)\n#&gt;    labeling            0.4.3    2023-08-29 [1] CRAN (R 4.4.0)\n#&gt;    later               1.3.2    2023-12-06 [1] CRAN (R 4.4.2)\n#&gt;    lattice             0.22-6   2024-03-20 [2] CRAN (R 4.4.2)\n#&gt;    leafem              0.2.3    2023-09-17 [1] CRAN (R 4.4.2)\n#&gt;    leaflet             2.2.2    2024-03-26 [1] CRAN (R 4.4.2)\n#&gt;    leaflet.providers   2.0.0    2023-10-17 [1] CRAN (R 4.4.2)\n#&gt;    leafpop             0.1.0    2021-05-22 [1] CRAN (R 4.4.2)\n#&gt;    lifecycle           1.0.4    2023-11-07 [1] CRAN (R 4.4.2)\n#&gt;    loo                 2.8.0    2024-07-03 [1] CRAN (R 4.4.2)\n#&gt;    lubridate         * 1.9.4    2024-12-08 [1] CRAN (R 4.4.2)\n#&gt;    magrittr            2.0.3    2022-03-30 [1] CRAN (R 4.4.2)\n#&gt;    mapview           * 2.11.2   2023-10-13 [1] CRAN (R 4.4.2)\n#&gt;    MASS                7.3-61   2024-06-13 [2] CRAN (R 4.4.2)\n#&gt;    Matrix              1.7-1    2024-10-18 [2] CRAN (R 4.4.2)\n#&gt;    matrixStats         1.4.1    2024-09-08 [1] CRAN (R 4.4.2)\n#&gt;    memoise             2.0.1    2021-11-26 [1] CRAN (R 4.4.2)\n#&gt;    mgcv                1.9-1    2023-12-21 [2] CRAN (R 4.4.2)\n#&gt;    mime                0.12     2021-09-28 [1] CRAN (R 4.4.0)\n#&gt;    miniUI              0.1.1.1  2018-05-18 [1] CRAN (R 4.4.2)\n#&gt;    munsell             0.5.1    2024-04-01 [1] CRAN (R 4.4.2)\n#&gt;    mvtnorm             1.3-2    2024-11-04 [1] CRAN (R 4.4.2)\n#&gt;    nlme                3.1-166  2024-08-14 [2] CRAN (R 4.4.2)\n#&gt;    patchwork         * 1.3.0    2024-09-16 [1] CRAN (R 4.4.2)\n#&gt;    pbapply             1.7-2    2023-06-27 [1] CRAN (R 4.4.2)\n#&gt;    pillar              1.9.0    2023-03-22 [1] CRAN (R 4.4.2)\n#&gt;    pkgbuild            1.4.5    2024-10-28 [1] CRAN (R 4.4.2)\n#&gt;    pkgconfig           2.0.3    2019-09-22 [1] CRAN (R 4.4.2)\n#&gt;    pkgload             1.4.0    2024-06-28 [1] CRAN (R 4.4.2)\n#&gt;    png                 0.1-8    2022-11-29 [1] CRAN (R 4.4.0)\n#&gt;    posterior           1.6.0    2024-07-03 [1] CRAN (R 4.4.2)\n#&gt;    processx            3.8.4    2024-03-16 [1] CRAN (R 4.4.2)\n#&gt;    profvis             0.4.0    2024-09-20 [1] CRAN (R 4.4.2)\n#&gt;    progressr           0.15.0   2024-10-29 [1] CRAN (R 4.4.2)\n#&gt;    promises            1.3.0    2024-04-05 [1] CRAN (R 4.4.2)\n#&gt;    proxy               0.4-27   2022-06-09 [1] CRAN (R 4.4.2)\n#&gt;    ps                  1.8.1    2024-10-28 [1] CRAN (R 4.4.2)\n#&gt;    purrr             * 1.0.2    2023-08-10 [1] CRAN (R 4.4.2)\n#&gt;    quarto            * 1.4.4    2024-07-20 [1] CRAN (R 4.4.2)\n#&gt;    QuickJSR            1.4.0    2024-10-01 [1] CRAN (R 4.4.2)\n#&gt;    R.cache             0.16.0   2022-07-21 [1] CRAN (R 4.4.2)\n#&gt;    R.methodsS3         1.8.2    2022-06-13 [1] CRAN (R 4.4.0)\n#&gt;    R.oo                1.27.0   2024-11-01 [1] CRAN (R 4.4.1)\n#&gt;    R.utils             2.12.3   2023-11-18 [1] CRAN (R 4.4.2)\n#&gt;    R6                  2.5.1    2021-08-19 [1] CRAN (R 4.4.2)\n#&gt;    raster            * 3.6-30   2024-10-02 [1] CRAN (R 4.4.2)\n#&gt;    rbibutils           2.3      2024-10-04 [1] CRAN (R 4.4.2)\n#&gt;    RColorBrewer        1.1-3    2022-04-03 [1] CRAN (R 4.4.0)\n#&gt;    Rcpp                1.0.13-1 2024-11-02 [1] CRAN (R 4.4.2)\n#&gt;    RcppNumerical       0.6-0    2023-09-06 [1] CRAN (R 4.4.2)\n#&gt;  D RcppParallel        5.1.9    2024-08-19 [1] CRAN (R 4.4.2)\n#&gt;    Rdpack              2.6.2    2024-11-15 [1] CRAN (R 4.4.2)\n#&gt;    readr             * 2.1.5    2024-01-10 [1] CRAN (R 4.4.2)\n#&gt;    readxl            * 1.4.3    2023-07-06 [1] CRAN (R 4.4.2)\n#&gt;    reformulas          0.4.0    2024-11-03 [1] CRAN (R 4.4.2)\n#&gt;    remotes             2.5.0    2024-03-17 [1] CRAN (R 4.4.2)\n#&gt;    renv                1.0.11   2024-10-12 [1] CRAN (R 4.4.2)\n#&gt;    rlang               1.1.4    2024-06-04 [1] CRAN (R 4.4.2)\n#&gt;    rmarkdown           2.29     2024-11-04 [1] CRAN (R 4.4.2)\n#&gt;    RSpectra            0.16-2   2024-07-18 [1] CRAN (R 4.4.2)\n#&gt;    rstan               2.32.6   2024-03-05 [1] CRAN (R 4.4.2)\n#&gt;    rstantools          2.4.0    2024-01-31 [1] CRAN (R 4.4.2)\n#&gt;    rstudioapi          0.17.1   2024-10-22 [1] CRAN (R 4.4.2)\n#&gt;    sass                0.4.9    2024-03-15 [1] CRAN (R 4.4.2)\n#&gt;    satellite           1.0.5    2024-02-10 [1] CRAN (R 4.4.2)\n#&gt;    scales              1.3.0    2023-11-28 [1] CRAN (R 4.4.2)\n#&gt;    secr                5.1.0    2024-11-04 [1] CRAN (R 4.4.2)\n#&gt;    sessioninfo         1.2.2    2021-12-06 [1] CRAN (R 4.4.2)\n#&gt;    sf                * 1.0-19   2024-11-05 [1] CRAN (R 4.4.2)\n#&gt;    shiny               1.9.1    2024-08-01 [1] CRAN (R 4.4.2)\n#&gt;    sp                * 2.1-4    2024-04-30 [1] CRAN (R 4.4.2)\n#&gt;    StanHeaders         2.32.10  2024-07-15 [1] CRAN (R 4.4.2)\n#&gt;    stringi             1.8.4    2024-05-06 [1] CRAN (R 4.4.0)\n#&gt;    stringr           * 1.5.1    2023-11-14 [1] CRAN (R 4.4.2)\n#&gt;    styler            * 1.10.3   2024-04-07 [1] CRAN (R 4.4.2)\n#&gt;    svglite             2.1.3    2023-12-08 [1] CRAN (R 4.4.2)\n#&gt;    systemfonts         1.1.0    2024-05-15 [1] CRAN (R 4.4.2)\n#&gt;    tensorA             0.36.2.1 2023-12-13 [1] CRAN (R 4.4.0)\n#&gt;    terra             * 1.8-5    2024-12-12 [1] CRAN (R 4.4.2)\n#&gt;    tibble            * 3.2.1    2023-03-20 [1] CRAN (R 4.4.2)\n#&gt;    tidyr             * 1.3.1    2024-01-24 [1] CRAN (R 4.4.2)\n#&gt;    tidyselect          1.2.1    2024-03-11 [1] CRAN (R 4.4.2)\n#&gt;    tidyverse         * 2.0.0    2023-02-22 [1] CRAN (R 4.4.2)\n#&gt;    timechange          0.3.0    2024-01-18 [1] CRAN (R 4.4.2)\n#&gt;    tzdb                0.4.0    2023-05-12 [1] CRAN (R 4.4.2)\n#&gt;    ubms              * 1.2.7    2024-10-01 [1] CRAN (R 4.4.2)\n#&gt;    units               0.8-5    2023-11-28 [1] CRAN (R 4.4.2)\n#&gt;    unmarked          * 1.4.3    2024-09-01 [1] CRAN (R 4.4.2)\n#&gt;    urlchecker          1.0.1    2021-11-30 [1] CRAN (R 4.4.2)\n#&gt;    usethis             3.0.0    2024-07-29 [1] CRAN (R 4.4.1)\n#&gt;    utf8                1.2.4    2023-10-22 [1] CRAN (R 4.4.2)\n#&gt;    uuid                1.2-1    2024-07-29 [1] CRAN (R 4.4.1)\n#&gt;    V8                  6.0.0    2024-10-12 [1] CRAN (R 4.4.2)\n#&gt;    vctrs               0.6.5    2023-12-01 [1] CRAN (R 4.4.2)\n#&gt;    viridisLite         0.4.2    2023-05-02 [1] CRAN (R 4.4.2)\n#&gt;    withr               3.0.2    2024-10-28 [1] CRAN (R 4.4.2)\n#&gt;    xfun                0.49     2024-10-31 [1] CRAN (R 4.4.2)\n#&gt;    xml2                1.3.6    2023-12-04 [1] CRAN (R 4.4.2)\n#&gt;    xtable              1.8-4    2019-04-21 [1] CRAN (R 4.4.2)\n#&gt;    yaml                2.3.10   2024-07-26 [1] CRAN (R 4.4.1)\n#&gt; \n#&gt;  [1] C:/Users/usuario/AppData/Local/R/win-library/4.4\n#&gt;  [2] C:/Program Files/R/R-4.4.2/library\n#&gt; \n#&gt;  D ── DLL MD5 mismatch, broken installation.\n#&gt; \n#&gt; ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/2024-12-15-riqueza/index.html",
    "href": "posts/2024-12-15-riqueza/index.html",
    "title": "Riqueza de especies",
    "section": "",
    "text": "Hay dos formas de uso común para tener en cuenta el esfuerzo de muestreo al estimar la riqueza de especies mediante cámaras trampa:\n\nUtilizando la rarefacción de la riqueza observada.\nUtilizando modelos de ocupación multiespecie para tener en cuenta las especies presentes pero no observadas (teniendo en cuenta la detección imperfecta).\n\nEn este post podemos ver un ejemplo del número 1 utilizando el enfoque clásico de la ecología de comunidades usando el paquete vegan. El paquete vegan (https://cran.r-project.org/package=vegan) proporciona herramientas para describir la ecología de las comunidades. Este paquete tiene funciones básicas de análisis de diversidad, ordenación de comunidades y análisis de disimilitud. El paquete vegan proporciona la mayoría de las herramientas estándar para el análisis descriptivo de comunidades principalmente de comunidades vegetales, pero sus conceptos tambien pueden ser aplicados a la fauna. Más adelante en este post realizamos otro análisis de diversidad utilizando algunas funciones del paquete iNEXT.\nEl enfoque moderno para medir la diversidad de especies incluye los “numeros de Hill”. La rarefacción y la extrapolación con números de Hill han ganado popularidad en la última década y se pueden calcular utilizando la función renyi en el paquete vegan (Oksanen 2016) y la función rarity en el paquete MeanRarity (Roswell y Dushoff 2020), y las diversidades de Hill de muestras de igual tamaño o igual cobertura se pueden comparar utilizando las funciones iNEXT y estimateD del paquete iNEXT (Hsieh et al. 2016). Las estimaciones para valores asintóticos de diversidad de Hill están tambien disponibles en el paquete SpadeR (Chao y Jost 2015, Chao et al. 2015)."
  },
  {
    "objectID": "posts/2024-12-15-riqueza/index.html#riqueza-de-especies-y-esfuerzo-de-muestreo",
    "href": "posts/2024-12-15-riqueza/index.html#riqueza-de-especies-y-esfuerzo-de-muestreo",
    "title": "Riqueza de especies",
    "section": "",
    "text": "Hay dos formas de uso común para tener en cuenta el esfuerzo de muestreo al estimar la riqueza de especies mediante cámaras trampa:\n\nUtilizando la rarefacción de la riqueza observada.\nUtilizando modelos de ocupación multiespecie para tener en cuenta las especies presentes pero no observadas (teniendo en cuenta la detección imperfecta).\n\nEn este post podemos ver un ejemplo del número 1 utilizando el enfoque clásico de la ecología de comunidades usando el paquete vegan. El paquete vegan (https://cran.r-project.org/package=vegan) proporciona herramientas para describir la ecología de las comunidades. Este paquete tiene funciones básicas de análisis de diversidad, ordenación de comunidades y análisis de disimilitud. El paquete vegan proporciona la mayoría de las herramientas estándar para el análisis descriptivo de comunidades principalmente de comunidades vegetales, pero sus conceptos tambien pueden ser aplicados a la fauna. Más adelante en este post realizamos otro análisis de diversidad utilizando algunas funciones del paquete iNEXT.\nEl enfoque moderno para medir la diversidad de especies incluye los “numeros de Hill”. La rarefacción y la extrapolación con números de Hill han ganado popularidad en la última década y se pueden calcular utilizando la función renyi en el paquete vegan (Oksanen 2016) y la función rarity en el paquete MeanRarity (Roswell y Dushoff 2020), y las diversidades de Hill de muestras de igual tamaño o igual cobertura se pueden comparar utilizando las funciones iNEXT y estimateD del paquete iNEXT (Hsieh et al. 2016). Las estimaciones para valores asintóticos de diversidad de Hill están tambien disponibles en el paquete SpadeR (Chao y Jost 2015, Chao et al. 2015)."
  },
  {
    "objectID": "posts/2024-12-15-riqueza/index.html#cargar-paquetes",
    "href": "posts/2024-12-15-riqueza/index.html#cargar-paquetes",
    "title": "Riqueza de especies",
    "section": "Cargar Paquetes",
    "text": "Cargar Paquetes\n\nCode\n\nlibrary(patchwork) # The Composer of Plots\nlibrary(readxl) # Read Excel Files\nlibrary(sf) # Simple Features for R\nlibrary(elevatr) # Access Elevation Data from Various APIs\nlibrary(mapview) # Interactive Viewing of Spatial Data in R\nlibrary(tmap) # nice maps in R\nlibrary(eks) # make countours\nlibrary(grateful) # Facilitate Citation of R Packages\nlibrary(camtrapR) # Camera Trap Data Management and Preparation of Occupancy and Spatial Capture-Recapture Analyses\nlibrary(vegan) # Community Ecology Package \nlibrary(ggvegan) # vegan adaptation for ggplot\n# library(BiodiversityR) # cause error!\nlibrary(ggordiplots)\nlibrary(grid)\nlibrary(gridExtra)\nlibrary(DT) # tablas en R\nlibrary(MeanRarity)\nlibrary(SpadeR)\nlibrary(iNEXT) # Interpolation and Extrapolation for Species Diversity\nlibrary(knitr) # A General-Purpose Package for Dynamic Report Generation in R\nlibrary(kableExtra) # Construct Complex Table with 'kable' and Pipe Syntax\nlibrary(tidyverse) # Easily Install and Load the 'Tidyverse'\nlibrary(ggforce) # Accelerating 'ggplot2'\nlibrary(plotly)"
  },
  {
    "objectID": "posts/2024-12-15-riqueza/index.html#cargar-los-datos",
    "href": "posts/2024-12-15-riqueza/index.html#cargar-los-datos",
    "title": "Riqueza de especies",
    "section": "Cargar los Datos",
    "text": "Cargar los Datos\n\nCode\ndatos &lt;- read_excel(\"C:/CodigoR/CameraTrapCesar/data/CT_CESAR_editada2025.xlsx\",\n    sheet = \"ImageData\")\n\n# habitat types extracted from Copernicus\nhabs &lt;- read.csv(\"C:/CodigoR/CameraTrapCesar/data/habitats.csv\")"
  },
  {
    "objectID": "posts/2024-12-15-riqueza/index.html#agrupación-de-varios-sitios",
    "href": "posts/2024-12-15-riqueza/index.html#agrupación-de-varios-sitios",
    "title": "Riqueza de especies",
    "section": "Agrupación de varios sitios",
    "text": "Agrupación de varios sitios\nPara este ejemplo usaremos datos de la Fundación Galictis y la Fundación Carboandes, que fueron tomados en varias localidade de la Serrania del Perija. En este caso seleccioné un año para los sitios: Becerril 2021 y LaPaz_Manaure 2019. Algunas veces, necesitamos crear códigos únicos por cámara y una tabla que relaciona las fechas de operacion de cada camara, Sin embargo, este no fue el caso.\nPara este ejemplo, usamos el tipo de hábitat donde se instaló la cámara como una categoria para comparar el esfuerzo de muestreo (número de cámaras) por tipo de hábitat. El tipo de hábitat se extrajo superponiendo los puntos de la cámara sobre el conjunto de datos global de cobertura terrestre de 100 m de COPERNICUS utilizando el Google Earth Engine conectado a R. Cómo hacer esto se explicará en otra publicación.\n\nCode# make a new column Station\n# datos_PCF &lt;- datos |&gt; dplyr::filter(Proyecto==\"CT_LaPaz_Manaure\") |&gt; unite (\"Station\", ProyectoEtapa:Salida:CT, sep = \"-\")\n\n# fix dates\ndatos$Start &lt;- as.Date(datos$EM_Inicio, \"%d/%m/%Y\") #start camera trap\ndatos$End &lt;- as.Date(datos$EM_Fin, \"%d/%m/%Y\") # end camera trap\ndatos$eventDate &lt;- as.Date(datos$eventDate_correjido, \"%d/%m/%Y\")\ndatos$eventDateTime &lt;- ymd_hms(paste(datos$eventDate, \" \",\n                              datos$eventTime4_Final, \":00\", sep=\"\"))\n\n# filter Becerril\ndatos_Becerril &lt;- datos |&gt; dplyr::filter(Proyecto==\"Becerril\") |&gt; mutate (Station=ID_GEO) |&gt; mutate(Year= year(eventDate)) |&gt; filter(Year==2021)\n\n# filter LaPaz_Manaure\ndatos_LaPaz_Manaure&lt;- datos |&gt; dplyr::filter(Proyecto==\"LaPaz_Manaure\") |&gt; mutate (Station=ID_GEO) |&gt; mutate(Year= year(eventDate)) |&gt; filter(Year==2019)\n\n# filter MLJ\n# datos_MLJ &lt;- datos |&gt; dplyr::filter(ProyectoEtapa==\"MLJ_TH_TS_2021\") |&gt; mutate (Station=IdGeo)\n\n# filter CL\n#datos_CL1 &lt;- datos |&gt; dplyr::filter(ProyectoEtapa==\"CL-TH2022\") |&gt; mutate (Station=IdGeo)\n# filter CL\n#datos_CL2 &lt;- datos |&gt; dplyr::filter(ProyectoEtapa==\"CL-TS2022\") |&gt; mutate (Station=IdGeo)\n\n# filter PCF\n#datos_PCF &lt;- datos |&gt; dplyr::filter(Proyecto==\"PCF\") |&gt; mutate (Station=IdGeo)\n\ndata_south &lt;- rbind(datos_LaPaz_Manaure, datos_Becerril) #, datos_MLJ,datos_CL1, datos_CL2,datos_PCF)\n\n# group and  and make uniques\nCToperation  &lt;- data_south |&gt; \n              # filter(Year==2021) |&gt; \n              group_by(Station) |&gt; \n              mutate(minStart=min(Start), maxEnd=max(End)) |&gt;  distinct(Lon, Lat, minStart, maxEnd, Year) |&gt; \n  ungroup()"
  },
  {
    "objectID": "posts/2024-12-15-riqueza/index.html#generar-la-tabla-cameraoperation-y-realizar-las-historias-de-detección-para-todas-las-especies",
    "href": "posts/2024-12-15-riqueza/index.html#generar-la-tabla-cameraoperation-y-realizar-las-historias-de-detección-para-todas-las-especies",
    "title": "Riqueza de especies",
    "section": "Generar la tabla cameraOperation y realizar las historias de detección para todas las especies",
    "text": "Generar la tabla cameraOperation y realizar las historias de detección para todas las especies\nEl paquete CamtrapR tiene la función cameraOperation que realiza una tabla de cámaras (estaciones) y fechas (setup, puck-up), esta tabla es la clave para generar las historias de detección utilizando la función detectionHistory en el siguiente paso. Para simplificar la matriz y facilitar la convergencia del modelo estamos colapsando los datos a 7 dias.\n\nCode# Generamos la matríz de operación de las cámaras\n\ncamop &lt;- cameraOperation(CTtable= CToperation, # Tabla de operación\n                         stationCol= \"Station\", # Columna que define la estación\n                         setupCol= \"minStart\", #Columna fecha de colocación\n                         retrievalCol= \"maxEnd\", #Columna fecha de retiro\n                         #hasProblems= T, # Hubo fallos de cámaras\n                         dateFormat= \"%Y-%m-%d\") #, # Formato de las fechas\n                         #cameraCol=\"CT\")\n                         # sessionCol= \"Year\")\n\n# Generar las historias de detección ---------------------------------------\n## remove problem species\nind &lt;- which(data_south$Species==\"Leopardus sp.\")\ndata_south &lt;- data_south[-ind,]\n# ind &lt;- which(data_south$Species==\"Hydrochoerus isthmius\")\n# data_south &lt;- data_south[-ind,]\n\n\nDetHist_list &lt;- lapply(unique(data_south$Species), FUN = function(x) {\n  detectionHistory(\n    recordTable         = data_south, # Tabla de registros\n    camOp                = camop, # Matriz de operación de cámaras\n    stationCol           = \"Station\",\n    speciesCol           = \"Species\",\n    recordDateTimeCol    = \"eventDateTime\",\n    recordDateTimeFormat  = \"%Y-%m-%d\",\n    species              = x,     # la función reemplaza x por cada una de las especies\n    occasionLength       = 7, # Colapso de las historias a 10 días\n    day1                 = \"station\", # (\"survey\"),or #inicia en la fecha de cada station\n    datesAsOccasionNames = FALSE,\n    includeEffort        = TRUE,\n    scaleEffort          = FALSE,\n    output               = (\"binary\"), # (\"binary\") or (\"count\")\n    #unmarkedMultFrameInput=TRUE\n    timeZone             = \"America/Bogota\" \n    )\n  }\n)\n\n# put names to the species \nnames(DetHist_list) &lt;- unique(data_south$Species)\n\n# Finally we make a new list to put all the detection histories.\nylist &lt;- lapply(DetHist_list, FUN = function(x) x$detection_history)"
  },
  {
    "objectID": "posts/2024-12-15-riqueza/index.html#usemos-los-historiales-de-detección-para-crear-una-matriz-para-vegan-y-la-matriz-de-incidencia-para-inext.",
    "href": "posts/2024-12-15-riqueza/index.html#usemos-los-historiales-de-detección-para-crear-una-matriz-para-vegan-y-la-matriz-de-incidencia-para-inext.",
    "title": "Riqueza de especies",
    "section": "Usemos los historiales de detección para crear una matriz para vegan y la matriz de incidencia para iNEXT.",
    "text": "Usemos los historiales de detección para crear una matriz para vegan y la matriz de incidencia para iNEXT.\nLas curvas de acumulación de especies, creadas con el paquete vegan, representan gráficamente el aumento de la riqueza de especies a medida que se añaden mas unidades de muestreo. Si la curva se estabiliza (se aplana o alcanza una asintota), esto indica que se ha muestreado la mayoría de las especies en el sitio de muestreo (en este caso la cámara o tipo de hábitat).\nPrimero creamos una matriz para vegan y luego modificamos la matriz para crear la matriz de incidencias que se usa en el paquete iNEXT, la cual es una lista.\n\nCode# loop to make vegan matrix\nmat_vegan &lt;- matrix(NA, dim(ylist[[1]])[1], length(unique(data_south$Species)))\nfor(i in 1:length(unique(data_south$Species))){\n  mat_vegan[,i] &lt;- apply(ylist[[i]], 1, sum, na.rm=TRUE)\n  mat_vegan[,i] &lt;- tidyr::replace_na(mat_vegan[,i], 0) # replace na with 0\n}\n\ncolnames(mat_vegan)  &lt;- unique(data_south$Species)\nrownames(mat_vegan) &lt;- rownames(ylist[[1]])\n\nmat_vegan2 &lt;- as.data.frame(mat_vegan)\nmat_vegan2$hab &lt;- habs$hab_code[1:41]\n# mat_vegan3 &lt;-  mat_vegan2 |&gt; \n  \n# ver la estructura de la matriz\ndatatable(head(mat_vegan))\n\n\n\n\nCode\n# Select specific rows by row numbers\nclosed_forest_rows &lt;- which(mat_vegan2$hab==\"closed_forest_evergreen_broad\")\n# herbaceous_rows &lt;- which(mat_vegan2$hab==\"herbaceous_wetland\")\nherbs_rows &lt;- which(mat_vegan2$hab==\"herbs\")\nopen_forest_rows &lt;- which(mat_vegan2$hab==\"open_forest_evergreen_broad\")\n# open_forest2_rows &lt;- which(mat_vegan2$hab==\"open_forest_other\")\n\n\nclosed_forest &lt;- apply(mat_vegan2[closed_forest_rows,1:22], MARGIN = 2, sum)\n# herbaceous_wetland &lt;- apply(mat_vegan2[herbaceous_rows,1:22], MARGIN = 2, sum)\nherbs  &lt;- apply(mat_vegan2[herbs_rows,1:22], MARGIN = 2, sum)\nopen_forest_evergreen &lt;- apply(mat_vegan2[open_forest_rows,1:22], MARGIN = 2, sum)\n# open_forest_other &lt;- apply(mat_vegan2[open_forest2_rows,1:22], MARGIN = 2, sum)\n\n# tb_sp &lt;- mat_vegan2 |&gt; group_by(hab)\n# hab_list &lt;- group_split(tb_sp)\n\n# make list of dataframes per habitat\nsp_by_hab &lt;- mat_vegan2 |&gt; dplyr::group_by(hab) %&gt;% split (.$hab)\n# arrange abundance (detection frecuency) mat for INEXT \ncesar_sp &lt;- t(rbind(\nt(colSums(sp_by_hab[[1]][,1:29])),\nt(colSums(sp_by_hab[[2]][,1:29])),\nt(colSums(sp_by_hab[[3]][,1:29]))\n# t(colSums(sp_by_hab[[4]][,1:30])),\n# t(colSums(sp_by_hab[[5]][,1:30]))\n))\n \ncolnames(cesar_sp) &lt;- names(sp_by_hab)\n\n\n\n# function to Format data to incidence and use iNext\nf_incidences &lt;- function(habitat_rows=closed_forest_rows){ylist %&gt;%  # historias de detection\n  map(~rowSums(.,na.rm = T)) %&gt;% # sumo las detecciones en cada sitio\n  reduce(cbind) %&gt;% # unimos las listas\n  as_data_frame() %&gt;% #formato dataframe\n  filter(row_number() %in% habitat_rows) |&gt; \n  t() %&gt;% # trasponer la tabla\n  as_tibble() %&gt;% #formato tibble\n  mutate_if(is.numeric,~(.&gt;=1)*1) %&gt;%  #como es incidencia, formateo a 1 y 0\n  rowSums() %&gt;%  # ahora si la suma de las incidencias en cada sitio\n  sort(decreasing=T) |&gt; \n  as_tibble() %&gt;% \n  add_row(value= length(habitat_rows), .before = 1) %&gt;%  # requiere que el primer valor sea el número de sitios\n  filter(!if_any()==0) |&gt;  # filter ceros\n  as.matrix() # Requiere formato de matriz\n}\n\n# Make incidence frequency table (is a list whit 5 habitats)\n# Make an empty list to store our data\nincidence_cesar &lt;- list() \nincidence_cesar[[1]] &lt;- f_incidences(closed_forest_rows)\n# incidence_cesar[[2]] &lt;- f_incidences(herbaceous_rows)\nincidence_cesar[[2]] &lt;- f_incidences(herbs_rows)\nincidence_cesar[[3]] &lt;- f_incidences(open_forest_rows)\n# incidence_cesar[[5]] &lt;- f_incidences(open_forest_other)\n\n# put names\nnames(incidence_cesar) &lt;- names(sp_by_hab)\n\n# we deleted this habitat type for making error\nincidence_cesar &lt;- within(incidence_cesar, rm(\"herbaceous_wetland\")) \n\n# ver la estructura de la matriz de incidencias\nstr(incidence_cesar)\n#&gt; List of 3\n#&gt;  $ closed_forest_evergreen_broad: num [1:28, 1] 20 15 11 9 8 8 7 6 6 6 ...\n#&gt;   ..- attr(*, \"dimnames\")=List of 2\n#&gt;   .. ..$ : NULL\n#&gt;   .. ..$ : chr \"value\"\n#&gt;  $ herbs                        : num [1:22, 1] 17 10 10 8 8 7 7 7 5 4 ...\n#&gt;   ..- attr(*, \"dimnames\")=List of 2\n#&gt;   .. ..$ : NULL\n#&gt;   .. ..$ : chr \"value\"\n#&gt;  $ open_forest_evergreen_broad  : num [1:14, 1] 4 4 4 3 2 2 1 1 1 1 ...\n#&gt;   ..- attr(*, \"dimnames\")=List of 2\n#&gt;   .. ..$ : NULL\n#&gt;   .. ..$ : chr \"value\""
  },
  {
    "objectID": "posts/2024-12-15-riqueza/index.html#para-comenzar-graficaremos-las-especies-versus-los-sitios",
    "href": "posts/2024-12-15-riqueza/index.html#para-comenzar-graficaremos-las-especies-versus-los-sitios",
    "title": "Riqueza de especies",
    "section": "Para comenzar, graficaremos las especies versus los sitios",
    "text": "Para comenzar, graficaremos las especies versus los sitios\n\nCode# Transpose if needed to have sample site names on rows\nabund_table&lt;-mat_vegan\n# Convert to relative frequencies\nabund_table &lt;- abund_table/rowSums(abund_table)\nlibrary(reshape2)\ndf&lt;-melt(abund_table)\ncolnames(df)&lt;-c(\"Sampled_site\",\"Species\",\"Value\")\nlibrary(plyr)\nlibrary(scales)\n \n# We are going to apply transformation to our data to make it\n# easier on eyes \n \n#df&lt;-ddply(df,.(Samples),transform,rescale=scale(Value))\ndf&lt;-ddply(df,.(Sampled_site),transform,rescale=sqrt(Value))\n \n# Plot heatmap\np &lt;- ggplot(df, aes(Species, Sampled_site)) + \n  geom_tile(aes(fill = rescale),colour = \"white\") + \n  scale_fill_gradient(low = \"white\",high = \"#1E5A8C\")+\n  scale_x_discrete(expand = c(0, 0)) +\n  scale_y_discrete(expand = c(0, 0)) + theme(legend.position = \"none\",axis.ticks = element_blank(),axis.text.x = element_text(angle = 90, hjust = 1,size=6),axis.text.y = element_text(size=4))\n\n# ggplotly(p) # see interactive\n# View the plot\np\n\n\n\n\n\n\n\n\nObserve cómo algunas cámaras no registraron ninguna especie. Aquí se muestra como la línea horizontal gis. Tal vez debamos eliminar esas cámaras."
  },
  {
    "objectID": "posts/2024-12-15-riqueza/index.html#rarefacción-usando-vegan",
    "href": "posts/2024-12-15-riqueza/index.html#rarefacción-usando-vegan",
    "title": "Riqueza de especies",
    "section": "Rarefacción usando vegan\n",
    "text": "Rarefacción usando vegan\n\n\nTenga en cuenta que los sitios son cámaras y la acumulación es de especies por cámara, no de tiempo.\n\nLa rarefacción es una técnica para evaluar la riqueza de especies esperada. La rarefacción permite calcular la riqueza de especies para un número determinado de muestras individuales, basándose en la construcción de curvas de rarefacción.\nEl problema que se produce al muestrear varias especies en una comunidad es que cuanto mayor sea el número de individuos muestreados, más especies se encontrarán. Las curvas de rarefacción se crean muestreando aleatoriamente el conjunto de N muestras varias veces y luego trazando el número promedio de especies encontradas en cada muestra (1,2, … N). “Por lo tanto, la rarefacción genera el número esperado de especies en una pequeña colección de n individuos (o n muestras) extraídos al azar del gran conjunto de N muestras”. Las curvas de rarefacción generalmente crecen rápidamente al principio, a medida que se encuentran las especies más comunes, pero las curvas se estabilizan a medida que solo quedan por muestrear las especies más raras.\n\nCode\nrarecurve(mat_vegan, col = \"blue\") \n\n\n\n\n\n\nCoderarecurve(t(cesar_sp), col = \"blue\") \n\n\n\n\n\n\nCode\nsp1 &lt;- specaccum(mat_vegan)\nsp2 &lt;- specaccum(mat_vegan, \"random\")\n# sp2\n# summary(sp2)\nplot(sp1, ci.type=\"poly\", col=\"blue\", lwd=2, ci.lty=0, ci.col=\"lightblue\")\n\n\n\n\n\n\nCode# boxplot(sp2, col=\"yellow\", add=TRUE, pch=\"+\")\n\n\nmods &lt;- fitspecaccum(sp1, \"gleason\")\nplot(mods, col=\"hotpink\")\nboxplot(sp2, col = \"yellow\", border = \"blue\", lty=1, cex=0.3, add= TRUE)\n\n\n\n\n\n\nCode\n\n## Accumulation model\npool &lt;- poolaccum(mat_vegan)\n# summary(pool, display = \"chao\")\nplot(pool)\n\n\n\n\n\n\n\nRango Abundancia Dominancia\nUn enfoque alternativo para la distribución de la abundancia de especies es representar gráficamente las abundancias logarítmicas en orden decreciente o en función de los rangos de especies. Estos tambien son conocidos como Whittaker plots.\nLas curvas de Rango Abundancia Dominancia muestran la abundancia logarítmica de las especies en función de su orden jerárquico. Se supone que estos gráficos son eficaces para analizar los tipos de distribución de la abundancia en las comunidades.\n\nCodek &lt;- sample(nrow(mat_vegan), 1)\n# Take a subset to save time and nerves\nrad &lt;- radfit(mat_vegan[21,]) # site 21\n# plot(rad)\nradlattice(rad)\n\n\n\n\n\n\nCode\n# Take a subset of sites 1 to 3 in mat_vegan to save time and nerves\nmod &lt;- radfit(mat_vegan[1:3,])\nmod\n#&gt; \n#&gt; Deviance for RAD models:\n#&gt; \n#&gt;            POA_ST18 POA_ST1 POA_ST15\n#&gt; Null        6.91101 2.06787   0.8623\n#&gt; Preemption  3.45643 0.43703   0.5957\n#&gt; Lognormal   2.41147 0.38861   0.6575\n#&gt; Zipf        4.63984 0.59345   0.6836\n#&gt; Mandelbrot  2.99015 0.13371   0.4411\nplot(mod)\n\n\n\n\n\n\n\nDiversidad de Hill usando el paquete vegan\n\nLa función renyi encuentra diversidades de Rényi en las escala del número de Hill correspondiente.\nCalculemos las curvas de acumulación de especies para todos los los sitios.\n\nCode# data(BCI)\ni &lt;- sample(nrow(mat_vegan), 20)\nmod2 &lt;- renyi(mat_vegan) #selecting sites with more than one record\nplot(mod2)\n\n\n\n\n\n\n\nAhora comparemos los sitios 1 al 18 que corresponden la Paz Manaure Vs. Beccerril que son los sitios 19 al 41. Note que el sitio 12 no tiene ninguna especie, asi que debe ser eliminado.\n\nCode# sitios 19 a 41\nmod3 &lt;- renyiaccum(mat_vegan[19:41,], hill=TRUE) # sitios 19 a 41 RNB\nmod4 &lt;- renyiaccum(mat_vegan[c(1,2,3,4,5,6,7,8,9,10,\n                               11,13,14,15,16,17,18),], hill=TRUE) # sitios POA\n\n# create a new plotting window and set the plotting area into a 1*2 array\npar(mfrow = c(1, 2))\nplot(mod3, as.table=TRUE, col = c(1, 2, 2))\n\n\n\n\n\n\nCodeplot(mod4, as.table=TRUE, col = c(1, 2, 2))\n\n\n\n\n\n\nCode\n# persp(mod3)\n\n\nLas graficas tambien se pueden ver en 3D\n\nCode\npar(mfrow = c(1, 2))\npersp(mod3)\npersp(mod4)\n\n\n\n\n\n\n\nNúmero total de especies\n\nCodeDT::datatable(round(specpool(mat_vegan),3))\n\n\n\n\n\nNumero de especies no vistas en cada camara\nLook at S.chao1\n\nCodeDT::datatable(\nt(round(as.data.frame(estimateR(mat_vegan[,])),3))\n)\n\n\n\n\nCode\n# save as dataframe\nS_per_site &lt;- as.data.frame(t(round(as.data.frame(estimateR(mat_vegan[,])),3)))\n# add sites\nS_per_site$Station &lt;- rownames(S_per_site)\n\n\nIt is weird to have .5 species in some sites."
  },
  {
    "objectID": "posts/2024-12-15-riqueza/index.html#creemos-un-mapa-al-convertir-la-tabla-de-operación-de-la-cámara-trampa-a-un-objeto-sf",
    "href": "posts/2024-12-15-riqueza/index.html#creemos-un-mapa-al-convertir-la-tabla-de-operación-de-la-cámara-trampa-a-un-objeto-sf",
    "title": "Riqueza de especies",
    "section": "Creemos un mapa al convertir la tabla de operación de la cámara trampa a un objeto sf\n",
    "text": "Creemos un mapa al convertir la tabla de operación de la cámara trampa a un objeto sf\n\nEn este paso, convertimos la tabla de operación de la cámara trampa a un objeto sf. Luego agregamos la elevación con una busqueda rapida en los datos de la nube de Amazon (AWS), luego agregamos el tipo de hábitat y las especies por sitio (S.chao1), para finalmente visualizar el mapa, el cuál muestra la cantidad de especies como el tamaño del punto.\n\nCode\n# datos_distinct &lt;- datos |&gt; distinct(Longitude, Latitude, CT, Proyecto)\n\nprojlatlon &lt;- \"+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0\"\n\nCToperation_sf &lt;-  st_as_sf(x = CToperation,\n                         coords = c(\"Lon\", \n                                    \"Lat\"),\n                         crs = projlatlon)\n\n# write.csv(habs, \"C:/CodigoR/CameraTrapCesar/data/habitats.csv\")\nhabs &lt;- read.csv(\"C:/CodigoR/CameraTrapCesar/data/habitats.csv\")\n\nCToperation_elev_sf &lt;- get_elev_point(CToperation_sf, src = \"aws\") # get elevation from AWS\n\nCToperation_elev_sf &lt;- CToperation_elev_sf |&gt; left_join(habs, by='Station') |&gt; left_join(S_per_site, by='Station') |&gt; select(\"Station\", \"elevation\", \"minStart.x\",\"maxEnd.x\", \"Year.x\", \"hab_code\" , \"S.obs\", \"S.chao1\")\n\n# add habitat \n# CToperation_elev_sf$habs &lt;- habs$hab_code\n# see the map\nmapview(CToperation_elev_sf, zcol=\"hab_code\", cex = \"S.chao1\", alpha = 0)"
  },
  {
    "objectID": "posts/2024-12-15-riqueza/index.html#mapa-de-contornos",
    "href": "posts/2024-12-15-riqueza/index.html#mapa-de-contornos",
    "title": "Riqueza de especies",
    "section": "Mapa de contornos",
    "text": "Mapa de contornos\nUna ventaja de utilizar la estimación de densidad es que podemos sobreponerla a un mapa y usar Los suavizadores de kernel, los cuales son herramientas esenciales para el análisis de datos geograficos. Gracias a su capacidad para transmitir información estadística compleja con visualizaciones gráficas concisas, podemos vcisualizar un mapa de riqueza de especies con contornos. El suavizador de kernel más utilizado es el estimador de densidad de kernel (KDE), que se calcula con la funcion st_kde del paquete eks.\nEl contorno del 20 % significa que “el 20 % de las mediciones se encuentran dentro de este contorno”. La documentación de eks no está de acuerdo con la forma en que stat_density_2d del paquete ggplot2 realiza su cálculo. No sé quién tiene razón porque el valor estimado es la especie y los resultados son similares. En todo caso usemos eks.\n\nCode# select chao\nspecies &lt;- dplyr::select(CToperation_elev_sf, \"S.chao1\")\n# hakeoides_coord &lt;- data.frame(sf::st_coordinates(hakeoides))\nSta_den &lt;- eks::st_kde(species) # calculate density\n\n# VERY conveniently, eks can generate an sf file of contour lines\ncontours &lt;- eks::st_get_contour(Sta_den, cont=c( 10,20,30,40,50,60,70,80, 90)) %&gt;% \n  mutate(value=as.numeric(levels(contlabel)))\n\n\n# pal_fun &lt;- leaflet::colorQuantile(\"YlOrRd\", NULL, n = 5)\n\np_popup &lt;- paste(\"Species\", as.numeric(levels(contours$estimate)), \"number\")\n\n\ntmap::tmap_mode(\"view\") # set mode to interactive plots\n\ntmap::tm_shape(species) + \n    tmap::tm_sf(col=\"black\", size=0.2) +\n  #   contours from eks\n  tmap::tm_shape(contours) +\n    tmap::tm_polygons(\"estimate\",\n                      palette=\"Reds\",\n                      alpha=0.5 )\n\n\n\n\n\nCode\n\n## geom_sf plot\n# ## suitable smoothing matrix gives optimally smoothed contours\n# gs1 &lt;- ggplot(Sta_den) + geom_sf(data=CToperation_elev_sf, fill=NA) + ggthemes::theme_map() +\n#     colorspace::scale_fill_discrete_sequential(palette=\"Heat2\") \n# gs1 + geom_sf(data=st_get_contour(Sta_den), aes(fill=label_percent(contlabel))) +\n#     coord_sf(xlim=xlim, ylim=ylim) \n\n\n\nEn términos generales, la estimación de riqueza de especies por sitio muestra que al parecer es mayor en el norte. Observe también que las estimaciones de densidad de núcleo son mayores que las de s.chao1."
  },
  {
    "objectID": "posts/2024-12-15-riqueza/index.html#escalamiento-multidimensional-no-métrico-nmds",
    "href": "posts/2024-12-15-riqueza/index.html#escalamiento-multidimensional-no-métrico-nmds",
    "title": "Riqueza de especies",
    "section": "Escalamiento multidimensional no métrico (NMDS)",
    "text": "Escalamiento multidimensional no métrico (NMDS)\nEn la investigación ecológica, a menudo nos interesa no solo comparar descriptores univariados de comunidades, como la diversidad, sino también cómo las especies constituyentes (o la composición de especies) cambian de una comunidad a la siguiente. Una herramienta común para hacer esto es el escalamiento multidimensional no métrico, o NMDS. El objetivo del NMDS es agrupar la información de múltiples dimensiones (por ejemplo, de múltiples comunidades, sitios donde se instaló la cámara trampa, etc.) en solo unas pocas, de modo que se puedan visualizar e interpretar. A diferencia de otras técnicas de ordenación que se basan en distancias (principalmente euclidianas), como el análisis de coordenadas principales, el NMDS utiliza órdenes de rango y, por lo tanto, es una técnica extremadamente flexible que puede adaptarse a una variedad de diferentes tipos de datos.\nSi el tratamiento es continuo, como un gradiente ambiental, entonces puede ser útil trazar líneas de contorno en lugar de envolturas convexas. Podemos obtener algunos datos de elevación para nuestra matriz comunitaria original y superponerlos en el gráfico NMDS usando ordisurf.\n\nCode\nexample_NMDS=metaMDS(as.data.frame(mat_vegan), \n                     distance=\"euclidean\",\n                     zerodist = \"ignore\",\n                     trymax=300,\n                     k=5) # T\n#&gt; Wisconsin double standardization\n#&gt; Run 0 stress 0.07931572 \n#&gt; Run 1 stress 0.08014803 \n#&gt; Run 2 stress 0.08070119 \n#&gt; Run 3 stress 0.08095094 \n#&gt; Run 4 stress 0.08067204 \n#&gt; Run 5 stress 0.07965688 \n#&gt; ... Procrustes: rmse 0.05115095  max resid 0.1813038 \n#&gt; Run 6 stress 0.07836932 \n#&gt; ... New best solution\n#&gt; ... Procrustes: rmse 0.08636736  max resid 0.3056494 \n#&gt; Run 7 stress 0.08024195 \n#&gt; Run 8 stress 0.0810637 \n#&gt; Run 9 stress 0.07933142 \n#&gt; Run 10 stress 0.07860664 \n#&gt; ... Procrustes: rmse 0.05999152  max resid 0.2908247 \n#&gt; Run 11 stress 0.07907563 \n#&gt; Run 12 stress 0.07956862 \n#&gt; Run 13 stress 0.08108113 \n#&gt; Run 14 stress 0.0782419 \n#&gt; ... New best solution\n#&gt; ... Procrustes: rmse 0.008577372  max resid 0.02260663 \n#&gt; Run 15 stress 0.08035403 \n#&gt; Run 16 stress 0.07882269 \n#&gt; Run 17 stress 0.07963713 \n#&gt; Run 18 stress 0.0796504 \n#&gt; Run 19 stress 0.07921461 \n#&gt; Run 20 stress 0.07941604 \n#&gt; Run 21 stress 0.08057114 \n#&gt; Run 22 stress 0.0791947 \n#&gt; Run 23 stress 0.07823504 \n#&gt; ... New best solution\n#&gt; ... Procrustes: rmse 0.06187092  max resid 0.2181191 \n#&gt; Run 24 stress 0.0785212 \n#&gt; ... Procrustes: rmse 0.08184962  max resid 0.2850129 \n#&gt; Run 25 stress 0.08011924 \n#&gt; Run 26 stress 0.08020207 \n#&gt; Run 27 stress 0.07995016 \n#&gt; Run 28 stress 0.08003922 \n#&gt; Run 29 stress 0.07917266 \n#&gt; Run 30 stress 0.07850791 \n#&gt; ... Procrustes: rmse 0.06474448  max resid 0.1978589 \n#&gt; Run 31 stress 0.08010422 \n#&gt; Run 32 stress 0.07940516 \n#&gt; Run 33 stress 0.07996894 \n#&gt; Run 34 stress 0.08068725 \n#&gt; Run 35 stress 0.07837964 \n#&gt; ... Procrustes: rmse 0.01560803  max resid 0.0715659 \n#&gt; Run 36 stress 0.07851791 \n#&gt; ... Procrustes: rmse 0.08287466  max resid 0.2932717 \n#&gt; Run 37 stress 0.08022056 \n#&gt; Run 38 stress 0.07927003 \n#&gt; Run 39 stress 0.07879515 \n#&gt; Run 40 stress 0.0821534 \n#&gt; Run 41 stress 0.08129897 \n#&gt; Run 42 stress 0.07891388 \n#&gt; Run 43 stress 0.0790046 \n#&gt; Run 44 stress 0.08129301 \n#&gt; Run 45 stress 0.07902798 \n#&gt; Run 46 stress 0.07930301 \n#&gt; Run 47 stress 0.07979179 \n#&gt; Run 48 stress 0.08131694 \n#&gt; Run 49 stress 0.07822472 \n#&gt; ... New best solution\n#&gt; ... Procrustes: rmse 0.004446989  max resid 0.01620173 \n#&gt; Run 50 stress 0.07824116 \n#&gt; ... Procrustes: rmse 0.06270762  max resid 0.2238349 \n#&gt; Run 51 stress 0.08069249 \n#&gt; Run 52 stress 0.08124517 \n#&gt; Run 53 stress 0.0783833 \n#&gt; ... Procrustes: rmse 0.01272943  max resid 0.05419391 \n#&gt; Run 54 stress 0.08030711 \n#&gt; Run 55 stress 0.08144491 \n#&gt; Run 56 stress 0.08077428 \n#&gt; Run 57 stress 0.07828174 \n#&gt; ... Procrustes: rmse 0.06351221  max resid 0.2148259 \n#&gt; Run 58 stress 0.08064748 \n#&gt; Run 59 stress 0.07918459 \n#&gt; Run 60 stress 0.08222877 \n#&gt; Run 61 stress 0.08124275 \n#&gt; Run 62 stress 0.08321819 \n#&gt; Run 63 stress 0.07918741 \n#&gt; Run 64 stress 0.07893333 \n#&gt; Run 65 stress 0.07932134 \n#&gt; Run 66 stress 0.0798518 \n#&gt; Run 67 stress 0.07977442 \n#&gt; Run 68 stress 0.07931401 \n#&gt; Run 69 stress 0.07861398 \n#&gt; ... Procrustes: rmse 0.01871308  max resid 0.06740836 \n#&gt; Run 70 stress 0.07896499 \n#&gt; Run 71 stress 0.08028605 \n#&gt; Run 72 stress 0.07893628 \n#&gt; Run 73 stress 0.08069282 \n#&gt; Run 74 stress 0.07970847 \n#&gt; Run 75 stress 0.08011481 \n#&gt; Run 76 stress 0.08147157 \n#&gt; Run 77 stress 0.08101052 \n#&gt; Run 78 stress 0.07865708 \n#&gt; ... Procrustes: rmse 0.01657987  max resid 0.05652728 \n#&gt; Run 79 stress 0.07989567 \n#&gt; Run 80 stress 0.08169148 \n#&gt; Run 81 stress 0.08144408 \n#&gt; Run 82 stress 0.08194274 \n#&gt; Run 83 stress 0.08117478 \n#&gt; Run 84 stress 0.08127721 \n#&gt; Run 85 stress 0.08209545 \n#&gt; Run 86 stress 0.08027951 \n#&gt; Run 87 stress 0.07892395 \n#&gt; Run 88 stress 0.08179564 \n#&gt; Run 89 stress 0.07823115 \n#&gt; ... Procrustes: rmse 0.001911547  max resid 0.007645847 \n#&gt; ... Similar to previous best\n#&gt; *** Best solution repeated 1 times\n\n# plot the graph\nvegan::ordisurf((example_NMDS),CToperation_elev_sf$elevation,main=\"\",col=\"forestgreen\", trymax=100) # bubble = 2\n#&gt; \n#&gt; Family: gaussian \n#&gt; Link function: identity \n#&gt; \n#&gt; Formula:\n#&gt; y ~ s(x1, x2, k = 10, bs = \"tp\", fx = FALSE)\n#&gt; \n#&gt; Estimated degrees of freedom:\n#&gt; 7.54  total = 8.54 \n#&gt; \n#&gt; REML score: 310.7183\nvegan::orditorp(example_NMDS,display=\"species\",col=\"blue\",air=0.1,\n   cex=0.5)\n\n\n\n\n\n\n\nPodemos hacer una gráfica similar usando gg_ordisurf del paquete ggordiplots pero incorporando también el tipo de hábitat.\n\nCode# ggordiplots::gg_ordisurf()\n# To fit a surface with ggordiplots:\n\n \nordiplot &lt;- gg_ordisurf(ord = example_NMDS, \n                        env.var = CToperation_elev_sf$elevation,\n                        var.label = \"Elevation\",\n                        pt.size = 2,\n                        groups = CToperation_elev_sf$hab_code,\n                        binwidth = 50)\n\n\n\n\n\n\nCode\n# ggplotly(ordiplot$plot) # see interactive\n\n# # alternative using biodiversityR\n# \n# A1.surface &lt;- ordisurf( y=example_NMDS)\n# A1.grid &lt;- ordisurfgrid.long(A1.surface)\n# # Preparing the plot\n# \n# plotgg4 &lt;- ggplot() + \n#     geom_contour_filled(data=A1.grid, \n#                         aes(x=x, y=y, z=z)) +\n#     geom_vline(xintercept = c(0), color = \"grey70\", linetype = 2) +\n#     geom_hline(yintercept = c(0), color = \"grey70\", linetype = 2) +  \n#     xlab(axis.long2[1, \"label\"]) +\n#     ylab(axis.long2[2, \"label\"]) +  \n#     scale_x_continuous(sec.axis = dup_axis(labels=NULL, name=NULL)) +\n#     scale_y_continuous(sec.axis = dup_axis(labels=NULL, name=NULL)) +\n#     geom_point(data=sites.long2, \n#                aes(x=axis1, y=axis2, shape=Management), \n#                colour=\"red\", size=4) +\n#     BioR.theme +\n#     scale_fill_viridis_d() +\n#     labs(fill=\"A1\") +\n#     coord_fixed(ratio=1)\n# # and seeing the plot.\n# \n# plotgg4\n\n\nLos contornos conectan especies en el espacio de ordenación que se predice que tendrán la misma elevación. Note que es una representación en el espacio multivariado, no una representación geográfica."
  },
  {
    "objectID": "posts/2024-12-15-riqueza/index.html#rarefaction-usando-inext",
    "href": "posts/2024-12-15-riqueza/index.html#rarefaction-usando-inext",
    "title": "Riqueza de especies",
    "section": "Rarefaction usando iNEXT\n",
    "text": "Rarefaction usando iNEXT\n\n\nCode\n\n\nout &lt;- iNEXT(incidence_cesar, # The data frame\n             q=0,# The type of diversity estimator \n             datatype=\"incidence_freq\",   # The type of analysis\n             knots=40,                    # The number of data points \n             se=TRUE,                     # confidence intervals\n             conf=0.95,                   # The level of confidence intervals\n             nboot=100)                    # The number of bootstraps \n\nggiNEXT(out, type=1)\n\n\n\n\n\n\nCodeggiNEXT(out, type=2)\n\n\n\n\n\n\nCodeggiNEXT(out, type=3)\n\n\n\n\n\n\nCode\np1 &lt;- ggiNEXT(out, type=1)+ theme_classic() +   #  type 1 = the diversity estimator\n        labs(x = \"Survey sites\", y = \"Richness\")\n  \np2 &lt;- ggiNEXT(out, type=2)+ theme_classic() +    #  type 2 = the survey coverage\n        labs(x = \"Survey sites\")\n    \ngrid.arrange(p1, p2, nrow = 2)\n\n\n\n\n\n\nCode##############\nout2 &lt;- iNEXT(incidence_cesar, q=c(0,1,2) ,datatype=\"incidence_freq\" )\n\nggiNEXT(out2, type=1, facet.var=\"Order.q\", color.var=\"Assemblage\") + theme_classic() \n\n\n\n\n\n\n\nEl paquete iNEXT es adecuado para comparaciones de índices de diversidad mediante el uso de números de Hill, de los cuales el valor q representa la riqueza y los índices de diversidad tradicionales:\n\nLa riqueza de especies es q = 0.\nEl índice de Shannon es q=1\nEl índice de Simpson es q=2.\n\n\nNota: el aumento de los valores de q reduce la influencia de las especies raras en nuestra estimación de la diversidad de la comunidad.\n\nFacil no?… tenga en cuenta que en los datos de fototrampeo, tal vez debamos separar en los datos aves de los de mamíferos."
  },
  {
    "objectID": "posts/2024-12-15-riqueza/index.html#package-citation",
    "href": "posts/2024-12-15-riqueza/index.html#package-citation",
    "title": "Riqueza de especies",
    "section": "Package Citation",
    "text": "Package Citation\n\nCodepkgs &lt;- cite_packages(output = \"paragraph\", out.dir = \".\") #knitr::kable(pkgs)\npkgs\n\nWe used R v. 4.4.2 (R Core Team 2024) and the following R packages: camtrapR v. 3.0.0 (Niedballa et al. 2016), DT v. 0.34.0 (Xie et al. 2025), eks v. 1.1.1 (Duong 2025), elevatr v. 0.99.0 (Hollister et al. 2023), ggforce v. 0.4.2 (Pedersen 2024), ggordiplots v. 0.4.3 (Quensen, Simpson, and Oksanen 2024), ggvegan v. 0.1.999 (Simpson and Oksanen 2023), gridExtra v. 2.3 (Auguie 2017), iNEXT v. 3.0.1 (Chao et al. 2014; Hsieh, Ma, and Chao 2024), kableExtra v. 1.4.0 (Zhu 2024), knitr v. 1.50 (Xie 2014, 2015, 2025), mapview v. 2.11.4 (Appelhans et al. 2025), MeanRarity v. 0.0.1.5 (Roswell and Dushoff 2023), patchwork v. 1.3.2 (Pedersen 2025), plotly v. 4.10.4 (Sievert 2020), plyr v. 1.8.9 (Wickham 2011), reshape2 v. 1.4.4 (Wickham 2007), rmarkdown v. 2.30 (Xie, Allaire, and Grolemund 2018; Xie, Dervieux, and Riederer 2020; Allaire et al. 2025), scales v. 1.4.0 (Wickham, Pedersen, and Seidel 2025), sf v. 1.0.21 (Pebesma 2018; Pebesma and Bivand 2023), SpadeR v. 0.1.1 (Chao et al. 2016), tidyverse v. 2.0.0 (Wickham et al. 2019), tmap v. 4.2 (Tennekes 2018), vegan v. 2.7.2 (Oksanen et al. 2025)."
  },
  {
    "objectID": "posts/2024-12-15-riqueza/index.html#sesion-info",
    "href": "posts/2024-12-15-riqueza/index.html#sesion-info",
    "title": "Riqueza de especies",
    "section": "Sesion info",
    "text": "Sesion info\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nCodeprint(sessionInfo(), locale = FALSE)\n#&gt; R version 4.4.2 (2024-10-31 ucrt)\n#&gt; Platform: x86_64-w64-mingw32/x64\n#&gt; Running under: Windows 10 x64 (build 19045)\n#&gt; \n#&gt; Matrix products: internal\n#&gt; \n#&gt; \n#&gt; attached base packages:\n#&gt; [1] grid      stats     graphics  grDevices utils     datasets  methods  \n#&gt; [8] base     \n#&gt; \n#&gt; other attached packages:\n#&gt;  [1] scales_1.4.0          plyr_1.8.9            reshape2_1.4.4       \n#&gt;  [4] plotly_4.10.4         ggforce_0.4.2         lubridate_1.9.4      \n#&gt;  [7] forcats_1.0.0         stringr_1.5.2         dplyr_1.1.4          \n#&gt; [10] purrr_1.1.0           readr_2.1.5           tidyr_1.3.1          \n#&gt; [13] tibble_3.2.1          tidyverse_2.0.0       kableExtra_1.4.0     \n#&gt; [16] knitr_1.50            iNEXT_3.0.1           SpadeR_0.1.1         \n#&gt; [19] MeanRarity_0.0.1.0005 DT_0.34.0             gridExtra_2.3        \n#&gt; [22] ggordiplots_0.4.3     glue_1.8.0            ggvegan_0.1.999      \n#&gt; [25] ggplot2_4.0.0         vegan_2.7-2           permute_0.9-7        \n#&gt; [28] camtrapR_3.0.0        grateful_0.3.0        eks_1.1.1            \n#&gt; [31] tmap_4.2              mapview_2.11.4        elevatr_0.99.0       \n#&gt; [34] sf_1.0-21             readxl_1.4.3          patchwork_1.3.2      \n#&gt; \n#&gt; loaded via a namespace (and not attached):\n#&gt;   [1] RColorBrewer_1.1-3      rstudioapi_0.17.1       jsonlite_2.0.0         \n#&gt;   [4] wk_0.9.4                magrittr_2.0.3          farver_2.1.2           \n#&gt;   [7] rmarkdown_2.30          vctrs_0.6.5             base64enc_0.1-3        \n#&gt;  [10] terra_1.8-70            RcppNumerical_0.6-0     progress_1.2.3         \n#&gt;  [13] htmltools_0.5.8.1       leafsync_0.1.0          curl_7.0.0             \n#&gt;  [16] raster_3.6-32           cellranger_1.1.0        s2_1.1.9               \n#&gt;  [19] sass_0.4.10             pracma_2.4.4            slippymath_0.3.1       \n#&gt;  [22] bslib_0.9.0             KernSmooth_2.23-24      htmlwidgets_1.6.4      \n#&gt;  [25] cachem_1.1.0            libgeos_3.11.1-3        stars_0.6-8            \n#&gt;  [28] uuid_1.2-1              mime_0.13               lifecycle_1.0.4        \n#&gt;  [31] pkgconfig_2.0.3         cols4all_0.8-1          Matrix_1.7-1           \n#&gt;  [34] R6_2.6.1                fastmap_1.2.0           rbibutils_2.3          \n#&gt;  [37] shiny_1.9.1             digest_0.6.37           colorspace_2.1-1       \n#&gt;  [40] leafem_0.2.4            crosstalk_1.2.1         maplegend_0.2.0        \n#&gt;  [43] labeling_0.4.3          lwgeom_0.2-14           progressr_0.15.0       \n#&gt;  [46] spacesXYZ_1.6-0         timechange_0.3.0        httr_1.4.7             \n#&gt;  [49] polyclip_1.10-7         abind_1.4-8             mgcv_1.9-1             \n#&gt;  [52] compiler_4.4.2          microbenchmark_1.5.0    proxy_0.4-27           \n#&gt;  [55] withr_3.0.2             brew_1.0-10             S7_0.2.0               \n#&gt;  [58] DBI_1.2.3               logger_0.4.0            MASS_7.3-61            \n#&gt;  [61] maptiles_0.10.0         tmaptools_3.3           leaflet_2.2.3          \n#&gt;  [64] classInt_0.4-11         tools_4.4.2             units_0.8-7            \n#&gt;  [67] leaflegend_1.2.1        httpuv_1.6.16           satellite_1.0.5        \n#&gt;  [70] nlme_3.1-166            geos_0.2.4              promises_1.3.3         \n#&gt;  [73] cluster_2.1.6           generics_0.1.3          isoband_0.2.7          \n#&gt;  [76] leaflet.providers_2.0.0 gtable_0.3.6            tzdb_0.4.0             \n#&gt;  [79] shinyBS_0.61.1          class_7.3-22            hms_1.1.3              \n#&gt;  [82] data.table_1.17.8       xml2_1.4.0              sp_2.2-0               \n#&gt;  [85] ggrepel_0.9.6           pillar_1.11.1           later_1.4.2            \n#&gt;  [88] splines_4.4.2           tweenr_2.0.3            mapsf_1.0.0            \n#&gt;  [91] lattice_0.22-6          renv_1.0.11             ks_1.15.1              \n#&gt;  [94] tidyselect_1.2.1        svglite_2.1.3           stats4_4.4.2           \n#&gt;  [97] xfun_0.52               shinydashboard_0.7.3    leafpop_0.1.0          \n#&gt; [100] stringi_1.8.4           lazyeval_0.2.2          yaml_2.3.10            \n#&gt; [103] evaluate_1.0.4          codetools_0.2-20        cli_3.6.5              \n#&gt; [106] RcppParallel_5.1.9      systemfonts_1.1.0       xtable_1.8-4           \n#&gt; [109] Rdpack_2.6.2            jquerylib_0.1.4         secr_5.1.0             \n#&gt; [112] dichromat_2.0-0.1       Rcpp_1.1.0              png_0.1-8              \n#&gt; [115] XML_3.99-0.18           parallel_4.4.2          prettyunits_1.2.0      \n#&gt; [118] mclust_6.1.1            viridisLite_0.4.2       mvtnorm_1.3-2          \n#&gt; [121] e1071_1.7-16            crayon_1.5.3            rlang_1.1.6"
  }
]