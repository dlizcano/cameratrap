---
title: 'Species diversity'
subtitle: "Species acumulation curves, rarefaction and other plots"
description: "using packages `vegan` and `iNext`"
author: 
  - name: 'Diego J. Lizcano'
    orcid: 0000-0002-9648-0576
    affiliation: "WildMon"
date: '2024-06-25'
file-modified: Sys.Date()
categories: [R, diversity, accumulation, effort]
image: 'img/preview.png'
citation: true
bibliography: "C:/CodigoR/CameraTrapCesar/posts/2024-06-25-species-diversity/grateful-refs.bib"
---


## Species richness and sampling effort  

There are two commonly used ways to account for survey effort when estimating species richness using camera traps:

1. using the rarefaction of observed richness.  

2. using multispecies occupancy models to account for the species present but not observed (occupancy model). 

In this post we can see an example of No 1. using the classical approach of community ecology using the `vegan` package. The vegan package (https://cran.r-project.org/package=vegan) provides tools for descriptive community ecology. It has basic functions of diversity analysis, community ordination and dissimilarity analysis. The vegan package provides most standard tools of descriptive community analysis. Later in the post we carry out another diversity analysis using functions of the package `iNEXT`.

The modern approach to measure species diversity include the "Sample Hill diversities" also known as Hill numbers. Rarefaction and extrapolation with Hill numbers have gain popularity in the last decade and can be computed using the function `renyi` in the R package `vegan` (Oksanen 2016) and the function `rarity` in the R package `MeanRarity` (Roswell and Dushoff 2020), and Hill diversities of equal-sized or equal-coverage samples can be approximately compared using the functions `iNEXT` and `estimateD` in the R package `iNEXT` (Hsieh et al. 2016). Estimates for asymptotic values of Hill diversity are available in `SpadeR` (Chao and Jost 2015, Chao et al. 2015).



## Load packages

```{r setup, include=TRUE}


library(patchwork) # The Composer of Plots
library(readxl) # Read Excel Files
library(sf) # Simple Features for R
library(elevatr) # Access Elevation Data from Various APIs
library(mapview) # Interactive Viewing of Spatial Data in R
library(grateful) # Facilitate Citation of R Packages
library(camtrapR) # Camera Trap Data Management and Preparation of Occupancy and Spatial Capture-Recapture Analyses
library(vegan) # Community Ecology Package 
library(ggvegan)
library(ggordiplots)
library(grid)
library(gridExtra)
library(MeanRarity)
library(SpadeR)
library(iNEXT) # Interpolation and Extrapolation for Species Diversity
library(knitr) # A General-Purpose Package for Dynamic Report Generation in R
library(kableExtra) # Construct Complex Table with 'kable' and Pipe Syntax
library(tidyverse) # Easily Install and Load the 'Tidyverse'
library(ggforce) # Accelerating 'ggplot2'


```



## Load data

```{r warning=FALSE}

datos <- read_excel("C:/CodigoR/CameraTrapCesar/data/CT_Cesar.xlsx")

# write.csv(habs, "C:/CodigoR/CameraTrapCesar/data/habitats.csv")
habs <- read.csv("C:/CodigoR/CameraTrapCesar/data/habitats.csv")


```




## Pooling together several sites

For this example I selected one year for the sites: Becerril 2021, LaPaz_Manaure 2019, MLJ, CL1, CL2 and PCF.  Sometimes we need to make unique codes per camera and cameraOperation table. This was not the case.

```{r}
# make a new column Station
# datos_PCF <- datos |> dplyr::filter(Proyecto=="CT_LaPaz_Manaure") |> unite ("Station", ProyectoEtapa:Salida:CT, sep = "-")

# fix dates
datos$Start <- as.Date(datos$Start, "%d/%m/%Y")
datos$End <- as.Date(datos$End, "%d/%m/%Y")
datos$eventDate <- as.Date(datos$eventDate, "%d/%m/%Y")
datos$eventDateTime <- ymd_hms(paste(datos$eventDate, " ",
                              datos$eventTime, ":00", sep=""))

# filter Becerril
datos_Becerril <- datos |> dplyr::filter(ProyectoEtapa=="CT_Becerril") |> mutate (Station=IdGeo) |> filter(Year==2021)

# filter LaPaz_Manaure
datos_LaPaz_Manaure<- datos |> dplyr::filter(ProyectoEtapa=="CT_LaPaz_Manaure") |> mutate (Station=IdGeo) |> filter(Year==2019)

# filter MLJ
datos_MLJ <- datos |> dplyr::filter(ProyectoEtapa=="MLJ_TH_TS_2021") |> mutate (Station=IdGeo)

# filter CL
datos_CL1 <- datos |> dplyr::filter(ProyectoEtapa=="CL-TH2022") |> mutate (Station=IdGeo)
# filter CL
datos_CL2 <- datos |> dplyr::filter(ProyectoEtapa=="CL-TS2022") |> mutate (Station=IdGeo)

# filter PCF
datos_PCF <- datos |> dplyr::filter(Proyecto=="PCF") |> mutate (Station=IdGeo)

data_south <- rbind(datos_LaPaz_Manaure, datos_Becerril, datos_MLJ,datos_CL1, datos_CL2,datos_PCF)

# filter 2021 and make uniques
CToperation  <- data_south |> 
              # filter(Year==2021) |> 
              group_by(Station) |> 
              mutate(minStart=min(Start), maxEnd=max(End)) |>  distinct(Longitude, Latitude, minStart, maxEnd, Year) |> 
  ungroup()


```


## Generating cameraOperation and making detection histories for all the species. 

The package CamtrapR has the function 'cameraOperation' which makes a table of cameras (stations) and dates (setup, puck-up), this table is key to generate the detection histories using the function 'detectionHistory' in the next step. 

```{r }
# Generamos la matríz de operación de las cámaras

camop <- cameraOperation(CTtable= CToperation, # Tabla de operación
                         stationCol= "Station", # Columna que define la estación
                         setupCol= "minStart", #Columna fecha de colocación
                         retrievalCol= "maxEnd", #Columna fecha de retiro
                         #hasProblems= T, # Hubo fallos de cámaras
                         dateFormat= "%Y-%m-%d") #, # Formato de las fechas
                         #cameraCol="CT")
                         # sessionCol= "Year")

# Generar las historias de detección ---------------------------------------
## remove plroblem species
# ind <- which(datos_PCF$Species=="Marmosa sp.")
# datos_PCF <- datos_PCF[-ind,]

DetHist_list <- lapply(unique(data_south$Species), FUN = function(x) {
  detectionHistory(
    recordTable         = data_south, # Tabla de registros
    camOp                = camop, # Matriz de operación de cámaras
    stationCol           = "Station",
    speciesCol           = "Species",
    recordDateTimeCol    = "eventDateTime",
    recordDateTimeFormat  = "%Y-%m-%d",
    species              = x,     # la función reemplaza x por cada una de las especies
    occasionLength       = 7, # Colapso de las historias a 10 días
    day1                 = "station", # ("survey"),or #inicia en la fecha de cada station
    datesAsOccasionNames = FALSE,
    includeEffort        = TRUE,
    scaleEffort          = FALSE,
    output               = ("binary"), # ("binary") or ("count")
    #unmarkedMultFrameInput=TRUE
    timeZone             = "America/Bogota" 
    )
  }
)

# names
names(DetHist_list) <- unique(data_south$Species)

# Finalmente creamos una lista nueva donde estén solo las historias de detección
ylist <- lapply(DetHist_list, FUN = function(x) x$detection_history)


  
```


## Use the detection histories to make the a matrix for `vegan`

Species accumulation curves made using the package vegan, plot the increase in species richness as we add survey units. If the curve plateaus (flattens), then that suggests you have sampled the majority of the species in your survey area.


```{r}
# loop to make vegan matrix
mat_vegan <- matrix(NA, dim(ylist[[1]])[1], length(unique(data_south$Species)))
for(i in 1:length(unique(data_south$Species))){
  mat_vegan[,i] <- apply(ylist[[i]], 1, sum, na.rm=TRUE)
  mat_vegan[,i] <- tidyr::replace_na(mat_vegan[,i], 0) # replace na with 0
}

colnames(mat_vegan)  <- unique(data_south$Species)
rownames(mat_vegan) <- rownames(ylist[[1]])

mat_vegan2 <- as.data.frame(mat_vegan)
mat_vegan2$hab <- habs$hab_code
# mat_vegan3 <-  mat_vegan2 |> 
  
# Select specific rows by row numbers
closed_forest_rows <- which(mat_vegan2$hab=="closed_forest_evergreen_broad")
herbaceous_rows <- which(mat_vegan2$hab=="herbaceous_wetland")
herbs_rows <- which(mat_vegan2$hab=="herbs")
open_forest_rows <- which(mat_vegan2$hab=="open_forest_evergreen_broad")
open_forest2_rows <- which(mat_vegan2$hab=="open_forest_other")


closed_forest <- apply(mat_vegan2[closed_forest_rows,1:22], MARGIN = 2, sum)
herbaceous_wetland <- apply(mat_vegan2[herbaceous_rows,1:22], MARGIN = 2, sum)
herbs  <- apply(mat_vegan2[herbs_rows,1:22], MARGIN = 2, sum)
open_forest_evergreen <- apply(mat_vegan2[open_forest_rows,1:22], MARGIN = 2, sum)
open_forest_other <- apply(mat_vegan2[open_forest2_rows,1:22], MARGIN = 2, sum)

# tb_sp <- mat_vegan2 |> group_by(hab)
# hab_list <- group_split(tb_sp)

# make list of dataframe per habitat
sp_by_hab <- mat_vegan2 |> dplyr::group_by(hab) %>% split (.$hab)
# arrange abundance (detection frecuency) mat for INEXT 
cesar_sp <- t(rbind(
t(colSums(sp_by_hab[[1]][,1:33])),
t(colSums(sp_by_hab[[2]][,1:33])),
t(colSums(sp_by_hab[[3]][,1:33])),
t(colSums(sp_by_hab[[4]][,1:33])),
t(colSums(sp_by_hab[[5]][,1:33]))
))
 
colnames(cesar_sp) <- names(sp_by_hab)



# function to Format data to incidence
f_incidences <- function(habitat_rows=closed_forest_rows){ylist %>%  # historias de detection
  map(~rowSums(.,na.rm = T)) %>% # sumo las detecciones en cada sitio
  reduce(cbind) %>% # unimos las listas
  as_data_frame() %>% #formato dataframe
  filter(row_number() %in% habitat_rows) |> 
  t() %>% # trasponer la tabla
  as_tibble() %>% #formato tibble
  mutate_if(is.numeric,~(.>=1)*1) %>%  #como es incidencia, formateo a 1 y 0
  rowSums() %>%  # ahora si la suma de las incidencias en cada sitio
  sort(decreasing=T) |> 
  as_tibble() %>% 
  add_row(value= length(habitat_rows), .before = 1) %>%  # requiere que el primer valor sea el número de sitios
  filter(!if_any()==0) |>  # filter ceros
  as.matrix() # Requiere formato de matriz
}

# incidence frequency table (is a list whit 5 habitats)
# Make an empty list to store our data
incidence_cesar <- list() 
incidence_cesar[[1]] <- f_incidences(closed_forest_rows)
incidence_cesar[[2]] <- f_incidences(herbaceous_rows)
incidence_cesar[[3]] <- f_incidences(herbs_rows)
incidence_cesar[[4]] <- f_incidences(open_forest_rows)
incidence_cesar[[5]] <- f_incidences(open_forest_other)

# put names
names(incidence_cesar) <- names(sp_by_hab)

incidence_cesar <- within(incidence_cesar, rm("herbaceous_wetland"))

############## here error loop here?
# Calculate the row sums for the selected rows
# specific_rows_sums <- rowSums(specific_rows[, c("Cerdocyon thous"  , "Cuniculus paca"  , "Cuniculus taczanowskii" )])
# 
# 
# all_numeric_sums <- mat_vegan2 %>%
#   mutate(TotalSums = rowSums(select(., where(is.numeric))))

```

## Rarefaction using `vegan`
 
> Notice that sites are cameras and the acumulation is species per camera not time
 
Rarefaction is a technique to assess expected species richness. Rarefaction allows the calculation of species richness for a given number of individual samples, based on the construction of rarefaction curves.

The issue that occurs when sampling various species in a community is that the larger the number of individuals sampled, the more species that will be found. Rarefaction curves are created by randomly re-sampling the pool of N samples multiple times and then plotting the average number of species found in each sample (1,2, … N). “Thus rarefaction generates the expected number of species in a small collection of n individuals (or n samples) drawn at random from the large pool of N samples.”. Rarefaction curves generally grow rapidly at first, as the most common species are found, but the curves plateau as only the rarest species remain to be sampled.



```{r}

rarecurve(mat_vegan, col = "blue") 
rarecurve(t(cesar_sp), col = "blue") 

sp1 <- specaccum(mat_vegan)
sp2 <- specaccum(mat_vegan, "random")
# sp2
# summary(sp2)
plot(sp1, ci.type="poly", col="blue", lwd=2, ci.lty=0, ci.col="lightblue")
boxplot(sp2, col="yellow", add=TRUE, pch="+")


mods <- fitspecaccum(sp1, "gleason")
plot(mods, col="hotpink")
boxplot(sp2, col = "yellow", border = "blue", lty=1, cex=0.3, add= TRUE)


## Accumulation model
pool <- poolaccum(mat_vegan)
# summary(pool, display = "chao")
plot(pool)




```

### Hill Diversities using vegan

```{r}
# data(BCI)
i <- sample(nrow(mat_vegan), 20)
mod <- renyi(mat_vegan) #selecting sites with more than one record
plot(mod)
mod <- renyiaccum(mat_vegan[55:89,])
plot(mod, as.table=TRUE, col = c(1, 2, 2))
persp(mod)
```



## Convert Cameratrap-operation to sf 

In this step we convert the Cameratrap-operation table to sf, we add elevation from AWS and habitat type to finally visualize the map

```{r}

# datos_distinct <- datos |> distinct(Longitude, Latitude, CT, Proyecto)

projlatlon <- "+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"

CToperation_sf <-  st_as_sf(x = CToperation,
                         coords = c("Longitude", 
                                    "Latitude"),
                         crs = projlatlon)

# write.csv(habs, "C:/CodigoR/CameraTrapCesar/data/habitats.csv")
habs <- read.csv("C:/CodigoR/CameraTrapCesar/data/habitats.csv")

CToperation_elev_sf <- get_elev_point(CToperation_sf, src = "aws") # get elevation from AWS

CToperation_elev_sf <- CToperation_elev_sf |>  left_join(habs, by='Station')

# add habitat 
# CToperation_elev_sf$habs <- habs$hab_code
# see the map
mapview(CToperation_elev_sf, zcol="hab_code")

```

## Nonmetric Multidimensional Scaling (NMDS)

Often in ecological research, we are interested not only in comparing univariate descriptors of communities, like diversity, but also in how the constituent species — or the species composition — changes from one community to the next. One common tool to do this is non-metric multidimensional scaling, or NMDS. The goal of NMDS is to collapse information from multiple dimensions (e.g, from multiple communities, sites were the cameratrap was installed, etc.) into just a few, so that they can be visualized and interpreted. Unlike other ordination techniques that rely on (primarily Euclidean) distances, such as Principal Coordinates Analysis, NMDS uses rank orders, and thus is an extremely flexible technique that can accommodate a variety of different kinds of data.

If the treatment is continuous, such as an environmental gradient, then it might be useful to plot contour lines rather than convex hulls. We can get some, elevation data for our original community matrix and overlay them onto the NMDS plot using `ordisurf`.

```{r}

example_NMDS=metaMDS(as.data.frame(mat_vegan), 
                     distance="euclidean",
                     zerodist = "ignore",
                     trymax=300,
                     k=5) # T

# plot the graph
vegan::ordisurf((example_NMDS),CToperation_elev_sf$elevation,main="",col="forestgreen", trymax=100) # bubble = 2
vegan::orditorp(example_NMDS,display="species",col="blue",air=0.1,
   cex=0.5)




```

We can make a similar plot using `gg_ordisurf` from the package `ggordiplots` but also incorporating habitat type.

```{r}
# ggordiplots::gg_ordisurf()
# To fit a surface with ggordiplots:

 
gg_ordisurf(ord = example_NMDS,
env.var = CToperation_elev_sf$elevation,
var.label = "Elevation",
pt.size = 2,
groups = CToperation_elev_sf$hab_code,
binwidth = 50)
```

The contours connect species in the ordination space that are predicted to have the same elevation.


## Rarefaction using `iNEXT`

```{r}


# inedat <- lapply(apply(mat_vegan, 2, sum, na.rm=TRUE), as.incfreq)
# 
# out <- iNEXT(inedat,          # The data frame
#              q=0,                    # The type of diversity estimator (see discussion of the options below)
#              datatype="incidence_freq",   # The type of analysis
#              knots=40,                    # The number of data points in your line (more = smoother)
#              se=TRUE,                     # Logical statement if you want confidence intervals
#              conf=0.95,                   # The level of confidence intervals
#              nboot=50)                    # The number of replications to perform - this generates your confidence interval - the bigger the number the longer the run time

#data(bird)

out <- iNEXT(incidence_cesar, # The data frame
             q=0,# The type of diversity estimator 
             datatype="incidence_freq",   # The type of analysis
             knots=40,                    # The number of data points 
             se=TRUE,                     # confidence intervals
             conf=0.95,                   # The level of confidence intervals
             nboot=100)                    # The number of bootstraps 

ggiNEXT(out, type=1)
ggiNEXT(out, type=2)
ggiNEXT(out, type=3)

p1 <- ggiNEXT(out, type=1)+ theme_classic() +   #  type 1 = the diversity estimator
        labs(x = "Survey sites", y = "Richness")
  
p2 <- ggiNEXT(out, type=2)+ theme_classic() +    #  type 2 = the survey coverage
        labs(x = "Survey sites")
    
grid.arrange(p1, p2, nrow = 2)
##############
out2 <- iNEXT(incidence_cesar, q=c(0,1,2) ,datatype="incidence_freq" )

ggiNEXT(out2, type=1, facet.var="Order.q", color.var="Assemblage") + theme_classic() 

```

the iNEXT package is well suited for comparisons of diversity indices through the use of hill numbers - of which the ‘q’ value represents the traditional Shannon (q=1) and Simpson (q=2) diversity indices (species richness: q = 0). Note Increasing values of q reduces the influence of rare species on your estimate of community diversity.





## Package Citation

```{r }
pkgs <- cite_packages(output = "paragraph", out.dir = ".") #knitr::kable(pkgs)
pkgs

```

## Sesion info

<details>
  
<summary>Session info</summary>

```{r sessioninfo, echo = FALSE}
#| label: sessioninfo
options(width = 150)
devtools::session_info()
```

</details>


